{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI-Powered Flood Prediction System with h2oGPTe and NVIDIA NIM\n",
    "\n",
    "[![Deploy on NVIDIA](https://img.shields.io/badge/Deploy%20on-NVIDIA%20AI%20Blueprints-76B900?logo=nvidia&logoColor=white)](https://build.nvidia.com)\n",
    "[![H2O.ai](https://img.shields.io/badge/Powered%20by-H2O.ai-FFD500)](https://h2o.ai)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒŠ Overview\n",
    "\n",
    "This blueprint demonstrates an **AI-powered flood prediction and disaster response system** that combines:\n",
    "\n",
    "- **h2oGPTe Agent-to-Agent (A2A)**: Advanced AutoML capabilities with Driverless AI for model training and feature engineering\n",
    "- **NVIDIA NIM**: State-of-the-art inference with `nvidia/llama-3.3-nemotron-super-49b-v1.5` and other NVIDIA models\n",
    "- **NVIDIA NAT Pipeline**: React Agent workflows for multi-agent orchestration\n",
    "- **FastMCP Server**: 20+ specialized tools across 5 intelligent agents\n",
    "- **Real-time Data Integration**: USGS Water Services, NOAA Forecasts, and Weather APIs\n",
    "\n",
    "### ğŸ¯ Use Case: AI for Good - Disaster Response\n",
    "\n",
    "This system provides:\n",
    "- **Real-time flood monitoring** with live data from watersheds and monitoring stations\n",
    "- **AI-powered risk assessment** using advanced machine learning models\n",
    "- **Emergency response coordination** with automated alerts and evacuation planning\n",
    "- **Predictive analytics** for flood forecasting 24-72 hours ahead\n",
    "- **AutoML model training** for continuous improvement of prediction accuracy\n",
    "\n",
    "### ğŸ—ï¸ Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      Flood Prediction System                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
    "â”‚  â”‚   h2oGPTe    â”‚  â”‚  NVIDIA NIM  â”‚  â”‚  FastMCP     â”‚         â”‚\n",
    "â”‚  â”‚  (A2A Mode)  â”‚  â”‚  (Nemotron)  â”‚  â”‚   Server     â”‚         â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "â”‚         â”‚                 â”‚                 â”‚                   â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
    "â”‚                  â”‚                 â”‚                            â”‚\n",
    "â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\n",
    "â”‚         â”‚    NVIDIA NAT Agent Pipeline      â”‚                  â”‚\n",
    "â”‚         â”‚      (React Agent Workflow)       â”‚                  â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n",
    "â”‚                  â”‚                                              â”‚\n",
    "â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚\n",
    "â”‚    â”‚    5 Specialized Agents   â”‚                               â”‚\n",
    "â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â”‚\n",
    "â”‚    â”‚  1. Data Collector        â”‚ â—„â”€â”€ USGS Water Data           â”‚\n",
    "â”‚    â”‚  2. Risk Analyzer         â”‚ â—„â”€â”€ NOAA Flood Alerts         â”‚\n",
    "â”‚    â”‚  3. Emergency Responder   â”‚ â—„â”€â”€ Weather APIs              â”‚\n",
    "â”‚    â”‚  4. AI Predictor          â”‚                               â”‚\n",
    "â”‚    â”‚  5. H2OGPTE ML Agent      â”‚                               â”‚\n",
    "â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  Output: Real-time Monitoring, Alerts, Predictions, ML Models  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Key Technologies\n",
    "\n",
    "1. **h2oGPTe**: Enterprise AI platform with agent mode for AutoML and advanced analytics\n",
    "2. **NVIDIA NIM**: Optimized inference microservices for AI models\n",
    "3. **NVIDIA NAT**: Agent orchestration framework with React-based workflows\n",
    "4. **FastMCP**: Model Context Protocol server for tool integration\n",
    "5. **FastAPI**: High-performance API server for real-time operations\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ What You'll Learn\n",
    "\n",
    "- Setting up multi-agent AI systems for disaster response\n",
    "- Integrating h2oGPTe for AutoML and model training\n",
    "- Using NVIDIA NIM for high-performance inference\n",
    "- Building NAT agent workflows with React patterns\n",
    "- Implementing FastMCP servers with custom tools\n",
    "- Real-time data integration from government APIs\n",
    "- Coordinating multiple AI agents for complex tasks\n",
    "\n",
    "Let's get started! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have the following installed and configured:\n",
    "\n",
    "### Required Software\n",
    "\n",
    "1. **Python 3.11**\n",
    "   ```bash\n",
    "   # Ubuntu/Debian\n",
    "   sudo apt-get update\n",
    "   sudo apt-get install python3.11 python3.11-venv\n",
    "   sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1\n",
    "   sudo update-alternatives --set python3 /usr/bin/python3.11\n",
    "   ```\n",
    "\n",
    "2. **Docker** (for Redis)\n",
    "   ```bash\n",
    "   # Ubuntu/Debian\n",
    "   sudo apt-get install docker.io\n",
    "   sudo systemctl start docker\n",
    "   ```\n",
    "\n",
    "3. **Node.js & npm** (for netcat utility used by scripts)\n",
    "   ```bash\n",
    "   # Ubuntu/Debian\n",
    "   sudo apt-get install nodejs npm netcat\n",
    "   ```\n",
    "\n",
    "### Required API Keys\n",
    "\n",
    "#### 1. NVIDIA API Key (Required)\n",
    "\n",
    "Get your NVIDIA API key from the NVIDIA AI API Catalog:\n",
    "\n",
    "ğŸ”— **[Get NVIDIA API Key](https://docs.api.nvidia.com/nim/docs/api-quickstart#interacting-through-python)**\n",
    "\n",
    "Steps:\n",
    "1. Visit [https://build.nvidia.com/explore/discover](https://build.nvidia.com/explore/discover)\n",
    "2. Sign in or create an NVIDIA account\n",
    "3. Navigate to \"API Keys\" section\n",
    "4. Generate a new API key\n",
    "5. Copy the key (starts with `nvapi-`)\n",
    "\n",
    "#### 2. h2oGPTe Credentials (Optional)\n",
    "\n",
    "For AutoML and advanced ML features, get h2oGPTe credentials:\n",
    "\n",
    "ğŸ”— **[Get h2oGPTe Access](https://h2o.ai/platform/enterprise-h2ogpte/)**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Environment Setup\n",
    "\n",
    "Set your API keys here before running the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NVIDIA_API_KEY configured\n",
      "   Key preview: nvapi-T9-o...\n",
      "âœ… h2oGPTe URL configured\n",
      "\n",
      "============================================================\n",
      "Ready to proceed! Run the next cell to start services.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ============================================\n",
    "# ğŸ” API Keys Configuration\n",
    "# ============================================\n",
    "\n",
    "# Required: NVIDIA API Key\n",
    "# Get yours at: https://docs.api.nvidia.com/nim/docs/api-quickstart#interacting-through-python\n",
    "# Steps:\n",
    "#   1. Visit https://build.nvidia.com/explore/discover\n",
    "#   2. Sign in or create NVIDIA account\n",
    "#   3. Go to API Keys section\n",
    "#   4. Generate new API key (starts with \"nvapi-\")\n",
    "#   5. Paste it below\n",
    "os.environ['NVIDIA_API_KEY'] = \"nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # Replace with your actual key\n",
    "\n",
    "# Optional: h2oGPTe Credentials (for AutoML features)\n",
    "# Get yours at: https://h2o.ai/platform/enterprise-h2ogpte/\n",
    "os.environ['APP_H2OGPTE_URL'] = \"\"  # Leave empty if not using\n",
    "os.environ['APP_H2OGPTE_API_KEY'] = \"\"  # Leave empty if not using\n",
    "\n",
    "# ============================================\n",
    "# Verification\n",
    "# ============================================\n",
    "if os.environ.get('NVIDIA_API_KEY') == \"nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" or not os.environ.get('NVIDIA_API_KEY'):\n",
    "    print(\"âš ï¸  WARNING: Please replace the placeholder with your actual NVIDIA API Key!\")\n",
    "    print(\"   ğŸ“š Documentation: https://docs.api.nvidia.com/nim/docs/api-quickstart#interacting-through-python\")\n",
    "    print(\"   ğŸ”‘ Get your key: https://build.nvidia.com/explore/discover\")\n",
    "    print(\"\")\n",
    "    print(\"   Steps:\")\n",
    "    print(\"   1. Visit https://build.nvidia.com/explore/discover\")\n",
    "    print(\"   2. Sign in or create NVIDIA account\")\n",
    "    print(\"   3. Navigate to 'API Keys' section\")\n",
    "    print(\"   4. Generate a new API key\")\n",
    "    print(\"   5. Copy and paste it above (starts with 'nvapi-')\")\n",
    "else:\n",
    "    print(\"âœ… NVIDIA_API_KEY configured\")\n",
    "    print(f\"   Key preview: {os.environ['NVIDIA_API_KEY'][:10]}...\")\n",
    "\n",
    "if os.environ.get('APP_H2OGPTE_URL'):\n",
    "    print(\"âœ… h2oGPTe URL configured\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  h2oGPTe not configured (optional - for AutoML features)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if os.environ.get('NVIDIA_API_KEY') and os.environ.get('NVIDIA_API_KEY') != \"nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\":\n",
    "    print(\"âœ… Ready to proceed! Run the next cell to setup environments.\")\n",
    "else:\n",
    "    print(\"âš ï¸  Please configure NVIDIA_API_KEY before proceeding.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking for required Python virtual environments...\n",
      "\n",
      "âœ… venv found at: /home/ubuntu/tmp-flood-prediction/flood_prediction/core/venv\n",
      "âœ… venv-mcp found at: /home/ubuntu/tmp-flood-prediction/flood_prediction/core/venv-mcp\n",
      "\n",
      "======================================================================\n",
      "âœ… All virtual environments are ready!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================\n",
    "# ğŸ” Check and Setup Python Virtual Environments\n",
    "# ============================================\n",
    "\n",
    "print(\"ğŸ” Checking for required Python virtual environments...\\n\")\n",
    "\n",
    "# Get the directories\n",
    "notebooks_dir = Path.cwd()\n",
    "core_dir = notebooks_dir.parent / \"core\"\n",
    "\n",
    "# Check for venv in multiple locations\n",
    "venv_locations = [\n",
    "    notebooks_dir / \"venv\",\n",
    "    core_dir / \"venv\"\n",
    "]\n",
    "\n",
    "venv_mcp_locations = [\n",
    "    notebooks_dir / \"venv-mcp\",\n",
    "    core_dir / \"venv-mcp\"\n",
    "]\n",
    "\n",
    "# Find existing venvs\n",
    "venv_path = None\n",
    "for loc in venv_locations:\n",
    "    if loc.exists() and (loc / \"bin\" / \"python3\").exists():\n",
    "        venv_path = loc\n",
    "        break\n",
    "\n",
    "venv_mcp_path = None\n",
    "for loc in venv_mcp_locations:\n",
    "    if loc.exists() and (loc / \"bin\" / \"python3\").exists():\n",
    "        venv_mcp_path = loc\n",
    "        break\n",
    "\n",
    "if venv_path:\n",
    "    print(f\"âœ… venv found at: {venv_path}\")\n",
    "else:\n",
    "    print(f\"âŒ venv NOT found\")\n",
    "\n",
    "if venv_mcp_path:\n",
    "    print(f\"âœ… venv-mcp found at: {venv_mcp_path}\")\n",
    "else:\n",
    "    print(f\"âŒ venv-mcp NOT found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if not venv_path or not venv_mcp_path:\n",
    "    print(\"âš™ï¸  SETUP REQUIRED - Running setup script...\\n\")\n",
    "    \n",
    "    # Use the new setup-venvs.sh script\n",
    "    setup_script = notebooks_dir / \"setup-venvs.sh\"\n",
    "    \n",
    "    if setup_script.exists():\n",
    "        print(\"ğŸ“¦ Running './notebooks/setup-venvs.sh' (this may take 5-10 minutes)...\")\n",
    "        print(\"This will create both venv and venv-mcp with all dependencies.\\n\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [str(setup_script)],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                check=True,\n",
    "                cwd=str(notebooks_dir)\n",
    "            )\n",
    "            \n",
    "            print(result.stdout)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"âœ… Virtual environments created successfully!\")\n",
    "            print(\"=\"*70 + \"\\n\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"\\nâŒ Error during setup: {e}\")\n",
    "            print(f\"Output: {e.stdout}\")\n",
    "            print(f\"Error: {e.stderr}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"âŒ setup-venvs.sh not found. Please ensure you have the latest notebook files.\")\n",
    "        print(\"\\nAlternative: If you have the full repo, run from core directory:\")\n",
    "        print(\"  cd ../core\")\n",
    "        print(\"  make setup\")\n",
    "        print(\"  make build\")\n",
    "else:\n",
    "    print(\"âœ… All virtual environments are ready!\")\n",
    "    print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Install Notebook Dependencies\n",
    "\n",
    "Before running the notebook, we need to install Python packages for interacting with the APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for the notebook\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"ğŸ“¦ Installing notebook dependencies...\\n\")\n",
    "\n",
    "packages = [\n",
    "    \"openai\",      # For NVIDIA NIM API\n",
    "    \"requests\",   # For API calls\n",
    "    \"pandas\",      # For data analysis\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "print(\"\\nâœ… All notebook dependencies installed!\")\n",
    "print(\"\\nInstalled packages:\")\n",
    "print(\"  - openai: For NVIDIA NIM integration\")\n",
    "print(\"  - requests: For API communication\")\n",
    "print(\"  - pandas: For data analysis and visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting all services...\n",
      "This may take 30-60 seconds...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Flood Prediction Services Startup\n",
      "=========================================\n",
      "\n",
      "\u001b[1;33mğŸ“¦ Starting services...\u001b[0m\n",
      "\n",
      "1ï¸âƒ£  Starting Redis server...\n",
      "\u001b[0;32mâœ… Redis already running on port 6379\u001b[0m\n",
      "\n",
      "2ï¸âƒ£  Starting MCP Server...\n",
      "\u001b[1;33mâš ï¸  Port 8001 already in use. Stopping existing MCP server...\u001b[0m\n",
      "\u001b[1;33mğŸš€ Starting MCP server on port 8001...\u001b[0m\n",
      "\u001b[1;33mâ³ Waiting for MCP Server to start on port 8001...\u001b[0m\n",
      "\u001b[0;32mâœ… MCP Server is ready!\u001b[0m\n",
      "\n",
      "3ï¸âƒ£  Starting RQ Workers...\n",
      "\u001b[1;33mğŸš€ Starting background worker...\u001b[0m\n",
      "\u001b[0;32mâœ… RQ Worker started (PID: 144496)\u001b[0m\n",
      "\n",
      "4ï¸âƒ£  Starting FastAPI Server...\n",
      "\u001b[1;33mâš ï¸  Port 8000 already in use. Stopping existing server...\u001b[0m\n",
      "\u001b[1;33mğŸš€ Starting FastAPI server on port 8000...\u001b[0m\n",
      "\u001b[1;33mâ³ Waiting for FastAPI Server to start on port 8000...\u001b[0m\n",
      "\u001b[0;32mâœ… FastAPI Server is ready!\u001b[0m\n",
      "\n",
      "=========================================\n",
      "\u001b[0;32mâœ… All Services Started Successfully!\u001b[0m\n",
      "=========================================\n",
      "\n",
      "Service Status:\n",
      "  ğŸ”´ Redis:        http://localhost:6379\n",
      "  ğŸŸ£ MCP Server:   http://localhost:8001\n",
      "  ğŸŸ¢ RQ Worker:    Running (PID: 144496)\n",
      "  ğŸ”µ FastAPI:      http://localhost:8000\n",
      "\n",
      "API Documentation: http://localhost:8000/docs\n",
      "\n",
      "To stop all services, run:\n",
      "  ./notebooks/stop.sh\n",
      "\n",
      "Log files:\n",
      "  MCP Server: notebooks/logs/mcp-server.log\n",
      "  Worker:     notebooks/logs/worker.log\n",
      "  Server:     notebooks/logs/server.log\n",
      "\n",
      "=========================================\n",
      "\n",
      "âœ… All services started successfully!\n",
      "\n",
      "ğŸ“ Service URLs:\n",
      "   - FastAPI Server: http://localhost:8000\n",
      "   - API Docs: http://localhost:8000/docs\n",
      "   - MCP Server: http://localhost:8001\n"
     ]
    }
   ],
   "source": [
    "# Start all services using the run.sh script\n",
    "# This will:\n",
    "# - Start Redis via Docker\n",
    "# - Start MCP Server on port 8001\n",
    "# - Start RQ Workers for background tasks\n",
    "# - Start FastAPI Server on port 8000\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the notebooks directory\n",
    "notebooks_dir = Path.cwd()\n",
    "run_script = notebooks_dir / \"run.sh\"\n",
    "\n",
    "if not run_script.exists():\n",
    "    print(\"âŒ Error: run.sh not found\")\n",
    "    print(\"Please ensure you're running this notebook from the notebooks/ directory\")\n",
    "else:\n",
    "    print(\"ğŸš€ Starting all services...\")\n",
    "    print(\"This may take 30-60 seconds...\\n\")\n",
    "    \n",
    "    # Run the startup script\n",
    "    result = subprocess.run(\n",
    "        [str(run_script)],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        env={**os.environ, 'NVIDIA_API_KEY': os.getenv('NVIDIA_API_KEY')}\n",
    "    )\n",
    "    \n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… All services started successfully!\")\n",
    "        print(\"\\nğŸ“ Service URLs:\")\n",
    "        print(\"   - FastAPI Server: http://localhost:8000\")\n",
    "        print(\"   - API Docs: http://localhost:8000/docs\")\n",
    "        print(\"   - MCP Server: http://localhost:8001\")\n",
    "    else:\n",
    "        print(\"âŒ Error starting services:\")\n",
    "        print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Verify Services\n",
    "\n",
    "Let's check that all services are running correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking service health...\n",
      "\n",
      "âœ… FastAPI Server is running\n",
      "âœ… MCP Server is listening on port 8001\n",
      "âœ… Redis is listening on port 6379\n",
      "\n",
      "==================================================\n",
      "âœ… All services are running correctly!\n",
      "Ready to proceed with the notebook.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def check_service(url, name):\n",
    "    \"\"\"Check if a service is responding\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ… {name} is running\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âš ï¸  {name} responded with status {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ {name} is not responding: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"ğŸ” Checking service health...\\n\")\n",
    "\n",
    "# Check FastAPI server\n",
    "fastapi_ok = check_service(\"http://localhost:8000/api/dashboard\", \"FastAPI Server\")\n",
    "\n",
    "# Check MCP server (it should be running on port 8001)\n",
    "# Note: MCP server may not have a GET endpoint, so we just check if port is open\n",
    "import socket\n",
    "def check_port(port, name):\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('127.0.0.1', port))\n",
    "    sock.close()\n",
    "    if result == 0:\n",
    "        print(f\"âœ… {name} is listening on port {port}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âŒ {name} is not listening on port {port}\")\n",
    "        return False\n",
    "\n",
    "mcp_ok = check_port(8001, \"MCP Server\")\n",
    "redis_ok = check_port(6379, \"Redis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if fastapi_ok and mcp_ok and redis_ok:\n",
    "    print(\"âœ… All services are running correctly!\")\n",
    "    print(\"Ready to proceed with the notebook.\")\n",
    "else:\n",
    "    print(\"âš ï¸  Some services are not running.\")\n",
    "    print(\"Please check the logs in notebooks/logs/\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 2: NVIDIA NIM Integration\n",
    "\n",
    "## ğŸš€ NVIDIA NIM - Optimized Inference Microservices\n",
    "\n",
    "NVIDIA NIM provides high-performance inference for state-of-the-art language models. Our flood prediction system uses several NVIDIA models:\n",
    "\n",
    "### Available Models\n",
    "\n",
    "1. **nvidia/llama-3.3-nemotron-super-49b-v1.5** (Default)\n",
    "   - Latest Nemotron model optimized for instruction following\n",
    "   - Excellent for agent workflows and tool calling\n",
    "   - 49B parameters with superior efficiency\n",
    "\n",
    "2. **meta/llama-3.1-70b-instruct**\n",
    "   - Strong general-purpose reasoning\n",
    "   - Great for complex analysis tasks\n",
    "\n",
    "3. **nvidia/llama-3.1-nemotron-70b-instruct**\n",
    "   - NVIDIA-optimized Llama variant\n",
    "   - Enhanced for enterprise use cases\n",
    "\n",
    "4. **meta/llama-3.1-405b-instruct**\n",
    "   - Used as LLM-as-Judge for evaluation\n",
    "   - Highest reasoning capability\n",
    "\n",
    "### Let's test NVIDIA NIM integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Testing NVIDIA NIM with nvidia/llama-3.3-nemotron-super-49b-v1.5\n",
      "\n",
      "ğŸ“ Response:\n",
      "<think>\n",
      "Okay, so I need to figure out the key factors that indicate an increased risk of flooding in a river basin. Let me start by recalling what I know about flooding and river basins. Flooding happens when a river overflows its banks, right? But why does that happen? I think there are several factors involved.\n",
      "\n",
      "First, rainfall comes to mind. If there's a lot of rain in a short time, the river might not be able to handle the volume, leading to flooding. But how much rain is considered a lot? Maybe it's not just the amount but also the intensity and duration. Like, heavy rainfall over several days versus a quick storm.\n",
      "\n",
      "Then there's the river basin's characteristics. The size and shape of the basin probably matter. A larger basin might collect more water, but maybe a steep basin would cause water to flow faster, increasing the risk of flash floods. Also, the slope of the land. Steeper slopes mean water runs off faster, less chance for infiltration, so more water goes into the river quickly.\n",
      "\n",
      "Soil type is another factor. If the soil is saturated, like after a wet period, it can't absorb more water, so more runoff occurs. Or if the soil is clay-heavy, which doesn't absorb water well, versus sandy soil that does. So soil permeability and saturation levels are important.\n",
      "\n",
      "Vegetation cover. Areas with a lot of trees and plants might absorb more water and reduce runoff because the roots hold the soil and the vegetation intercepts rainfall. So deforestation could increase flood risk by reducing this absorption.\n",
      "\n",
      "Urbanization is a big one. Cities have a lot of impermeable surfaces like concrete and asphalt, which prevent water from soaking into the ground, leading to more runoff into rivers and streams. So more urban areas in a basin might mean higher flood risk.\n",
      "\n",
      "Land use changes in general. If agricultural land is converted to urban, or if there's more construction, that affects runoff. Also, agricultural practices like tilling can affect soil's ability to absorb water.\n",
      "\n",
      "Snowmelt might be a factor in some regions. If there's a lot of snow in the mountains and it melts quickly due to warm temperatures or rain, that can cause a sudden increase in river levels.\n",
      "\n",
      "River channel characteristics. If the river is narrow or has meanders, it might have a lower capacity to carry water. Obstructions like bridges, dams, or debris can also slow down the flow, causing water to back\n",
      "\n",
      "ğŸ“Š Tokens used: 540\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Initialize NVIDIA NIM client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=os.getenv('NVIDIA_API_KEY')\n",
    ")\n",
    "\n",
    "# Test with Nemotron Super 49B\n",
    "model = \"nvidia/llama-3.3-nemotron-super-49b-v1.5\"\n",
    "\n",
    "print(f\"ğŸ¤– Testing NVIDIA NIM with {model}\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert flood prediction assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are the key factors that indicate an increased risk of flooding in a river basin?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"\\nğŸ“Š Tokens used: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Response Example\n",
    "\n",
    "NVIDIA NIM supports streaming for real-time responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒŠ Streaming response about flood prediction...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants to know how AI can improve flood forecasting accuracy. Let me start by breaking down what flood forecasting involves. There's data collection, like rainfall, river levels, soil moisture, and weather patterns. Then there's the modeling part, where they predict how much water will flow where.\n",
      "\n",
      "AI, especially machine learning, can handle large datasets and find patterns that traditional models might miss. Maybe I should mention how AI can process real-time data from various sources like satellites, sensors, and weather stations. That's probably important because more data usually leads to better predictions.\n",
      "\n",
      "I should also think about the different AI techniques. For example, neural networks can model complex relationships between variables. Maybe convolutional neural networks (CNNs) for spatial data like satellite imagery, or recurrent neural networks (RNNs) for time-series data like river levels over time.\n",
      "\n",
      "Another point is handling uncertainty. Flood models have uncertainties in input data and model parameters. AI can use probabilistic models or ensemble methods to quantify uncertainty, which is crucial for decision-making.\n",
      "\n",
      "Also, AI can improve lead times. If the model can predict floods earlier, there's more time for evacuations or flood defenses. How does AI achieve that? Maybe by identifying early warning signs that humans or traditional models might not detect.\n",
      "\n",
      "Integration with existing models. AI doesn't have to replace hydrological models but can work alongside them. For example, using AI to correct biases in physical models or to downscale climate models to local\n",
      "\n",
      "âœ… Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸŒŠ Streaming response about flood prediction...\\n\")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise flood prediction expert.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain how AI can improve flood forecasting accuracy.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\nâœ… Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Let's compare responses from different NVIDIA models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Comparing model responses for:\n",
      "'Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– Model: llama-3.3-nemotron-super-49b-v1.5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's see. The user is asking if they should issue a flood alert given a streamflow of 2500 CFS that's rising at 200 CFS per hour. Hmm, first, I need to recall what the typical thresholds are for flood alerts. I know that different regions have different criteria, but generally, there are standard stages like action stage, flood stage, and so on.\n",
      "\n",
      "Wait, the user didn't specify the location or the specific river, so maybe I should mention that local guidelines are important. But since they want a concise answer, I should probably give a general guideline. Let me think, 2500 CFS is the current flow, and it's increasing rapidly at 200 CFS/hour. That's a significant rate of rise. \n",
      "\n",
      "In many places, a flood watch or warning might be issued when the flow is expected to reach a certain level within a certain time. For example, if the flood stage is at 300\n",
      "\n",
      "ğŸ“ˆ Tokens: 250\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¤– Model: llama-3.1-70b-instruct\n",
      "\n",
      "Streamflow is already high (2500 CFS) and rising rapidly (200 CFS/hour). I recommend issuing a flood alert immediately. The rapid increase in streamflow indicates a high risk of flooding, and prompt action is necessary to protect people and property.\n",
      "\n",
      "ğŸ“ˆ Tokens: 103\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ¤– Model: llama-3.1-nemotron-70b-instruct\n",
      "\n",
      "**Quick Assessment:**\n",
      "\n",
      "* **Current Streamflow:** 2500 CFS (Cubic Feet per Second)\n",
      "* **Trend:** Rising at 200 CFS/hour\n",
      "\n",
      "**Flood Alert Considerations:**\n",
      "\n",
      "1. **Thresholds:**\n",
      "\t* **Action Stage** (e.g., increased monitoring): Typically around 1500-2000 CFS\n",
      "\t* **Flood Warning** (e.g., imminent flooding): Often above 3000-3500 CFS\n",
      "2. **Rate of Rise:** 200 CFS/hour is relatively rapid, indicating increasing flood potential\n",
      "3. **Projected Streamflow:**\n",
      "\t* **1 hour from now:** Approximately 2700 CFS\n",
      "\t* **2 hours from now:** Approximately 2900 CFS\n",
      "\t* **3 hours from now:** Approximately 3100 CFS (potentially exceeding Flood Warning threshold)\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "* **Issue a Flood Watch** immediately, highlighting the rapid\n",
      "\n",
      "ğŸ“ˆ Tokens: 251\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_to_test = [\n",
    "    \"nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
    "    \"meta/llama-3.1-70b-instruct\",\n",
    "    \"nvidia/llama-3.1-nemotron-70b-instruct\"\n",
    "]\n",
    "\n",
    "question = \"Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?\"\n",
    "\n",
    "print(f\"ğŸ“Š Comparing model responses for:\\n'{question}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\nğŸ¤– Model: {model_name.split('/')[-1]}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a flood emergency expert. Be concise.\"},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        print(response.choices[0].message.content)\n",
    "        print(f\"\\nğŸ“ˆ Tokens: {response.usage.total_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-as-Judge Evaluation\n",
    "\n",
    "The system includes an automatic evaluation feature using **cross-provider LLM-as-Judge**:\n",
    "- When NVIDIA models generate responses, h2oGPTe judges them\n",
    "- When h2oGPTe generates responses, NVIDIA models judge them\n",
    "- This provides unbiased evaluation of response quality\n",
    "\n",
    "Let's evaluate the NVIDIA model responses using our evaluation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating NVIDIA model response using LLM-as-Judge...\n",
      "\n",
      "âœ… Evaluation Complete!\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Evaluation Metrics:\n",
      "\n",
      "   ğŸ¯ Overall Score:    6.0/10\n",
      "   ğŸ¤ Helpfulness:      6.0/10\n",
      "   âœ… Accuracy:         4.0/10\n",
      "   ğŸ¯ Relevance:        8.0/10\n",
      "   ğŸ“ Coherence:        8.0/10\n",
      "   ğŸ›¡ï¸  Safety:           7.0/10\n",
      "   ğŸ’ª Confidence:       85.0%\n",
      "\n",
      "ğŸ’­ Judge's Reasoning:\n",
      "   The response is well-structured and directly addresses the question with a clear recommendation. However, it lacks critical context needed for accurate flood prediction - no baseline flow rates, flood stage thresholds, historical data, or watershed characteristics are considered. The response assumes 2500 CFS is 'high' without knowing the specific river's capacity or flood stage. While the precautionary approach is generally safe, the recommendation may be premature without proper context. A more accurate response would request additional information like flood stage levels, normal flow ranges, and local emergency protocols before making definitive alert recommendations.\n",
      "\n",
      "â±ï¸  Evaluation Duration: 8748ms\n",
      "ğŸ†” Evaluation ID: d7a84a48-4ee8-4c3e-8384-31909806381b\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Let's evaluate one of the model responses from above\n",
    "question = \"Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?\"\n",
    "\n",
    "# Response from meta/llama-3.1-70b-instruct (from cell 12)\n",
    "response_text = \"\"\"Streamflow is already high (2500 CFS) and rising rapidly (200 CFS/hour). I recommend issuing a flood alert immediately. The rapid increase in streamflow indicates a high risk of flooding, and prompt action is necessary to protect people and property.\"\"\"\n",
    "\n",
    "print(\"ğŸ” Evaluating NVIDIA model response using LLM-as-Judge...\\n\")\n",
    "\n",
    "# Call the evaluation API\n",
    "eval_payload = {\n",
    "    \"question\": question,\n",
    "    \"response\": response_text,\n",
    "    \"model\": \"meta/llama-3.1-70b-instruct\",\n",
    "    \"agent_used\": False,\n",
    "    \"response_provider\": \"nvidia\"  # This will trigger h2oGPTe as the judge\n",
    "}\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/api/evaluation/evaluate\",\n",
    "    json=eval_payload,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    eval_result = response.json()\n",
    "    \n",
    "    print(\"âœ… Evaluation Complete!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ğŸ“Š Evaluation Metrics:\\n\")\n",
    "    \n",
    "    metrics = eval_result.get('metrics', {})\n",
    "    print(f\"   ğŸ¯ Overall Score:    {metrics.get('overall', 0):.1f}/10\")\n",
    "    print(f\"   ğŸ¤ Helpfulness:      {metrics.get('helpfulness', 0):.1f}/10\")\n",
    "    print(f\"   âœ… Accuracy:         {metrics.get('accuracy', 0):.1f}/10\")\n",
    "    print(f\"   ğŸ¯ Relevance:        {metrics.get('relevance', 0):.1f}/10\")\n",
    "    print(f\"   ğŸ“ Coherence:        {metrics.get('coherence', 0):.1f}/10\")\n",
    "    print(f\"   ğŸ›¡ï¸  Safety:           {metrics.get('safety', 0):.1f}/10\")\n",
    "    print(f\"   ğŸ’ª Confidence:       {metrics.get('confidence', 0):.1%}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’­ Judge's Reasoning:\")\n",
    "    print(f\"   {eval_result.get('reasoning', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  Evaluation Duration: {eval_result.get('duration_ms', 0)}ms\")\n",
    "    print(f\"ğŸ†” Evaluation ID: {eval_result.get('evaluation_id', 'N/A')}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"âŒ Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 3: h2oGPTe Agent (A2A) Integration\n",
    "\n",
    "## ğŸ§  h2oGPTe - Enterprise AI with Agent Mode\n",
    "\n",
    "h2oGPTe provides advanced AutoML capabilities through its agent mode, enabling:\n",
    "\n",
    "- **Driverless AI Integration**: Automated machine learning with minimal code\n",
    "- **Agent-to-Agent (A2A)**: AI agents that can invoke other AI agents\n",
    "- **Feature Engineering**: Automatic feature creation for time-series data\n",
    "- **Model Interpretability**: Explainable AI for emergency response decisions\n",
    "\n",
    "### Setting up h2oGPTe Client\n",
    "\n",
    "**Note**: This section requires h2oGPTe credentials. If you don't have access, you can skip to the next section.\n",
    "\n",
    "Get your credentials at: [H2O.ai Enterprise](https://h2o.ai/platform/enterprise-h2ogpte/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… h2oGPTe credentials found\n",
      "ğŸ”— URL: https://h2ogpte.internal.dedicated.h2o.ai/\n"
     ]
    }
   ],
   "source": [
    "# Check if h2oGPTe credentials are available\n",
    "h2ogpte_url = os.getenv('APP_H2OGPTE_URL', '')\n",
    "h2ogpte_key = os.getenv('APP_H2OGPTE_API_KEY', '')\n",
    "\n",
    "if h2ogpte_url and h2ogpte_key:\n",
    "    print(\"âœ… h2oGPTe credentials found\")\n",
    "    print(f\"ğŸ”— URL: {h2ogpte_url}\")\n",
    "    H2OGPTE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"âš ï¸  h2oGPTe credentials not set\")\n",
    "    print(\"This section will be skipped. To enable:\")\n",
    "    print(\"  export APP_H2OGPTE_URL='<your-url>'\")\n",
    "    print(\"  export APP_H2OGPTE_API_KEY='<your-key>'\")\n",
    "    H2OGPTE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h2oGPTe for Flood Prediction ML\n",
    "\n",
    "Let's use h2oGPTe's agent mode to get guidance on training a flood prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Consulting h2oGPTe agent for AutoML guidance...\n",
      "\n",
      "ğŸ“¡ Provider: h2ogpte\n",
      "ğŸ¤– Model: claude-sonnet-4-20250514\n",
      "\n",
      "ğŸ“ Response:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Agentic Analysis  \n",
      "#### Starting Agent  \n",
      "I'll help you build a comprehensive ML model for flood risk prediction. Let me start by creating a detailed analysis and implementation plan that covers feature engineering, model selection, and best practices for this critical application.\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_analysis.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "import lightgbm as lgb\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "print(\"=== FLOOD PREDICTION MODEL DEVELOPMENT GUIDE ===\\n\")\n",
      "\n",
      "# Create synthetic flood prediction dataset for demonstration\n",
      "np.random.seed(42)\n",
      "n_samples = 5000\n",
      "\n",
      "# Generate realistic flood prediction data\n",
      "data = {\n",
      "    'streamflow_cfs': np.random.lognormal(mean=5, sigma=1.5, size=n_samples),\n",
      "    'rainfall_24h': np.random.exponential(scale=0.8, size=n_samples),\n",
      "    'river_stage_ft': np.random.normal(loc=12, scale=4, size=n_samples),\n",
      "    'soil_moisture': np.random.beta(a=2, b=3, size=n_samples) * 100,\n",
      "    'elevation_ft': np.random.normal(loc=500, scale=200, size=n_samples)\n",
      "}\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Ensure realistic constraints\n",
      "df['river_stage_ft'] = np.clip(df['river_stage_ft'], 2, 35)\n",
      "df['elevation_ft'] = np.clip(df['elevation_ft'], 100, 1500)\n",
      "df['streamflow_cfs'] = np.clip(df['streamflow_cfs'], 10, 50000)\n",
      "\n",
      "print(\"1. DATASET OVERVIEW\")\n",
      "print(\"==================\")\n",
      "print(f\"Dataset shape: {df.shape}\")\n",
      "print(\"\\nFeature statistics:\")\n",
      "print(df.describe())\n",
      "\n",
      "# Create flood risk target based on realistic thresholds\n",
      "def create_flood_risk(row):\n",
      "    # Complex flood risk logic based on multiple factors\n",
      "    risk_score = 0\n",
      "    \n",
      "    # High streamflow increases risk\n",
      "    if row['streamflow_cfs'] > 1000:\n",
      "        risk_score += 2\n",
      "    elif row['streamflow_cfs'] > 500:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # Heavy rainfall increases risk\n",
      "    if row['rainfall_24h'] > 2.0:\n",
      "        risk_score += 2\n",
      "    elif row['rainfall_24h'] > 1.0:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # High river stage increases risk\n",
      "    if row['river_stage_ft'] > 20:\n",
      "        risk_score += 2\n",
      "    elif row['river_stage_ft'] > 15:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # High soil moisture increases risk (saturated ground)\n",
      "    if row['soil_moisture'] > 80:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # Lower elevation increases risk\n",
      "    if row['elevation_ft'] < 300:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # Interaction effects\n",
      "    if row['streamflow_cfs'] > 800 and row['rainfall_24h'] > 1.5:\n",
      "        risk_score += 1\n",
      "    \n",
      "    if row['river_stage_ft'] > 18 and row['soil_moisture'] > 70:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # Convert to binary classification (risk_score >= 3 means flood risk)\n",
      "    return 1 if risk_score >= 3 else 0\n",
      "\n",
      "df['flood_risk_24h'] = df.apply(create_flood_risk, axis=1)\n",
      "\n",
      "print(f\"\\nFlood risk distribution:\")\n",
      "print(df['flood_risk_24h'].value_counts())\n",
      "print(f\"Flood risk percentage: {df['flood_risk_24h'].mean()*100:.1f}%\")\n",
      "\n",
      "# Save the dataset\n",
      "df.to_csv('flood_prediction_data.csv', index=False)\n",
      "print(f\"\\nDataset saved as 'flood_prediction_data.csv'\")\n",
      "```\n",
      "\n",
      "<stream_turn_title>Creating Flood Prediction Dataset and Initial Analysis</stream_turn_title>\n",
      "\n",
      "**LLM Call Info:**\n",
      "\n",
      " Turn Time: 16.12s out of 120s.\n",
      "\n",
      " Turns: 1 out of 20.\n",
      " Time: 16.1 out of 3600.\n",
      " Cost: Turn: $0.0757, Total: $0.0757, Remaining: $489.14.\n",
      "\n",
      "\n",
      "ENDOFTURN\n",
      "\n",
      "\n",
      "**Executing python code blocks**\n",
      "\n",
      "=== FLOOD PREDICTION MODEL DEVELOPMENT GUIDE ===\n",
      "\n",
      "1. DATASET OVERVIEW\n",
      "==================\n",
      "Dataset shape: (5000, 5)\n",
      "\n",
      "Feature statistics:\n",
      "       streamflow_cfs  rainfall_24h  ...  soil_moisture  elevation_ft\n",
      "count     5000.000000   5000.000000  ...    5000.000000   5000.000000\n",
      "mean       462.471294      0.775323  ...      40.456777    498.686097\n",
      "std       1440.280995      0.759004  ...      19.855152    199.186787\n",
      "min         10.000000      0.000042  ...       0.109537    100.000000\n",
      "25%         55.320440      0.231739  ...      25.048815    355.518313\n",
      "50%        151.441382      0.541609  ...      39.101939    496.172178\n",
      "75%        403.031989      1.072618  ...      54.924695    635.064505\n",
      "max      50000.000000      6.420943  ...      95.927866   1245.566669\n",
      "\n",
      "[8 rows x 5 columns]\n",
      "\n",
      "Flood risk distribution:\n",
      "0    4420\n",
      "1     580\n",
      "Name: flood_risk_24h, dtype: int64\n",
      "Flood risk percentage: 11.6%\n",
      "\n",
      "Dataset saved as 'flood_prediction_data.csv'\n",
      "\n",
      "\n",
      "** [Sunday, October 05, 2025 - 11:36:42.5 PM PDT] Completed execution of code block using python in 2.23 seconds after 1 out of 20 turns and time 20.4s out of 3600s and minimum runtime 0s.**\n",
      "\n",
      "ENDOFTURN\n",
      "Now let me continue with the comprehensive feature engineering and model building approach:\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_feature_engineering.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "import lightgbm as lgb\n",
      "from datetime import datetime, timedelta\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Load the dataset\n",
      "df = pd.read_csv('flood_prediction_data.csv')\n",
      "\n",
      "print(\"=== COMPREHENSIVE FEATURE ENGINEERING FOR FLOOD PREDICTION ===\\n\")\n",
      "\n",
      "print(\"2. ADVANCED FEATURE ENGINEERING\")\n",
      "print(\"===============================\")\n",
      "\n",
      "# Create a copy for feature engineering\n",
      "df_features = df.copy()\n",
      "\n",
      "# Add timestamp for time-based features (simulate hourly data)\n",
      "base_time = datetime(2024, 1, 1)\n",
      "df_features['timestamp'] = [base_time + timedelta(hours=i) for i in range(len(df_features))]\n",
      "df_features['hour'] = df_features['timestamp'].dt.hour\n",
      "df_features['day_of_year'] = df_features['timestamp'].dt.dayofyear\n",
      "df_features['month'] = df_features['timestamp'].dt.month\n",
      "\n",
      "print(\"Original features:\", df.columns.tolist())\n",
      "\n",
      "# 1. RATIO AND INTERACTION FEATURES\n",
      "print(\"\\n1. Creating ratio and interaction features...\")\n",
      "\n",
      "# Flow intensity relative to typical conditions\n",
      "df_features['streamflow_log'] = np.log1p(df_features['streamflow_cfs'])\n",
      "df_features['streamflow_zscore'] = (df_features['streamflow_cfs'] - df_features['streamflow_cfs'].mean()) / df_features['streamflow_cfs'].std()\n",
      "\n",
      "# Rainfall intensity categories\n",
      "df_features['rainfall_intensity'] = pd.cut(df_features['rainfall_24h'], \n",
      "                                         bins=[0, 0.1, 0.5, 1.0, 2.0, np.inf], \n",
      "                                         labels=['none', 'light', 'moderate', 'heavy', 'extreme'])\n",
      "df_features['rainfall_intensity_encoded'] = df_features['rainfall_intensity'].cat.codes\n",
      "\n",
      "# River stage relative to elevation (flood depth potential)\n",
      "df_features['stage_elevation_ratio'] = df_features['river_stage_ft'] / (df_features['elevation_ft'] / 100)\n",
      "df_features['elevation_risk_factor'] = np.where(df_features['elevation_ft'] < 300, 2.0,\n",
      "                                               np.where(df_features['elevation_ft'] < 500, 1.5, 1.0))\n",
      "\n",
      "# Soil saturation levels\n",
      "df_features['soil_saturation_level'] = pd.cut(df_features['soil_moisture'], \n",
      "                                             bins=[0, 30, 60, 80, 100], \n",
      "                                             labels=['dry', 'moderate', 'wet', 'saturated'])\n",
      "df_features['soil_saturation_encoded'] = df_features['soil_saturation_level'].cat.codes\n",
      "\n",
      "# 2. COMPOSITE RISK INDICATORS\n",
      "print(\"2. Creating composite risk indicators...\")\n",
      "\n",
      "# Hydrological stress index\n",
      "df_features['hydro_stress_index'] = (\n",
      "    (df_features['streamflow_cfs'] / 1000) * 0.4 +\n",
      "    (df_features['rainfall_24h'] / 3) * 0.3 +\n",
      "    (df_features['river_stage_ft'] / 25) * 0.3\n",
      ")\n",
      "\n",
      "# Vulnerability index (combines elevation and soil factors)\n",
      "df_features['vulnerability_index'] = (\n",
      "    (1 - df_features['elevation_ft'] / df_features['elevation_ft'].max()) * 0.6 +\n",
      "    (df_features['soil_moisture'] / 100) * 0.4\n",
      ")\n",
      "\n",
      "# Combined flood potential score\n",
      "df_features['flood_potential_score'] = (\n",
      "    df_features['hydro_stress_index'] * df_features['vulnerability_index'] * \n",
      "    df_features['elevation_risk_factor']\n",
      ")\n",
      "\n",
      "# 3. ROLLING WINDOW FEATURES (simulating time series)\n",
      "print(\"3. Creating rolling window features...\")\n",
      "\n",
      "# Simulate historical patterns with rolling windows\n",
      "window_sizes = [6, 12, 24]  # 6h, 12h, 24h windows\n",
      "\n",
      "for window in window_sizes:\n",
      "    # Rolling averages\n",
      "    df_features[f'streamflow_rolling_mean_{window}h'] = df_features['streamflow_cfs'].rolling(window=window, min_periods=1).mean()\n",
      "    df_features[f'rainfall_rolling_sum_{window}h'] = df_features['rainfall_24h'].rolling(window=window, min_periods=1).sum()\n",
      "    df_features[f'stage_rolling_max_{window}h'] = df_features['river_stage_ft'].rolling(window=window, min_periods=1).max()\n",
      "    \n",
      "    # Rolling trends\n",
      "    df_features[f'streamflow_trend_{window}h'] = df_features['streamflow_cfs'] - df_features[f'streamflow_rolling_mean_{window}h']\n",
      "    df_features[f'stage_trend_{window}h'] = df_features['river_stage_ft'] - df_features[f'stage_rolling_max_{window}h']\n",
      "\n",
      "# 4. THRESHOLD-BASED FEATURES\n",
      "print(\"4. Creating threshold-based features...\")\n",
      "\n",
      "# Critical threshold indicators\n",
      "df_features['streamflow_critical'] = (df_features['streamflow_cfs'] > 1000).astype(int)\n",
      "df_features['rainfall_heavy'] = (df_features['rainfall_24h'] > 1.5).astype(int)\n",
      "df_features['stage_flood_level'] = (df_features['river_stage_ft'] > 18).astype(int)\n",
      "df_features['soil_saturated'] = (df_features['soil_moisture'] > 75).astype(int)\n",
      "\n",
      "# Multiple threshold breaches\n",
      "df_features['multiple_thresholds_breached'] = (\n",
      "    df_features['streamflow_critical'] + \n",
      "    df_features['rainfall_heavy'] + \n",
      "    df_features['stage_flood_level'] + \n",
      "    df_features['soil_saturated']\n",
      ")\n",
      "\n",
      "# 5. SEASONAL AND TEMPORAL FEATURES\n",
      "print(\"5. Creating seasonal and temporal features...\")\n",
      "\n",
      "# Seasonal patterns\n",
      "df_features['season'] = pd.cut(df_features['month'], \n",
      "                              bins=[0, 3, 6, 9, 12], \n",
      "                              labels=['winter', 'spring', 'summer', 'fall'])\n",
      "df_features['season_encoded'] = df_features['season'].cat.codes\n",
      "\n",
      "# Time of day patterns (floods often occur at specific times)\n",
      "df_features['time_of_day'] = pd.cut(df_features['hour'], \n",
      "                                   bins=[0, 6, 12, 18, 24], \n",
      "                                   labels=['night', 'morning', 'afternoon', 'evening'])\n",
      "df_features['time_of_day_encoded'] = df_features['time_of_day'].cat.codes\n",
      "\n",
      "print(f\"\\nTotal features after engineering: {len(df_features.columns)}\")\n",
      "print(\"New features created:\")\n",
      "new_features = [col for col in df_features.columns if col not in df.columns and col != 'timestamp']\n",
      "for i, feature in enumerate(new_features, 1):\n",
      "    print(f\"{i:2d}. {feature}\")\n",
      "\n",
      "# Save the engineered dataset\n",
      "df_features.to_csv('flood_prediction_engineered.csv', index=False)\n",
      "print(f\"\\nEngineered dataset saved as 'flood_prediction_engineered.csv'\")\n",
      "```\n",
      "\n",
      "**LLM Call Info:**\n",
      "\n",
      " Turn Time: 26.31s out of 120s.\n",
      "\n",
      " Turns: 2 out of 20.\n",
      " Time: 46.7 out of 3600.\n",
      " Cost: Turn: $0.0920, Total: $0.1677, Remaining: $489.05.\n",
      "\n",
      "\n",
      "ENDOFTURN\n",
      "\n",
      "\n",
      "**Executing python code blocks**\n",
      "\n",
      "=== COMPREHENSIVE FEATURE ENGINEERING FOR FLOOD PREDICTION ===\n",
      "\n",
      "2. ADVANCED FEATURE ENGINEERING\n",
      "===============================\n",
      "Original features: ['streamflow_cfs', 'rainfall_24h', 'river_stage_ft', 'soil_moisture', 'elevation_ft', 'flood_risk_24h']\n",
      "\n",
      "1. Creating ratio and interaction features...\n",
      "2. Creating composite risk indicators...\n",
      "3. Creating rolling window features...\n",
      "4. Creating threshold-based features...\n",
      "5. Creating seasonal and temporal features...\n",
      "\n",
      "Total features after engineering: 45\n",
      "New features created:\n",
      " 1. hour\n",
      " 2. day_of_year\n",
      " 3. month\n",
      " 4. streamflow_log\n",
      " 5. streamflow_zscore\n",
      " 6. rainfall_intensity\n",
      " 7. rainfall_intensity_encoded\n",
      " 8. stage_elevation_ratio\n",
      " 9. elevation_risk_factor\n",
      "10. soil_saturation_level\n",
      "11. soil_saturation_encoded\n",
      "12. hydro_stress_index\n",
      "13. vulnerability_index\n",
      "14. flood_potential_score\n",
      "15. streamflow_rolling_mean_6h\n",
      "16. rainfall_rolling_sum_6h\n",
      "17. stage_rolling_max_6h\n",
      "18. streamflow_trend_6h\n",
      "19. stage_trend_6h\n",
      "20. streamflow_rolling_mean_12h\n",
      "21. rainfall_rolling_sum_12h\n",
      "22. stage_rolling_max_12h\n",
      "23. streamflow_trend_12h\n",
      "24. stage_trend_12h\n",
      "25. streamflow_rolling_mean_24h\n",
      "26. rainfall_rolling_sum_24h\n",
      "27. stage_rolling_max_24h\n",
      "28. streamflow_trend_24h\n",
      "29. stage_trend_24h\n",
      "30. streamflow_critical\n",
      "31. rainfall_heavy\n",
      "32. stage_flood_level\n",
      "33. soil_saturated\n",
      "34. multiple_thresholds_breached\n",
      "35. season\n",
      "36. season_encoded\n",
      "37. time_of_day\n",
      "38. time_of_day_encoded\n",
      "\n",
      "Engineered dataset saved as 'flood_prediction_engineered.csv'\n",
      "\n",
      "\n",
      "** [Sunday, October 05, 2025 - 11:37:12.1 PM PDT] Completed execution of code block using python in 1.54 seconds after 2 out of 20 turns and time 50.0s out of 3600s and minimum runtime 0s.**\n",
      "\n",
      "ENDOFTURN\n",
      "Now let me build and evaluate multiple ML models with proper validation techniques:\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_modeling.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
      "import lightgbm as lgb\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Load the engineered dataset\n",
      "df = pd.read_csv('flood_prediction_engineered.csv')\n",
      "\n",
      "print(\"=== FLOOD PREDICTION MODEL BUILDING & EVALUATION ===\\n\")\n",
      "\n",
      "print(\"3. MODEL DEVELOPMENT STRATEGY\")\n",
      "print(\"============================\")\n",
      "\n",
      "# Prepare features for modeling\n",
      "# Remove non-numeric an\n",
      "\n",
      "âœ… Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "if H2OGPTE_AVAILABLE:\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "    # Using FastAPI streaming endpoint for h2oGPTe\n",
    "    url = \"http://localhost:8000/api/ai/chat/enhanced/stream\"\n",
    "    \n",
    "    payload = {\n",
    "        \"message\": \"\"\"I have flood prediction data with these features:\n",
    "        - streamflow_cfs: Current river flow rate\n",
    "        - rainfall_24h: Rainfall in last 24 hours\n",
    "        - river_stage_ft: Water level\n",
    "        - soil_moisture: Ground saturation\n",
    "        - elevation_ft: Location elevation\n",
    "        \n",
    "        How should I approach building an ML model to predict flood risk in the next 24 hours?\n",
    "        What feature engineering would you recommend?\"\"\",\n",
    "        \"provider\": \"h2ogpte\",\n",
    "        \"use_agent\": True,\n",
    "        \"max_tokens\": 8192*10,\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ§  Consulting h2oGPTe agent for AutoML guidance...\\n\")\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        last_content = \"\"\n",
    "        # Stream the response\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                line_str = line.decode('utf-8')\n",
    "                if line_str.startswith('data: '):\n",
    "                    data_str = line_str[6:]  # Remove 'data: ' prefix\n",
    "                    try:\n",
    "                        data = json.loads(data_str)\n",
    "                        \n",
    "                        # First message contains provider info\n",
    "                        if 'provider' in data:\n",
    "                            print(f\"ğŸ“¡ Provider: {data.get('provider')}\")\n",
    "                            print(f\"ğŸ¤– Model: {data.get('model')}\\n\")\n",
    "                            print(\"ğŸ“ Response:\\n\")\n",
    "                        \n",
    "                        # h2oGPTe sends incremental chunks with full content\n",
    "                        elif 'chunk' in data and not data.get('done', False):\n",
    "                            new_content = data['chunk']\n",
    "                            # Only print the new portion\n",
    "                            if new_content.startswith(last_content):\n",
    "                                new_part = new_content[len(last_content):]\n",
    "                                print(new_part, end='', flush=True)\n",
    "                                last_content = new_content\n",
    "                        \n",
    "                        # Check for completion\n",
    "                        elif data.get('done', False):\n",
    "                            break\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "        \n",
    "        print(\"\\n\\nâœ… Streaming complete!\")\n",
    "    else:\n",
    "        print(f\"âŒ Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "else:\n",
    "    print(\"â­ï¸  Skipping h2oGPTe demo (credentials not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 4: Multi-Agent System with FastMCP\n",
    "\n",
    "## ğŸ¤ FastMCP - Model Context Protocol Server\n",
    "\n",
    "Our flood prediction system uses FastMCP to expose 20+ specialized tools across 5 intelligent agents:\n",
    "\n",
    "### The 5 Agents\n",
    "\n",
    "1. **Data Collector Agent** ğŸ“Š\n",
    "   - Collects USGS water data\n",
    "   - Retrieves NOAA flood forecasts\n",
    "   - Gathers weather information\n",
    "   - Monitors data quality\n",
    "\n",
    "2. **Risk Analyzer Agent** âš ï¸\n",
    "   - Calculates flood risk scores\n",
    "   - Analyzes trends and patterns\n",
    "   - Identifies high-risk areas\n",
    "\n",
    "3. **Emergency Responder Agent** ğŸš¨\n",
    "   - Assesses emergency readiness\n",
    "   - Activates alerts\n",
    "   - Coordinates evacuations\n",
    "\n",
    "4. **AI Predictor Agent** ğŸ”®\n",
    "   - Generates flood forecasts\n",
    "   - Predicts critical conditions\n",
    "   - Analyzes prediction accuracy\n",
    "\n",
    "5. **H2OGPTE ML Agent** ğŸ§ \n",
    "   - Trains ML models\n",
    "   - Optimizes features\n",
    "   - Analyzes model performance\n",
    "\n",
    "### Let's explore the available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Available Agents and Their Status\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸŸ¢ Data Collector\n",
      "   Description: Continuously pulls real-time flood data from USGS, NOAA, and weather APIs\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-04T18:36:55.878809+00:00\n",
      "   Check Interval: 300 seconds\n",
      "   Insights: 4\n",
      "\n",
      "ğŸŸ¢ Risk Analyzer\n",
      "   Description: AI-powered analysis of flood risk conditions and trend detection\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-04T18:36:55.878994+00:00\n",
      "   Check Interval: 600 seconds\n",
      "   Insights: 4\n",
      "   Active Alerts: 1\n",
      "\n",
      "ğŸŸ¢ Emergency Responder\n",
      "   Description: Coordinates emergency response activities and manages critical alerts\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-04T18:36:55.879056+00:00\n",
      "   Check Interval: 180 seconds\n",
      "   Insights: 5\n",
      "\n",
      "ğŸŸ¢ AI Predictor\n",
      "   Description: Advanced AI forecasting and predictive analysis for flood conditions\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-04T18:36:55.879255+00:00\n",
      "   Check Interval: 900 seconds\n",
      "   Insights: 4\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get list of all agents and their capabilities\n",
    "response = requests.get(\"http://localhost:8000/api/agents\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"ğŸ¤– Available Agents and Their Status\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # The API returns a nested structure with agents dictionary\n",
    "    agents_dict = data.get('agents', {})\n",
    "    \n",
    "    for agent_key, agent_data in agents_dict.items():\n",
    "        status = \"ğŸŸ¢\" if agent_data.get('is_running') else \"ğŸ”´\"\n",
    "        print(f\"\\n{status} {agent_data.get('name', agent_key)}\")\n",
    "        print(f\"   Description: {agent_data.get('description', 'N/A')}\")\n",
    "        print(f\"   Status: {'Running' if agent_data.get('is_running') else 'Stopped'}\")\n",
    "        if agent_data.get('last_check'):\n",
    "            print(f\"   Last Check: {agent_data.get('last_check')}\")\n",
    "        if agent_data.get('check_interval'):\n",
    "            print(f\"   Check Interval: {agent_data.get('check_interval')} seconds\")\n",
    "        if agent_data.get('insights_count'):\n",
    "            print(f\"   Insights: {agent_data.get('insights_count')}\")\n",
    "        if agent_data.get('active_alerts_count'):\n",
    "            print(f\"   Active Alerts: {agent_data.get('active_alerts_count')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(f\"âŒ Error fetching agents: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Agent Insights\n",
    "\n",
    "Agents continuously monitor flood conditions and generate insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Refreshing USGS data first...\n",
      "\n",
      "âœ… USGS data refresh started\n",
      "â³ Waiting for data refresh to process...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Agent Insights\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– Data Collector\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”µ ğŸ”„ Data Freshness: 100% current\n",
      "\n",
      "ğŸ”µ ğŸŒ API Connectivity: 5/5 active\n",
      "\n",
      "ğŸ”µ ğŸ“Š Data Quality: 9.3/10\n",
      "   Change: +0.0\n",
      "\n",
      "ğŸ”µ âš¡ Update Frequency: 12 updates/hour\n",
      "\n",
      "ğŸ¤– Risk Analyzer\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”µ ğŸ¯ Overall Risk Level: MODERATE (5.0/10)\n",
      "   Change: +0.0\n",
      "\n",
      "ğŸ”µ ğŸš¨ Critical Watersheds: 1 areas\n",
      "\n",
      "ğŸ”µ ğŸ“ˆ Risk Trend Analysis: Stable\n",
      "   Change: 0.0% per hour\n",
      "\n",
      "ğŸ”µ ğŸ§  AI Confidence: 0%\n",
      "   Change: Low\n",
      "\n",
      "ğŸ¤– Emergency Responder\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”µ ğŸš¨ Active Incidents: 0 ongoing\n",
      "\n",
      "ğŸ”µ ğŸš Response Readiness: GOOD (85%)\n",
      "   Change: 8 teams ready\n",
      "\n",
      "ğŸ”µ ğŸƒ Evacuation Status: No active evacuations\n",
      "   Change: 0 zones active\n",
      "\n",
      "ğŸ”µ ğŸ“¡ Communication Systems: 100% operational\n",
      "   Change: 6 channels active\n",
      "\n",
      "ğŸ”µ ğŸ“¢ Alert Distribution: 0 alerts sent\n",
      "   Change: 0 today\n",
      "\n",
      "ğŸ¤– Predictor\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ”µ ğŸ¯ Model Accuracy: 85.0%\n",
      "   Change: +0.0% vs yesterday\n",
      "\n",
      "ğŸ”µ ğŸ§  Prediction Confidence: 72%\n",
      "   Change: High\n",
      "\n",
      "================================================================================\n",
      "Generated at: 2025-10-04T19:47:14.221818+00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Refresh USGS data before getting insights\n",
    "print(\"ğŸ”„ Refreshing USGS data first...\\n\")\n",
    "\n",
    "# Note: Using local-token for development mode (server.py allows this when OIDC is disabled)\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "refresh_response = requests.post(\n",
    "    \"http://localhost:8000/api/dashboard/refresh-usgs-data\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if refresh_response.status_code == 200:\n",
    "    refresh_result = refresh_response.json()\n",
    "    print(f\"âœ… {refresh_result.get('message', 'Data refresh initiated')}\")\n",
    "    \n",
    "    # Wait a moment for background job to start\n",
    "    print(\"â³ Waiting for data refresh to process...\\n\")\n",
    "    time.sleep(3)\n",
    "else:\n",
    "    print(f\"âš ï¸  Data refresh returned status {refresh_response.status_code}\")\n",
    "    print(f\"   Proceeding with existing data...\\n\")\n",
    "\n",
    "# Get insights from all agents\n",
    "response = requests.get(\"http://localhost:8000/api/agents/insights\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"ğŸ’¡ Agent Insights\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # The API returns insights grouped by agent\n",
    "    insights_by_agent = data.get('insights', {})\n",
    "    \n",
    "    count = 0\n",
    "    for agent_name, agent_insights in insights_by_agent.items():\n",
    "        print(f\"\\nğŸ¤– {agent_name.replace('_', ' ').title()}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for insight in agent_insights:\n",
    "            title = insight.get('title', 'N/A')\n",
    "            value = insight.get('value', 'N/A')\n",
    "            change = insight.get('change')\n",
    "            urgency = insight.get('urgency', 'normal')\n",
    "            timestamp = insight.get('timestamp', '')\n",
    "            \n",
    "            urgency_icon = {\n",
    "                'critical': 'ğŸ”´',\n",
    "                'high': 'ğŸŸ¡',\n",
    "                'normal': 'ğŸ”µ',\n",
    "                'low': 'ğŸŸ¢'\n",
    "            }.get(urgency, 'âšª')\n",
    "            \n",
    "            print(f\"\\n{urgency_icon} {title}: {value}\")\n",
    "            if change:\n",
    "                print(f\"   Change: {change}\")\n",
    "            \n",
    "            count += 1\n",
    "            if count >= 15:  # Limit total insights shown\n",
    "                break\n",
    "        \n",
    "        if count >= 15:\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Generated at: {data.get('generated_at', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"âŒ Error fetching insights: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Risk Analyzer Agent\n",
    "\n",
    "Calculates comprehensive flood risk scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Risk Analyzer Agent...\n",
      "\n",
      "ğŸš€ Starting risk_analyzer agent...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "ğŸ’¬ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "Action: comprehensive_flood_analysis_tool\n",
      "Action Input: {\"location\": \"Texas\"}\n",
      "\n",
      "\u001b[39m\n",
      "------------------------------\n",
      "ğŸ’¬ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: comprehensive_flood_analysis_tool\n",
      "\u001b[33mTool's input: {'location': 'Texas'}\n",
      "\u001b[36mTool's response: \n",
      "{\"status\":\"success\",\"location\":\"Texas\",\"analysis_timestamp\":\"2025-10-04T19:47:44.996795+00:00\",\"data_collection\":{\"agent\":\"Data Collector\",\"data_sources\":{\"usgs_sites\":10,\"noaa_alerts\":1,\"weather_locations\":7},\"insights\":[{\"title\":\"ğŸ”„ Data Freshness\",\"value\":\"100% current\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"ğŸŒ API Connectivity\",\"value\":\"5/5 active\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"ğŸ“Š Data Quality\",\"value\":\"9.3/10\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"âš¡ Update Frequency\",\"value\":\"12 updates/hour\",\"trend\":\"stable\",\"urgency\":\"normal\"}],\"alerts\":[]},\"risk_analysis\":{\"agent\":\"Risk Analyzer\",\"insights\":[{\"title\":\"ğŸ¯ Overall Risk Level\",\"value\":\"Unknown (0.0/10)\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"ğŸš¨ Critical Watersheds\",\"value\":\"0 areas\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"ğŸ“ˆ Risk Trend Analysis\",\"value\":\"Insufficient data\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"ğŸ§  AI Confidence\",\"value\":\"0%\",\"trend\":\"stable\",\"urgency\":\"normal\"}],\"alerts\":[]},\"...(rest of response truncated)\u001b[39m\n",
      "------------------------------\n",
      "ğŸ’¬ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "Action: calculate_risk_score_tool\n",
      "Action Input: {\"location\": \"Texas\", \"current_rainfall_mm\": 0, \"forecast_rainfall_mm\": 0, \"elevation_m\": 500, \"distance_to_water_km\": 5, \"population_density\": 1000, \"historical_events\": 5, \"usgs_flow_cfs\": 0, \"river_stage_ft\": 0, \"flood_stage_ft\": 20, \"weather_alerts\": 0}\u001b[39m\n",
      "------------------------------\n",
      "ğŸ’¬ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: calculate_risk_score_tool\n",
      "\u001b[33mTool's input: {'location': 'Texas', 'current_rainfall_mm': 0, 'forecast_rainfall_mm': 0, 'elevation_m': 500, 'distance_to_water_km': 5, 'population_density': 1000, 'historical_events': 5, 'usgs_flow_cfs': 0, 'river_stage_ft': 0, 'flood_stage_ft': 20, 'weather_alerts': 0}\n",
      "\u001b[36mTool's response: \n",
      "{\"status\":\"success\",\"agent\":\"Risk Analyzer\",\"location\":\"Texas\",\"overall_risk_score\":25.0,\"risk_level\":\"Low\",\"risk_color\":\"#90EE90\",\"immediate_risk\":\"Low\",\"component_scores\":{\"likelihood\":{\"total\":0.0,\"rainfall\":0.0,\"river_stage\":0,\"flow_rate\":0,\"alerts\":0.0},\"severity\":{\"total\":25.0,\"elevation\":2.5,\"proximity\":7.5,\"historical\":10,\"population\":5}},\"stage_info\":{\"current_stage_ft\":0.0,\"flood_stage_ft\":20.0,\"percent_of_flood_stage\":0.0},\"timestamp\":\"2025-10-04T19:48:08.922184+00:00\"}\u001b[39m\n",
      "------------------------------\n",
      "ğŸ’¬ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: \n",
      "\n",
      "**Flood Risk Analysis for Texas**  \n",
      "**1. Detailed Risk Scores**  \n",
      "- **Overall Risk Score**: 25.0/100 (**Low Risk**)  \n",
      "- **Component Scores**:  \n",
      "  - **Severity**: 25.0 (Elevation: 2.5, Proximity to Water: 7.5, Historical Events: 10, Population Density: 5)  \n",
      "  - **Likelihood**: 0.0 (Rainfall: 0, River Stage: 0, Flow Rate: 0, Alerts: 0)  \n",
      "\n",
      "**2. Highest Risk Components**  \n",
      "- **Historical Flood Events** (Score: 10/10) â€“ Texas has a documented history of severe flooding.  \n",
      "- **Proximity to Water** (Score: 7.5/10) â€“ Many regions are near rivers/coastlines.  \n",
      "- **Population Density** (Score: 5/10) â€“ Urban areas like Houston amplify potential impact.  \n",
      "\n",
      "**3. Trend Analysis**  \n",
      "- **Current Trend**: Stable (Likelihood factors are negligible due to no active rainfall or river stage threats).  \n",
      "- **Future Risk**: Could escalate rapidly with forecasted heavy rainfall (not currently active).  \n",
      "\n",
      "**4. Recommendations**  \n",
      "- **Immediate Monitoring**: Focus on NOAA weather alerts and USGS river stage updates.  \n",
      "- **Long-Term Preparedness**: Prioritize flood-prone watersheds (e.g., Brazos, Trinity) and urban drainage systems.  \n",
      "- **Public Awareness**: Maintain education campaigns in high-risk zones (e.g., Houston, Corpus Christi).  \n",
      "\n",
      "**Key Insight**: While current risk is low, historical patterns and geographic vulnerabilities necessitate sustained vigilance.\u001b[39m\n",
      "------------------------------\n",
      "\n",
      "================================================================================\n",
      "âœ… Data Collection Complete!\n",
      "\n",
      "**Flood Risk Analysis for Texas**  \n",
      "**1. Detailed Risk Scores**  \n",
      "- **Overall Risk Score**: 25.0/100 (**Low Risk**)  \n",
      "- **Component Scores**:  \n",
      "  - **Severity**: 25.0 (Elevation: 2.5, Proximity to Water: 7.5, Historical Events: 10, Population Density: 5)  \n",
      "  - **Likelihood**: 0.0 (Rainfall: 0, River Stage: 0, Flow Rate: 0, Alerts: 0)  \n",
      "\n",
      "**2. Highest Risk Components**  \n",
      "- **Historical Flood Events** (Score: 10/10) â€“ Texas has a documented history of severe flooding.  \n",
      "- **Proximity to Water** (Score: 7.5/10) â€“ Many regions are near rivers/coastlines.  \n",
      "- **Population Density** (Score: 5/10) â€“ Urban areas like Houston amplify potential impact.  \n",
      "\n",
      "**3. Trend Analysis**  \n",
      "- **Current Trend**: Stable (Likelihood factors are negligible due to no active rainfall or river stage threats).  \n",
      "- **Future Risk**: Could escalate rapidly with forecasted heavy rainfall (not currently active).  \n",
      "\n",
      "**4. Recommendations**  \n",
      "- **Immediate Monitoring**: Focus on NOAA weather alerts and USGS river stage updates.  \n",
      "- **Long-Term Preparedness**: Prioritize flood-prone watersheds (e.g., Brazos, Trinity) and urban drainage systems.  \n",
      "- **Public Awareness**: Maintain education campaigns in high-risk zones (e.g., Houston, Corpus Christi).  \n",
      "\n",
      "**Key Insight**: While current risk is low, historical patterns and geographic vulnerabilities necessitate sustained vigilance.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run Risk Analyzer Agent via NAT\n",
    "import json\n",
    "payload = {\n",
    "    \"agent\": \"risk_analyzer\",\n",
    "    \"message\": \"\"\"Analyze current flood risk for the Texas:\n",
    "    1. Calculate detailed risk scores for all factors\n",
    "    2. Identify the highest risk components\n",
    "    3. Provide trend analysis\n",
    "    4. Give recommendations for monitoring\n",
    "    \n",
    "    Be specific about the risk levels and factors.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Running Risk Analyzer Agent...\\n\")\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/api/nat/chat/stream\",\n",
    "    json=payload,\n",
    "    headers=headers,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    final_output = None\n",
    "    \n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            line_str = line.decode('utf-8')\n",
    "            if line_str.startswith('data: '):\n",
    "                data_str = line_str[6:]  # Remove 'data: ' prefix\n",
    "                try:\n",
    "                    data = json.loads(data_str)\n",
    "                    \n",
    "                    # Handle different event types\n",
    "                    event_type = data.get('type')\n",
    "                    \n",
    "                    if event_type == 'start':\n",
    "                        print(f\"ğŸš€ Starting {data.get('agent_type')} agent...\")\n",
    "                        print()\n",
    "                    \n",
    "                    elif event_type == 'log':\n",
    "                        log_entry = data.get('log', {})\n",
    "                        level = log_entry.get('level', 'INFO')\n",
    "                        message = log_entry.get('message', '')\n",
    "                        \n",
    "                        # Show important logs\n",
    "                        if level in ['WARNING', 'ERROR']:\n",
    "                            print(f\"[{level}] {message}\")\n",
    "                        elif 'Agent' in message or 'Final Answer' in message or 'Tool' in message:\n",
    "                            print(f\"ğŸ’¬ {message}\")\n",
    "                    \n",
    "                    elif event_type == 'result':\n",
    "                        final_output = data.get('output')\n",
    "                        print(\"\\n\" + \"=\"*80)\n",
    "                        print(\"âœ… Data Collection Complete!\\n\")\n",
    "                    \n",
    "                    elif event_type == 'error':\n",
    "                        print(f\"\\nâŒ Error: {data.get('error')}\")\n",
    "                    \n",
    "                    elif event_type == 'done':\n",
    "                        break\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "    \n",
    "    # Display final output\n",
    "    if final_output:\n",
    "        print(final_output)\n",
    "        print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"âŒ Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: H2OGPTE ML Agent\n",
    "\n",
    "AutoML agent for model training and optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run H2OGPTE ML Agent via NAT\n",
    "payload = {\n",
    "    \"agent\": \"h2ogpte_agent\",\n",
    "    \"message\": \"\"\"Help me design an ML pipeline for flood prediction:\n",
    "    1. What features should I engineer from raw sensor data?\n",
    "    2. What model types work best for flood forecasting?\n",
    "    3. How should I handle imbalanced flood event data?\n",
    "    4. What validation strategy is appropriate for time-series?\n",
    "    \n",
    "    Provide actionable AutoML recommendations.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ§  Running H2OGPTE ML Agent...\\n\")\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/nat/chat\", json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"âœ… ML Recommendations Complete!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(result.get('response', result))\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"âŒ Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 6: Real-World Data Integration\n",
    "\n",
    "## ğŸŒ Live Data from Government APIs\n",
    "\n",
    "Our system integrates with real-time data sources:\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "1. **USGS Water Services**\n",
    "   - Real-time streamflow (CFS)\n",
    "   - Gage height (feet)\n",
    "   - 12 monitoring stations in Texas\n",
    "   - Updated every 15 minutes\n",
    "\n",
    "2. **NOAA Weather Service**\n",
    "   - Flood warnings and watches\n",
    "   - Weather alerts\n",
    "   - Forecast data\n",
    "\n",
    "3. **Open-Meteo**\n",
    "   - Weather forecasts\n",
    "   - Flood API predictions\n",
    "   - Historical data\n",
    "\n",
    "### Let's view live watershed data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refresh USGS Data Manually\n",
    "\n",
    "Trigger a fresh data collection from USGS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Triggering USGS data refresh...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒŠ Live Watershed Data\n",
      "\n",
      "====================================================================================================\n",
      "                                                name  current_streamflow_cfs  risk_score  trend_rate_cfs_per_hour        last_updated\n",
      "         Neches River at Evadale, TX (USGS 08041000)                 1000.00         4.0                      0.0 2025-10-04 20:00:07\n",
      "        Red River at Arthur City, TX (USGS 07335500)                 1020.00         4.0                      0.0 2025-10-04 20:00:06\n",
      "      Brazos River near Rosharon, TX (USGS 08116650)                  934.00         3.9                      0.0 2025-10-04 20:00:07\n",
      "         Trinity River at Dallas, TX (USGS 08057000)                  330.00         1.6                      0.0 2025-10-04 20:00:07\n",
      "        Colorado River at Austin, TX (USGS 08158000)                  249.00         1.2                      0.0 2025-10-04 20:00:07\n",
      "    Sabine River near Gladewater, TX (USGS 08020000)                  120.00         0.6                      0.0 2025-10-04 20:00:07\n",
      "      Guadalupe River at Comfort, TX (USGS 08167000)                   53.20         0.5                      0.0 2025-10-04 20:00:07\n",
      "San Antonio River at San Antonio, TX (USGS 08178000)                   11.10         0.5                      0.0 2025-10-04 20:00:07\n",
      "      Pecos River near Sheffield, TX (USGS 08447000)                    6.03         0.5                      0.0 2025-10-04 20:00:07\n",
      "    Canadian River near Amarillo, TX (USGS 07227500)                   41.80         0.5                      0.0 2025-10-04 20:00:06\n",
      "       Llano River near Junction, TX (USGS 08150000)                   61.60         0.5                      0.0 2025-10-04 20:00:07\n",
      "        Nueces River near Mathis, TX (USGS 08211000)                   63.60         0.5                      0.0 2025-10-04 20:00:07\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Total Watersheds Monitored: 12\n",
      "\n",
      "âš ï¸  Risk Distribution:\n",
      "   ğŸ”´ High Risk (>7.0): 0\n",
      "   ğŸŸ¡ Medium Risk (4.0-7.0): 2\n",
      "   ğŸŸ¢ Low Risk (<4.0): 10\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”„ Triggering USGS data refresh...\\n\")\n",
    "header = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/dashboard/refresh-usgs-data\", headers=header    )\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    time.sleep(5)\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Error: {response.status_code}\")\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Get current watershed data\n",
    "response = requests.get(\"http://localhost:8000/api/watersheds\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    watersheds = response.json()\n",
    "    \n",
    "    # Convert to DataFrame for nice display\n",
    "    df = pd.DataFrame(watersheds)\n",
    "    \n",
    "    # Select key columns\n",
    "    display_cols = ['name', 'current_streamflow_cfs', 'risk_score', \n",
    "                    'trend_rate_cfs_per_hour', 'last_updated']\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    \n",
    "    print(\"ğŸŒŠ Live Watershed Data\\n\")\n",
    "    print(\"=\"*100)\n",
    "    print(df[available_cols].to_string(index=False))\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nğŸ“Š Total Watersheds Monitored: {len(watersheds)}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if 'risk_score' in df.columns:\n",
    "        high_risk = len(df[df['risk_score'] > 7.0])\n",
    "        medium_risk = len(df[(df['risk_score'] >= 4.0) & (df['risk_score'] <= 7.0)])\n",
    "        low_risk = len(df[df['risk_score'] < 4.0])\n",
    "        \n",
    "        print(f\"\\nâš ï¸  Risk Distribution:\")\n",
    "        print(f\"   ğŸ”´ High Risk (>7.0): {high_risk}\")\n",
    "        print(f\"   ğŸŸ¡ Medium Risk (4.0-7.0): {medium_risk}\")\n",
    "        print(f\"   ğŸŸ¢ Low Risk (<4.0): {low_risk}\")\n",
    "else:\n",
    "    print(f\"âŒ Error fetching watersheds: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Cleanup\n",
    "\n",
    "## ğŸ›‘ Stopping All Services\n",
    "\n",
    "When you're done with the notebook, stop all running services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "notebooks_dir = Path.cwd()\n",
    "stop_script = notebooks_dir / \"stop.sh\"\n",
    "\n",
    "if stop_script.exists():\n",
    "    print(\"ğŸ›‘ Stopping all services...\\n\")\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        [str(stop_script)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ… All services stopped successfully!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Some services may still be running\")\n",
    "        print(result.stderr)\n",
    "else:\n",
    "    print(\"âŒ stop.sh not found\")\n",
    "    print(\"You can manually stop services:\")\n",
    "    print(\"  - pkill -f 'uvicorn flood_prediction'\")\n",
    "    print(\"  - pkill -f 'mcp_unified_flood_server'\")\n",
    "    print(\"  - pkill -f 'rq worker'\")\n",
    "    print(\"  - docker stop flood-redis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ Summary & Next Steps\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "In this notebook, you've learned how to:\n",
    "\n",
    "âœ… **Set up a multi-agent AI system** for disaster response  \n",
    "âœ… **Integrate h2oGPTe** for AutoML and model training  \n",
    "âœ… **Use NVIDIA NIM** for high-performance inference  \n",
    "âœ… **Build NAT agent workflows** with React patterns  \n",
    "âœ… **Implement FastMCP servers** with custom tools  \n",
    "âœ… **Integrate real-time data** from government APIs  \n",
    "âœ… **Coordinate multiple AI agents** for complex tasks  \n",
    "âœ… **Evaluate responses** using LLM-as-Judge  \n",
    "\n",
    "## Architecture Highlights\n",
    "\n",
    "- **5 Specialized Agents**: Data Collector, Risk Analyzer, Emergency Responder, Predictor, H2OGPTE ML\n",
    "- **20+ MCP Tools**: Via FastMCP server on port 8001\n",
    "- **NVIDIA NIM Models**: Nemotron Super 49B, Llama 3.1 variants\n",
    "- **h2oGPTe A2A**: Agent-to-agent AutoML capabilities\n",
    "- **Real-time Data**: USGS, NOAA, Weather APIs\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **NVIDIA NIM**: [build.nvidia.com](https://build.nvidia.com)\n",
    "- **h2oGPTe**: [h2o.ai/platform/enterprise-h2ogpte](https://h2o.ai/platform/enterprise-h2ogpte/)\n",
    "- **NVIDIA NAT**: [docs.nvidia.com/nat](https://docs.nvidia.com/nat)\n",
    "- **FastMCP**: [github.com/jlowin/fastmcp](https://github.com/jlowin/fastmcp)\n",
    "- **USGS Water Data**: [waterdata.usgs.gov](https://waterdata.usgs.gov)\n",
    "- **NOAA Weather**: [weather.gov](https://weather.gov)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Customize Agents**: Modify agent configs for your specific use case\n",
    "2. **Add Data Sources**: Integrate additional APIs and sensors\n",
    "3. **Train ML Models**: Use h2oGPTe to train production models\n",
    "4. **Deploy to Production**: Use Docker/Kubernetes deployment\n",
    "5. **Monitor Performance**: Add logging and metrics\n",
    "\n",
    "## Contributing\n",
    "\n",
    "This is an open-source AI for Good project. Contributions welcome!\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒŠ Thank you for exploring the Flood Prediction Blueprint!\n",
    "\n",
    "**Built with â¤ï¸ using h2oGPTe and NVIDIA NIM**\n",
    "\n",
    "For questions and support, please open an issue in the repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
