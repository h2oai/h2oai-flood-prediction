{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI-Powered Flood Prediction System with h2oGPTe and NVIDIA NIM\n",
    "\n",
    "[![Deploy on NVIDIA](https://img.shields.io/badge/Deploy%20on-NVIDIA%20AI%20Blueprints-76B900?logo=nvidia&logoColor=white)](https://build.nvidia.com)\n",
    "[![H2O.ai](https://img.shields.io/badge/Powered%20by-H2O.ai-FFD500)](https://h2o.ai)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåä Overview\n",
    "\n",
    "This blueprint demonstrates an **AI-powered flood prediction and disaster response system** that combines:\n",
    "\n",
    "- **h2oGPTe Agent-to-Agent (A2A)**: Advanced AutoML capabilities with Driverless AI for model training and feature engineering\n",
    "- **NVIDIA NIM**: State-of-the-art inference with `nvidia/llama-3.3-nemotron-super-49b-v1.5` and other NVIDIA models\n",
    "- **NVIDIA NAT Pipeline**: React Agent workflows for multi-agent orchestration\n",
    "- **FastMCP Server**: 20+ specialized tools across 5 intelligent agents\n",
    "- **Real-time Data Integration**: USGS Water Services, NOAA Forecasts, and Weather APIs\n",
    "\n",
    "### üéØ Use Case: AI for Good - Disaster Response\n",
    "\n",
    "This system provides:\n",
    "- **Real-time flood monitoring** with live data from watersheds and monitoring stations\n",
    "- **AI-powered risk assessment** using advanced machine learning models\n",
    "- **Emergency response coordination** with automated alerts and evacuation planning\n",
    "- **Predictive analytics** for flood forecasting 24-72 hours ahead\n",
    "- **AutoML model training** for continuous improvement of prediction accuracy\n",
    "\n",
    "### üèóÔ∏è Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                      Flood Prediction System                     ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n",
    "‚îÇ  ‚îÇ   h2oGPTe    ‚îÇ  ‚îÇ  NVIDIA NIM  ‚îÇ  ‚îÇ  FastMCP     ‚îÇ         ‚îÇ\n",
    "‚îÇ  ‚îÇ  (A2A Mode)  ‚îÇ  ‚îÇ  (Nemotron)  ‚îÇ  ‚îÇ   Server     ‚îÇ         ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n",
    "‚îÇ         ‚îÇ                 ‚îÇ                 ‚îÇ                   ‚îÇ\n",
    "‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n",
    "‚îÇ                  ‚îÇ                 ‚îÇ                            ‚îÇ\n",
    "‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ         ‚îÇ    NVIDIA NAT Agent Pipeline      ‚îÇ                  ‚îÇ\n",
    "‚îÇ         ‚îÇ      (React Agent Workflow)       ‚îÇ                  ‚îÇ\n",
    "‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                  ‚îÇ                                              ‚îÇ\n",
    "‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ\n",
    "‚îÇ    ‚îÇ    5 Specialized Agents   ‚îÇ                               ‚îÇ\n",
    "‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                               ‚îÇ\n",
    "‚îÇ    ‚îÇ  1. Data Collector        ‚îÇ ‚óÑ‚îÄ‚îÄ USGS Water Data           ‚îÇ\n",
    "‚îÇ    ‚îÇ  2. Risk Analyzer         ‚îÇ ‚óÑ‚îÄ‚îÄ NOAA Flood Alerts         ‚îÇ\n",
    "‚îÇ    ‚îÇ  3. Emergency Responder   ‚îÇ ‚óÑ‚îÄ‚îÄ Weather APIs              ‚îÇ\n",
    "‚îÇ    ‚îÇ  4. AI Predictor          ‚îÇ                               ‚îÇ\n",
    "‚îÇ    ‚îÇ  5. H2OGPTE ML Agent      ‚îÇ                               ‚îÇ\n",
    "‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  Output: Real-time Monitoring, Alerts, Predictions, ML Models  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üîë Key Technologies\n",
    "\n",
    "1. **h2oGPTe**: Enterprise AI platform with agent mode for AutoML and advanced analytics\n",
    "2. **NVIDIA NIM**: Optimized inference microservices for AI models\n",
    "3. **NVIDIA NAT**: Agent orchestration framework with React-based workflows\n",
    "4. **FastMCP**: Model Context Protocol server for tool integration\n",
    "5. **FastAPI**: High-performance API server for real-time operations\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "- Setting up multi-agent AI systems for disaster response\n",
    "- Integrating h2oGPTe for AutoML and model training\n",
    "- Using NVIDIA NIM for high-performance inference\n",
    "- Building NAT agent workflows with React patterns\n",
    "- Implementing FastMCP servers with custom tools\n",
    "- Real-time data integration from government APIs\n",
    "- Coordinating multiple AI agents for complex tasks\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Prerequisites\n",
    "\n",
    "Before running this setup, make sure you have:\n",
    "\n",
    "### Required:\n",
    "- ‚úÖ **NVIDIA API Key** - Get it from [build.nvidia.com](https://build.nvidia.com)\n",
    "  - This key is used for NVIDIA NIM models and services\n",
    "\n",
    "### Optional (but recommended):\n",
    "- üîπ **H2OGPTE API Key** - For AutoML and advanced AI features\n",
    "  - Get access at [h2o.ai](https://h2o.ai/platform/enterprise-h2ogpte/)\n",
    "  - If you don't have this, you can skip it - the app will still work with reduced features\n",
    "\n",
    "---\n",
    "\n",
    "Ready? Let's collect your API keys! üîê"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Dependencies\n",
    "\n",
    "Please restart the kernel after this step. Do not repeat this step after restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "!{python} -m ensurepip --upgrade\n",
    "!{python} -m pip install --upgrade pip setuptools wheel\n",
    "!{python} -m pip install --upgrade --force-reinstall pandas openai requests python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîê Step 1: Collect API Keys\n",
    "\n",
    "Run the cells below to securely enter your API keys. Your inputs will be hidden for security.\n",
    "\n",
    "### What you'll provide:\n",
    "1. **NVIDIA API Key** (required)\n",
    "2. **H2OGPTE API Key** (optional)\n",
    "3. **H2OGPTE URL** (optional, default provided)\n",
    "\n",
    "**Note**: Ports are pre-configured in this Launchable (8090 for Web UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import getpass\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Enter your NVIDIA API Key\n",
      "   Get it from: https://build.nvidia.com or https://catalog.ngc.nvidia.com/\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NVIDIA API Key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NVIDIA API Key collected successfully!\n",
      "   Preview: nvapi-hR2s...o3QS\n"
     ]
    }
   ],
   "source": [
    "# Collect NVIDIA API Key (Required)\n",
    "print(\"üîë Enter your NVIDIA API Key\")\n",
    "print(\"   Get it from: https://build.nvidia.com or https://catalog.ngc.nvidia.com/\")\n",
    "print()\n",
    "\n",
    "nvidia_api_key = getpass.getpass(\"NVIDIA API Key: \")\n",
    "\n",
    "if not nvidia_api_key or nvidia_api_key.strip() == \"\":\n",
    "    raise ValueError(\n",
    "        \"‚ùå NVIDIA API Key is required! Please run this cell again and provide the key.\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ NVIDIA API Key collected successfully!\")\n",
    "print(f\"   Preview: {nvidia_api_key[:10]}...{nvidia_api_key[-4:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Enter your NGC API Key\n",
      "   Get it from: https://catalog.ngc.nvidia.com/\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NGC API Key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NGC API Key collected successfully!\n",
      "   Preview: nvapi-aoBi...R1Ep\n"
     ]
    }
   ],
   "source": [
    "# Collect NGC API Key (Optional)\n",
    "print(\"üîë Enter your NGC API Key\")\n",
    "print(\"   Get it from: https://catalog.ngc.nvidia.com/\")\n",
    "print()\n",
    "\n",
    "ngc_api_key = getpass.getpass(\"NGC API Key: \")\n",
    "\n",
    "if not ngc_api_key or ngc_api_key.strip() == \"\":\n",
    "    print(\"‚ö†Ô∏è  No API key provided, skipping Local NIM LLM setup\")\n",
    "else:\n",
    "    print(\"‚úÖ NGC API Key collected successfully!\")\n",
    "    print(f\"   Preview: {ngc_api_key[:10]}...{ngc_api_key[-4:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ H2OGPTE Configuration (Optional)\n",
      "   H2OGPTE provides advanced AutoML and AI agent capabilities\n",
      "   If you don't have access, just press Enter to skip\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you have H2OGPTE access? (yes/no) [no]:  yes\n",
      "H2OGPTE URL [https://h2ogpte.cloud-dev.h2o.dev]:  \n",
      "H2OGPTE API Key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ H2OGPTE configured successfully!\n",
      "   URL: https://h2ogpte.cloud-dev.h2o.dev\n",
      "   API Key Preview: sk-ktl41qb...tiqB\n"
     ]
    }
   ],
   "source": [
    "# Collect H2OGPTE Credentials (Optional)\n",
    "print(\"ü§ñ H2OGPTE Configuration (Optional)\")\n",
    "print(\"   H2OGPTE provides advanced AutoML and AI agent capabilities\")\n",
    "print(\"   If you don't have access, just press Enter to skip\")\n",
    "print()\n",
    "\n",
    "use_h2ogpte = input(\"Do you have H2OGPTE access? (yes/no) [no]: \").strip().lower()\n",
    "\n",
    "if use_h2ogpte in [\"yes\", \"y\"]:\n",
    "    h2ogpte_url = input(\"H2OGPTE URL [https://h2ogpte.cloud-dev.h2o.dev]: \").strip()\n",
    "    h2ogpte_api_key = getpass.getpass(\"H2OGPTE API Key: \")\n",
    "\n",
    "    if not h2ogpte_url:\n",
    "        h2ogpte_url = \"https://h2ogpte.cloud-dev.h2o.dev\"\n",
    "\n",
    "    if not h2ogpte_api_key or h2ogpte_api_key.strip() == \"\":\n",
    "        print(\"‚ö†Ô∏è  No API key provided, skipping H2OGPTE setup\")\n",
    "        h2ogpte_api_key = \"\"\n",
    "        h2ogpte_url = \"\"\n",
    "    else:\n",
    "        print(f\"‚úÖ H2OGPTE configured successfully!\")\n",
    "        print(f\"   URL: {h2ogpte_url}\")\n",
    "        print(f\"   API Key Preview: {h2ogpte_api_key[:10]}...{h2ogpte_api_key[-4:]}\")\n",
    "else:\n",
    "    h2ogpte_api_key = \"\"\n",
    "    h2ogpte_url = \"https://h2ogpte.cloud-dev.h2o.dev\"\n",
    "    print(\"‚è≠Ô∏è  Skipping H2OGPTE setup - application will run with NVIDIA NIM only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Step 2: Generate Configuration File\n",
    "\n",
    "Now we'll create the environment configuration file with all the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper function created successfully!\n"
     ]
    }
   ],
   "source": [
    "def create_env_file(\n",
    "    nvidia_api_key,\n",
    "    ngc_api_key,\n",
    "    h2ogpte_api_key,\n",
    "    h2ogpte_url,\n",
    "    output_path=\"./flood_prediction.env\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create the environment configuration file for the Flood Prediction application.\n",
    "\n",
    "    Parameters:\n",
    "    - nvidia_api_key: NVIDIA API key (used for both NVIDIA_API_KEY)\n",
    "    - ngc_api_key: NGC API key (used for NGC_API_KEY)\n",
    "    - h2ogpte_api_key: H2OGPTE API key (can be empty string if not used)\n",
    "    - h2ogpte_url: H2OGPTE service URL\n",
    "    - output_path: Where to save the env file\n",
    "\n",
    "    Note: Ports are pre-configured in the Launchable:\n",
    "    - WEB_PORT: 8090 (fixed)\n",
    "    \"\"\"\n",
    "\n",
    "    env_content = f\"\"\"# ==============================================================================\n",
    "# API KEYS\n",
    "# ==============================================================================\n",
    "\n",
    "NVIDIA_API_KEY={nvidia_api_key}\n",
    "NGC_API_KEY={ngc_api_key}\n",
    "H2OGPTE_API_KEY={h2ogpte_api_key}\n",
    "\n",
    "# ==============================================================================\n",
    "# H2OGPTE CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# H2OGPTE service URL\n",
    "H2OGPTE_URL={h2ogpte_url}\n",
    "\n",
    "# H2OGPTE model to use\n",
    "H2OGPTE_MODEL=claude-sonnet-4-20250514\n",
    "\n",
    "# ==============================================================================\n",
    "# WEB APPLICATION IMAGE CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "WEB_IMAGE_REGISTRY=h2oairelease\n",
    "WEB_IMAGE_REPOSITORY=h2oai-floodprediction-app\n",
    "WEB_IMAGE_TAG=v1.0.0\n",
    "\n",
    "WEB_PORT=8090\n",
    "\n",
    "# ==============================================================================\n",
    "# REDIS CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "REDIS_IMAGE_REGISTRY=docker.io\n",
    "REDIS_IMAGE_REPOSITORY=redis\n",
    "REDIS_IMAGE_TAG=8.2.1\n",
    "\n",
    "REDIS_ENABLED=true\n",
    "\n",
    "# ==============================================================================\n",
    "# NVIDIA NIM LLM CONFIGURATION (Optional)\n",
    "# ==============================================================================\n",
    "\n",
    "NIMLLM_IMAGE=nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5:1.12.0\n",
    "\n",
    "NIMLLM_PORT=8989\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Write to file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(env_content)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Generating environment configuration file...\n",
      "\n",
      "‚úÖ Configuration file created successfully!\n",
      "   Location: /home/nvidia/h2oai-flood-prediction-agent/notebooks/flood_prediction.env\n",
      "\n",
      "üìã Configuration Summary:\n",
      "   NVIDIA API Key: nvapi-hR2s...o3QS\n",
      "   H2OGPTE API Key: sk-ktl41qb...tiqB\n",
      "   H2OGPTE URL: https://h2ogpte.cloud-dev.h2o.dev\n",
      "\n",
      "üîå Pre-configured Ports:\n",
      "   Web UI Port: 8090 (fixed)\n"
     ]
    }
   ],
   "source": [
    "# Generate the environment file\n",
    "print(\"üî® Generating environment configuration file...\")\n",
    "print()\n",
    "\n",
    "env_file_path = create_env_file(\n",
    "    nvidia_api_key=nvidia_api_key,\n",
    "    ngc_api_key=ngc_api_key,\n",
    "    h2ogpte_api_key=h2ogpte_api_key,\n",
    "    h2ogpte_url=h2ogpte_url,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration file created successfully!\")\n",
    "print(f\"   Location: {os.path.abspath(env_file_path)}\")\n",
    "print()\n",
    "print(\"üìã Configuration Summary:\")\n",
    "print(f\"   NVIDIA API Key: {nvidia_api_key[:10]}...{nvidia_api_key[-4:]}\")\n",
    "if h2ogpte_api_key:\n",
    "    print(f\"   H2OGPTE API Key: {h2ogpte_api_key[:10]}...{h2ogpte_api_key[-4:]}\")\n",
    "    print(f\"   H2OGPTE URL: {h2ogpte_url}\")\n",
    "else:\n",
    "    print(\"   H2OGPTE: Not configured (optional)\")\n",
    "print()\n",
    "print(\"üîå Pre-configured Ports:\")\n",
    "print(\"   Web UI Port: 8090 (fixed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"./flood_prediction.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üê≥ Step 3: Pull Docker Images\n",
    "\n",
    "Now we'll authenticate with Docker registries and pull the required images.\n",
    "\n",
    "This may take 5-10 minutes depending on your connection speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull WEB APPLICATION IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.0.0: Pulling from h2oairelease/h2oai-floodprediction-app\n",
      "Digest: sha256:9aafbdba37ad48cd9d7fd02a8e8f30cfa2ea349e3bf6e976892818e6190ee0c9\n",
      "Status: Image is up to date for h2oairelease/h2oai-floodprediction-app:v1.0.0\n",
      "docker.io/h2oairelease/h2oai-floodprediction-app:v1.0.0\n"
     ]
    }
   ],
   "source": [
    "!docker pull h2oairelease/h2oai-floodprediction-app:v1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                             TAG       IMAGE ID       CREATED        SIZE\n",
      "h2oairelease/h2oai-floodprediction-app                 v1.0.0    92070ae047ee   2 hours ago    1.84GB\n",
      "redis                                                  8.2.1     0d85a7a7167b   2 months ago   137MB\n",
      "nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5   1.12.0    efe42d99222d   2 months ago   24.4GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - If Nvidia H200 GPU or equivalent is available, Deploy a local NIM LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if Nvidia Drivers are installed and GPU is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA H200 (UUID: GPU-7ab83f00-d006-9544-be64-b8eb9a64acfd)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authenticate Docker with NGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!echo \"${NGC_API_KEY}\" | docker login nvcr.io -u '$oauthtoken' --password-stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull Nvidia NIM LLM Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5:1.12.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The image is defined in the env file as NIMLLM_IMAGE\n",
    "\n",
    "nim_llm_image = os.getenv(\"NIMLLM_IMAGE\", \"nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5:1.12.0\")\n",
    "nim_llm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0: Pulling from nim/nvidia/llama-3_3-nemotron-super-49b-v1_5\n",
      "Digest: sha256:06af8d8467217fd6f344a53cc37ba2d1d234cb98d918b1ecdf85bf1c16854262\n",
      "Status: Image is up to date for nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5:1.12.0\n",
      "nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5:1.12.0\n"
     ]
    }
   ],
   "source": [
    "# pull image\n",
    "\n",
    "!docker pull \"${NIMLLM_IMAGE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                             TAG       IMAGE ID       CREATED        SIZE\n",
      "h2oairelease/h2oai-floodprediction-app                 v1.0.0    92070ae047ee   2 hours ago    1.84GB\n",
      "redis                                                  8.2.1     0d85a7a7167b   2 months ago   137MB\n",
      "nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5   1.12.0    efe42d99222d   2 months ago   24.4GB\n"
     ]
    }
   ],
   "source": [
    "# check available images\n",
    "\n",
    "!docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the application using Docker Compose\n",
    "\n",
    "Run only one of the `docker compose` commands below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy with a local NVIDIA NIM LLM - **Only if NVIDIA GPU is available and NIM LLM Image was successfully pulled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 2/4\n",
      " \u001b[32m‚úî\u001b[0m Network flood-prediction-network   \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      " \u001b[33m‚†ã\u001b[0m Container flood-prediction-redis   Starting                             \u001b[34m0.1s \u001b[0m\n",
      " \u001b[33m‚†ã\u001b[0m Container flood-prediction-nimllm  Starting                             \u001b[34m0.1s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-web     \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/4\n",
      " \u001b[32m‚úî\u001b[0m Network flood-prediction-network   \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      " \u001b[33m‚†ô\u001b[0m Container flood-prediction-redis   Starting                             \u001b[34m0.2s \u001b[0m\n",
      " \u001b[33m‚†ô\u001b[0m Container flood-prediction-nimllm  Starting                             \u001b[34m0.2s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-web     \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 3/4\n",
      " \u001b[32m‚úî\u001b[0m Network flood-prediction-network   \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-redis   \u001b[32mStarted\u001b[0m                              \u001b[34m0.2s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-nimllm  \u001b[32mStarted\u001b[0m                              \u001b[34m0.3s \u001b[0m\n",
      " \u001b[33m‚†ô\u001b[0m Container flood-prediction-web     Starting                             \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 3/4\n",
      " \u001b[32m‚úî\u001b[0m Network flood-prediction-network   \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-redis   \u001b[32mStarted\u001b[0m                              \u001b[34m0.2s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-nimllm  \u001b[32mStarted\u001b[0m                              \u001b[34m0.3s \u001b[0m\n",
      " \u001b[33m‚†π\u001b[0m Container flood-prediction-web     Starting                             \u001b[34m0.3s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 4/4\u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Network flood-prediction-network   \u001b[32mCreated\u001b[0m                              \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-redis   \u001b[32mStarted\u001b[0m                              \u001b[34m0.2s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-nimllm  \u001b[32mStarted\u001b[0m                              \u001b[34m0.3s \u001b[0m\n",
      " \u001b[32m‚úî\u001b[0m Container flood-prediction-web     \u001b[32mStarted\u001b[0m                              \u001b[34m0.4s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker compose -f ./docker-compose.yml -f ./docker-compose.nimllm.yml --env-file ./flood_prediction.env up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If not using local NVIDIA NIM LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker compose -f ./docker-compose.yml --env-file ./flood_prediction.env up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for all containers to be healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                                         COMMAND                  CREATED         STATUS                   PORTS                    NAMES\n",
      "f53268dd2a4f   h2oairelease/h2oai-floodprediction-app:v1.0.0                 \"./docker-entrypoint‚Ä¶\"   3 minutes ago   Up 3 minutes (healthy)   0.0.0.0:8090->8000/tcp   flood-prediction-web\n",
      "dc8b512df0c3   nvcr.io/nim/nvidia/llama-3_3-nemotron-super-49b-v1_5:1.12.0   \"/opt/nvidia/nvidia_‚Ä¶\"   3 minutes ago   Up 3 minutes (healthy)   0.0.0.0:8989->8000/tcp   flood-prediction-nimllm\n",
      "a01a67a99196   redis:8.2.1                                                   \"docker-entrypoint.s‚Ä¶\"   3 minutes ago   Up 3 minutes (healthy)   6379/tcp                 flood-prediction-redis\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the deployed containers. Wait till the STATUS is healthy\n",
    "\n",
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_key(value: str) -> str:\n",
    "    if not value:\n",
    "        return \"Not set\"\n",
    "    if len(value) <= 14:\n",
    "        return f\"{value[:4]}{'.' * len(value) - 4}\"\n",
    "    dots = max(1, len(value) - 14)\n",
    "    return f\"{value[:10]}{'.' * dots}{value[-4:]}\"\n",
    "\n",
    "def check_service(path, name, headers=None):\n",
    "    url = f\"{base_url}/{path.lstrip('/')}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        print(f\"‚ùå {name} is not responding: {exc}\")\n",
    "        return False\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ {name} is running\")\n",
    "        return True\n",
    "    if response.status_code == 401:\n",
    "        print(f\"‚ö†Ô∏è  {name} requires authentication (401)\")\n",
    "        return True\n",
    "\n",
    "    print(f\"‚ö†Ô∏è  {name} responded with status {response.status_code}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NVIDIA_API_KEY: nvapi-hR2s........................................................o3QS\n",
      "‚úÖ H2OGPTE_URL: https://h2ogpte.cloud-dev.h2o.dev\n",
      "‚úÖ H2OGPTE_API_KEY: sk-ktl41qb.....................................tiqB\n",
      "‚úÖ h2oGPTe credentials found\n",
      "‚úÖ API_SERVER_URL detected: http://localhost:8090\n"
     ]
    }
   ],
   "source": [
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "if NVIDIA_API_KEY:\n",
    "    print(f\"‚úÖ NVIDIA_API_KEY: {preview_key(NVIDIA_API_KEY)}\")\n",
    "else:\n",
    "    print(f\"‚ùó NVIDIA_API_KEY NOT SET\")\n",
    "\n",
    "H2OGPTE_URL = os.getenv(\"H2OGPTE_URL\")\n",
    "if H2OGPTE_URL:\n",
    "    print(f\"‚úÖ H2OGPTE_URL: {H2OGPTE_URL}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è H2OGPTE_URL NOT SET\")\n",
    "\n",
    "H2OGPTE_API_KEY = os.getenv(\"H2OGPTE_API_KEY\")\n",
    "if H2OGPTE_API_KEY:\n",
    "    print(f\"‚úÖ H2OGPTE_API_KEY: {preview_key(H2OGPTE_API_KEY)}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è H2OGPTE_API_KEY NOT SET\")\n",
    "\n",
    "if H2OGPTE_URL and H2OGPTE_API_KEY:\n",
    "    print(\"‚úÖ h2oGPTe credentials found\")\n",
    "    H2OGPTE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  h2oGPTe credentials not set\")\n",
    "    print(\"This section will be skipped. To enable:\")\n",
    "    print(\"  export H2OGPTE_URL='<your-url>'\")\n",
    "    print(\"  export H2OGPTE_API_KEY='<your-key>'\")\n",
    "    H2OGPTE_AVAILABLE = False\n",
    "\n",
    "api_port = os.getenv(\"WEB_PORT\")\n",
    "if not api_port:\n",
    "    print(\"‚ö†Ô∏è WEB_PORT not set. API interactions will be skipped.\")\n",
    "\n",
    "api_server_base_url = os.getenv(\"API_SERVER_URL\", f\"http://localhost:{api_port}\")\n",
    "if api_server_base_url:\n",
    "    print(f\"‚úÖ API_SERVER_URL detected: {api_server_base_url}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è API_SERVER_URL not set. API interactions will be skipped.\")\n",
    "\n",
    "# Set this to False Here.\n",
    "# Later, we will verify that a Local NIM LLM is deployed and is reachable. If yes, we will set this to True\n",
    "LOCAL_NIM_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Service Endpoints:\n",
      "   - FastAPI Server: http://localhost:8090\n",
      "   - API Docs: http://localhost:8090/docs\n",
      "   - Agents API: http://localhost:8090/api/agents\n",
      "\n",
      "Use the next cell to verify service health.\n"
     ]
    }
   ],
   "source": [
    "if not api_server_base_url:\n",
    "    print(\"‚ö†Ô∏è  API_SERVER_URL not set. Export API_SERVER_URL before continuing.\")\n",
    "else:\n",
    "    base_url = api_server_base_url.rstrip('/')\n",
    "    print(\"üìç Service Endpoints:\")\n",
    "    print(f\"   - FastAPI Server: {base_url}\")\n",
    "    print(f\"   - API Docs: {base_url}/docs\")\n",
    "    print(f\"   - Agents API: {base_url}/api/agents\")\n",
    "    print(\"\\nUse the next cell to verify service health.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Verify Services\n",
    "\n",
    "Let's check that all services are running correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking service health...\n",
      "\n",
      "‚úÖ FastAPI Dashboard is running\n",
      "‚úÖ Agents API is running\n",
      "‚úÖ Watersheds API is running\n",
      "\n",
      "==================================================\n",
      "‚úÖ All services are responding!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Checking service health...\\n\")\n",
    "\n",
    "if not api_server_base_url:\n",
    "    print(\"‚ö†Ô∏è  API_SERVER_URL not set. Skipping health checks.\")\n",
    "    fastapi_ok = False\n",
    "else:\n",
    "    base_url = api_server_base_url.rstrip('/')\n",
    "\n",
    "    fastapi_ok = check_service('api/dashboard', 'FastAPI Dashboard')\n",
    "    agents_ok = check_service('api/agents', 'Agents API', headers={'Authorization': 'Bearer local-token'})\n",
    "    watersheds_ok = check_service('api/watersheds', 'Watersheds API')\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    if fastapi_ok and agents_ok and watersheds_ok:\n",
    "        print(\"‚úÖ All services are responding!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  One or more endpoints did not respond as expected.\")\n",
    "        print(\"Review Helm deployment status or API logs if needed.\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that a Local NIM LLM is deployed and is reachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:8989/v1'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the base url for NIM\n",
    "nimllm_port = os.getenv(\"NIMLLM_PORT\", \"8989\")\n",
    "nim_llm_base_url = f\"http://localhost:{nimllm_port}/v1\"\n",
    "nim_llm_base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Local NIM LLM is running\n"
     ]
    }
   ],
   "source": [
    "# Test if the NIM container is up. This will take 10 to 15 mins. Repeat this step until you see a positive message.\n",
    "if nim_llm_base_url:\n",
    "    response = requests.get(f\"{nim_llm_base_url}/models\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Local NIM LLM is running\")\n",
    "        LOCAL_NIM_AVAILABLE = True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No locally deployed NIM LLM is found. Will be using NIMs via API.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No locally deployed NIM LLM is found. Will be using NIMs via API.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 2: NVIDIA NIM Integration\n",
    "\n",
    "## üöÄ NVIDIA NIM - Optimized Inference Microservices\n",
    "\n",
    "NVIDIA NIM provides high-performance inference for state-of-the-art language models. Our flood prediction system uses several NVIDIA models:\n",
    "\n",
    "### Available Models\n",
    "\n",
    "1. **nvidia/llama-3.3-nemotron-super-49b-v1.5** (Default)\n",
    "   - Latest Nemotron model optimized for instruction following\n",
    "   - Excellent for agent workflows and tool calling\n",
    "   - 49B parameters with superior efficiency\n",
    "\n",
    "2. **meta/llama-3.1-70b-instruct**\n",
    "   - Strong general-purpose reasoning\n",
    "   - Great for complex analysis tasks\n",
    "\n",
    "### Let's test NVIDIA NIM integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local NIM LLM base URL: http://localhost:8989/v1\n"
     ]
    }
   ],
   "source": [
    "# Initialize NVIDIA NIM client\n",
    "\n",
    "USE_NVIDIA_API = False\n",
    "\n",
    "if LOCAL_NIM_AVAILABLE:\n",
    "    print(f\"Using local NIM LLM base URL: {nim_llm_base_url}\")\n",
    "    model = \"nvidia/llama-3_3-nemotron-super-49b-v1_5\"\n",
    "    client = OpenAI(\n",
    "        base_url=nim_llm_base_url,\n",
    "        api_key=\"no-key\",\n",
    "    )\n",
    "else:\n",
    "\n",
    "    USE_NVIDIA_API = True\n",
    "\n",
    "    # Test with Nemotron Super 49B\n",
    "    model = \"nvidia/llama-3.3-nemotron-super-49b-v1.5\"\n",
    "\n",
    "    # From Nvidia API\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=NVIDIA_API_KEY,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Testing NVIDIA NIM with nvidia/llama-3_3-nemotron-super-49b-v1_5\n",
      "\n",
      "üìù Response:\n",
      "<think>\n",
      "Okay, so I need to figure out the key factors that indicate an increased risk of flooding in a river basin. Let me start by recalling what I know about floods and river basins. A river basin is the area of land that drains water into a particular river and its tributaries. Flooding occurs when the river can't hold the amount of water it's receiving, leading to overflow.\n",
      "\n",
      "First, I think about precipitation. Heavy rainfall over a short period or prolonged rain can cause rivers to rise quickly. But how much rain is considered heavy? Maybe it's relative to the area's normal climate. Also, if the ground is already saturated from previous rain, even moderate rainfall could lead to flooding because the soil can't absorb more water.\n",
      "\n",
      "Then there's the topography of the river basin. Steep slopes might lead to faster runoff, meaning water flows quickly into the river, increasing the chance of a sudden rise in water levels. In contrast, flat areas might have slower runoff, but if the river is already high, that could still contribute to flooding. The shape of the basin might matter too‚Äîlike if it's narrow, water might accumulate faster.\n",
      "\n",
      "Land use and cover are probably important. Urban areas with lots of impermeable surfaces like concrete and asphalt prevent water from soaking into the ground, leading to more runoff. Deforestation could reduce the land's ability to absorb water and increase erosion, which might affect river flow. Agriculture might have different impacts depending on practices like terracing or drainage.\n",
      "\n",
      "River characteristics themselves. If a river is narrow or has meanders, it might have a lower capacity to hold water. Obstructions like bridges, dams, or debris can block flow, causing water to back up. Dams can actually help control flooding if managed properly, but if they fail or release water suddenly, that's a risk.\n",
      "\n",
      "Climate change might be a factor. Rising temperatures could lead to more intense rainfall events in some regions. Also, warmer air holds more moisture, which could increase precipitation amounts. Changes in snowmelt patterns‚Äîif a basin relies on snowpack, earlier melting could cause earlier and more intense flooding.\n",
      "\n",
      "Human activities like urbanization, which I mentioned before, but also things like building in floodplains. If people construct homes or infrastructure in areas that are prone to flooding, the risk increases both in likelihood and impact. Poor drainage systems in cities can exacerbate flooding.\n",
      "\n",
      "Soil type is another aspect. Sandy soils absorb water better than clay\n",
      "\n",
      "üìä Tokens used: 540\n"
     ]
    }
   ],
   "source": [
    "print(f\"ü§ñ Testing NVIDIA NIM with {model}\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert flood prediction assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are the key factors that indicate an increased risk of flooding in a river basin?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"üìù Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"\\nüìä Tokens used: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Response Example\n",
    "\n",
    "NVIDIA NIM supports streaming for real-time responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Streaming response about flood prediction...\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking how AI can improve flood forecasting accuracy. Let me start by breaking down the key areas where AI applies here. First, AI can process large datasets quickly. Flood forecasting involves a lot of variables like rainfall, river levels, soil moisture, etc. Traditional models might struggle with the volume and complexity, but AI can handle that.\n",
      "\n",
      "Machine learning models, especially neural networks, can find non-linear patterns that humans or traditional statistical models might miss. For example, LSTM networks are good for time-series data, which is relevant for predicting water levels over time. Then there's the integration of multiple data sources. AI can combine data from satellites, rain gauges, weather radars, and even social media reports. This multi-source data fusion probably leads to more accurate predictions.\n",
      "\n",
      "Real-time data processing is another point. AI can analyze real-time data streams and update forecasts more frequently. This is crucial because flood situations can change rapidly. Also, AI can optimize existing hydrological models by adjusting parameters automatically, which might improve their accuracy.\n",
      "\n",
      "Uncertainty quantification is important too. AI models can provide confidence intervals for their predictions, helping authorities understand the reliability of the forecast. Then there's the use of AI for early warning systems. By predicting floods earlier, authorities can take preventive measures, which saves lives and reduces damage.\n",
      "\n",
      "I should also mention specific AI techniques like CNNs for satellite imagery analysis, which can detect changes in land use or identify flood-prone areas. Reinforcement\n",
      "\n",
      "‚úÖ Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"üåä Streaming response about flood prediction...\\n\")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise flood prediction expert.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain how AI can improve flood forecasting accuracy.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\n‚úÖ Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Let's compare responses from different NVIDIA models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Comparing model responses for:\n",
      "'Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ü§ñ Model: llama-3_3-nemotron-super-49b-v1_5\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "**Flood Alert Assessment**\n",
      "\n",
      "To provide a concise answer, I'll need to make a few assumptions since specific details about the stream, location, and flood stage thresholds aren't provided. Typically, the decision to issue a flood alert depends on:\n",
      "\n",
      "1. **Current Streamflow (CFS)**: 2500 CFS\n",
      "2. **Rate of Change**: Rising at 200 CFS/hour\n",
      "3. **Flood Stage Thresholds** (assuming, as not provided):\n",
      "   - **Action Stage**: Typically set to alert for potential flooding.\n",
      "   - **Flood Stage**: The level at which flooding is expected.\n",
      "\n",
      "**Assumed Flood Stage Thresholds for Illustration Purposes:**\n",
      "\n",
      "- **Action Stage**: 3000 CFS\n",
      "- **Flood Stage**: 4000 CFS\n",
      "\n",
      "**Analysis:**\n",
      "\n",
      "- **Current Situation**: Streamflow is at 2500 CFS, which is below both the assumed action and flood stages.\n",
      "\n",
      "\n",
      "üìà Tokens: 250\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if USE_NVIDIA_API:\n",
    "    models_to_test = [\n",
    "        \"nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
    "        \"meta/llama-3.1-70b-instruct\"\n",
    "    ]\n",
    "else:\n",
    "    models_to_test = [model]\n",
    "\n",
    "question = \"Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?\"\n",
    "\n",
    "print(f\"üìä Comparing model responses for:\\n'{question}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\nü§ñ Model: {model_name.split('/')[-1]}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a flood emergency expert. Be concise.\"},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        print(response.choices[0].message.content)\n",
    "        print(f\"\\nüìà Tokens: {response.usage.total_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-as-Judge Evaluation\n",
    "\n",
    "The system includes an automatic evaluation feature using **cross-provider LLM-as-Judge**:\n",
    "- When NVIDIA models generate responses, h2oGPTe judges them\n",
    "- When h2oGPTe generates responses, NVIDIA models judge them\n",
    "- This provides unbiased evaluation of response quality\n",
    "\n",
    "Let's evaluate the NVIDIA model responses using our evaluation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating NVIDIA model response using LLM-as-Judge...\n",
      "\n",
      "‚úÖ Evaluation Complete!\n",
      "\n",
      "================================================================================\n",
      "üìä Evaluation Metrics:\n",
      "\n",
      "   üéØ Overall Score:    6.0/10\n",
      "   ü§ù Helpfulness:      6.0/10\n",
      "   ‚úÖ Accuracy:         4.0/10\n",
      "   üéØ Relevance:        8.0/10\n",
      "   üìù Coherence:        8.0/10\n",
      "   üõ°Ô∏è  Safety:           7.0/10\n",
      "   üí™ Confidence:       85.0%\n",
      "\n",
      "üí≠ Judge's Reasoning:\n",
      "   The response is well-structured and directly addresses the question with appropriate urgency. However, it lacks critical context - flood thresholds vary dramatically by location, watershed characteristics, and baseline conditions. 2500 CFS could be normal flow for a large river or extreme flooding for a small stream. The response assumes high risk without considering flood stage levels, historical data, or local thresholds. While the precautionary approach is generally safe, making definitive recommendations without proper context could lead to unnecessary evacuations or alert fatigue. The response would benefit from requesting additional watershed-specific information before making alert recommendations.\n",
      "\n",
      "‚è±Ô∏è  Evaluation Duration: 7998ms\n",
      "üÜî Evaluation ID: fa3a4e73-9afb-4c4a-b69a-2fa59a1aa070\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's evaluate one of the model responses from above\n",
    "question = \"Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?\"\n",
    "\n",
    "# Response from meta/llama-3.1-70b-instruct (from cell 12)\n",
    "response_text = \"\"\"Streamflow is already high (2500 CFS) and rising rapidly (200 CFS/hour). I recommend issuing a flood alert immediately. The rapid increase in streamflow indicates a high risk of flooding, and prompt action is necessary to protect people and property.\"\"\"\n",
    "\n",
    "print(\"üîç Evaluating NVIDIA model response using LLM-as-Judge...\\n\")\n",
    "\n",
    "# Call the evaluation API\n",
    "eval_payload = {\n",
    "    \"question\": question,\n",
    "    \"response\": response_text,\n",
    "    \"model\": \"meta/llama-3.1-70b-instruct\",\n",
    "    \"agent_used\": False,\n",
    "    \"response_provider\": \"nvidia\"  # This will trigger h2oGPTe as the judge\n",
    "}\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "response = requests.post(\n",
    "    f\"{api_server_base_url}/api/evaluation/evaluate\",\n",
    "    json=eval_payload,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    eval_result = response.json()\n",
    "    \n",
    "    print(\"‚úÖ Evaluation Complete!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìä Evaluation Metrics:\\n\")\n",
    "    \n",
    "    metrics = eval_result.get('metrics', {})\n",
    "    print(f\"   üéØ Overall Score:    {metrics.get('overall', 0):.1f}/10\")\n",
    "    print(f\"   ü§ù Helpfulness:      {metrics.get('helpfulness', 0):.1f}/10\")\n",
    "    print(f\"   ‚úÖ Accuracy:         {metrics.get('accuracy', 0):.1f}/10\")\n",
    "    print(f\"   üéØ Relevance:        {metrics.get('relevance', 0):.1f}/10\")\n",
    "    print(f\"   üìù Coherence:        {metrics.get('coherence', 0):.1f}/10\")\n",
    "    print(f\"   üõ°Ô∏è  Safety:           {metrics.get('safety', 0):.1f}/10\")\n",
    "    print(f\"   üí™ Confidence:       {metrics.get('confidence', 0):.1%}\")\n",
    "    \n",
    "    print(f\"\\nüí≠ Judge's Reasoning:\")\n",
    "    print(f\"   {eval_result.get('reasoning', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Evaluation Duration: {eval_result.get('duration_ms', 0)}ms\")\n",
    "    print(f\"üÜî Evaluation ID: {eval_result.get('evaluation_id', 'N/A')}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 3: h2oGPTe Agent (A2A) Integration\n",
    "\n",
    "## üß† h2oGPTe - Enterprise AI with Agent Mode\n",
    "\n",
    "h2oGPTe provides advanced AutoML capabilities through its agent mode, enabling:\n",
    "\n",
    "- **Driverless AI Integration**: Automated machine learning with minimal code\n",
    "- **Agent-to-Agent (A2A)**: AI agents that can invoke other AI agents\n",
    "- **Feature Engineering**: Automatic feature creation for time-series data\n",
    "- **Model Interpretability**: Explainable AI for emergency response decisions\n",
    "\n",
    "### Setting up h2oGPTe Client\n",
    "\n",
    "**Note**: This section requires h2oGPTe credentials. If you don't have access, you can skip to the next section.\n",
    "\n",
    "Get your credentials at: [H2O.ai Enterprise](https://h2o.ai/platform/enterprise-h2ogpte/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h2oGPTe for Flood Prediction ML\n",
    "\n",
    "Let's use h2oGPTe's agent mode to get guidance on training a flood prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Consulting h2oGPTe agent for AutoML guidance...\n",
      "\n",
      "üì° Provider: h2ogpte\n",
      "ü§ñ Model: claude-sonnet-4-20250514\n",
      "\n",
      "üìù Response:\n",
      "\n",
      "#### Agentic Analysis  \n",
      "#### Starting Agent  \n",
      "I'll help you build a comprehensive ML model for flood risk prediction. Let me start by analyzing your data structure and then provide recommendations for feature engineering and model development.\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_analysis.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Set up plotting style\n",
      "plt.style.use('default')\n",
      "sns.set_palette(\"husl\")\n",
      "\n",
      "print(\"=== FLOOD PREDICTION MODEL DEVELOPMENT GUIDE ===\\n\")\n",
      "\n",
      "# First, let's create a synthetic dataset that represents your flood prediction scenario\n",
      "# This will help demonstrate the approach and feature engineering techniques\n",
      "np.random.seed(42)\n",
      "n_samples = 5000\n",
      "\n",
      "print(\"1. CREATING SYNTHETIC FLOOD DATASET FOR DEMONSTRATION\")\n",
      "print(\"=\" * 60)\n",
      "\n",
      "# Generate realistic flood prediction data\n",
      "data = {\n",
      "    'streamflow_cfs': np.random.lognormal(mean=3, sigma=1, size=n_samples),\n",
      "    'rainfall_24h': np.random.exponential(scale=0.5, size=n_samples),\n",
      "    'river_stage_ft': np.random.normal(loc=8, scale=3, size=n_samples),\n",
      "    'soil_moisture': np.random.beta(a=2, b=2, size=n_samples),\n",
      "    'elevation_ft': np.random.normal(loc=500, scale=200, size=n_samples)\n",
      "}\n",
      "\n",
      "# Ensure realistic ranges\n",
      "data['streamflow_cfs'] = np.clip(data['streamflow_cfs'], 10, 50000)\n",
      "data['rainfall_24h'] = np.clip(data['rainfall_24h'], 0, 10)\n",
      "data['river_stage_ft'] = np.clip(data['river_stage_ft'], 2, 25)\n",
      "data['soil_moisture'] = np.clip(data['soil_moisture'], 0, 1)\n",
      "data['elevation_ft'] = np.clip(data['elevation_ft'], 100, 1500)\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Create flood risk target based on realistic thresholds\n",
      "# Higher risk when: high streamflow, high rainfall, high river stage, high soil moisture, low elevation\n",
      "flood_risk_score = (\n",
      "    (df['streamflow_cfs'] / df['streamflow_cfs'].max()) * 0.3 +\n",
      "    (df['rainfall_24h'] / df['rainfall_24h'].max()) * 0.25 +\n",
      "    (df['river_stage_ft'] / df['river_stage_ft'].max()) * 0.25 +\n",
      "    df['soil_moisture'] * 0.15 +\n",
      "    (1 - df['elevation_ft'] / df['elevation_ft'].max()) * 0.05\n",
      ")\n",
      "\n",
      "# Add some noise and create binary target\n",
      "flood_risk_score += np.random.normal(0, 0.1, n_samples)\n",
      "df['flood_risk_24h'] = (flood_risk_score > 0.6).astype(int)\n",
      "\n",
      "print(f\"Dataset created with {len(df)} samples\")\n",
      "print(f\"Flood risk distribution: {df['flood_risk_24h'].value_counts().to_dict()}\")\n",
      "print(f\"Flood risk rate: {df['flood_risk_24h'].mean():.3f}\")\n",
      "\n",
      "# Display basic statistics\n",
      "print(\"\\n2. BASIC DATASET STATISTICS\")\n",
      "print(\"=\" * 40)\n",
      "print(df.describe())\n",
      "\n",
      "# Check for missing values and data quality\n",
      "print(f\"\\nMissing values per column:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "print(f\"\\nData types:\")\n",
      "print(df.dtypes)\n",
      "\n",
      "# Save the synthetic dataset for reference\n",
      "df.to_csv('flood_prediction_data.csv', index=False)\n",
      "print(f\"\\nSynthetic dataset saved as 'flood_prediction_data.csv'\")\n",
      "```\n",
      "\n",
      "<stream_turn_title>Creating Synthetic Flood Dataset and Basic Analysis</stream_turn_title>\n",
      "\n",
      "**LLM Call Info:**\n",
      "\n",
      " Turn Time: 17.48s out of 120s.\n",
      "\n",
      " Turns: 1 out of 20.\n",
      " Time: 17.5 out of 3600.\n",
      " Cost: Turn: $0.1071, Total: $0.1071, Remaining: $475.06.\n",
      "\n",
      "\n",
      "ENDOFTURN\n",
      "\n",
      "\n",
      "**Executing python code blocks**\n",
      "\n",
      "=== FLOOD PREDICTION MODEL DEVELOPMENT GUIDE ===\n",
      "\n",
      "1. CREATING SYNTHETIC FLOOD DATASET FOR DEMONSTRATION\n",
      "============================================================\n",
      "Dataset created with 5000 samples\n",
      "Flood risk distribution: {0: 4995, 1: 5}\n",
      "Flood risk rate: 0.001\n",
      "\n",
      "2. BASIC DATASET STATISTICS\n",
      "========================================\n",
      "       streamflow_cfs  rainfall_24h  ...  elevation_ft  flood_risk_24h\n",
      "count     5000.000000   5000.000000  ...   5000.000000      5000.00000\n",
      "mean        34.151620      0.484577  ...    498.808038         0.00100\n",
      "std         44.383381      0.474377  ...    198.862276         0.03161\n",
      "min         10.000000      0.000026  ...    100.000000         0.00000\n",
      "25%         10.403008      0.144837  ...    355.913323         0.00000\n",
      "50%         20.357832      0.338505  ...    496.262014         0.00000\n",
      "75%         39.095627      0.670386  ...    634.768324         0.00000\n",
      "max       1018.654285      4.013089  ...   1245.566669         1.00000\n",
      "\n",
      "[8 rows x 6 columns]\n",
      "\n",
      "Missing values per column:\n",
      "streamflow_cfs    0\n",
      "rainfall_24h      0\n",
      "river_stage_ft    0\n",
      "soil_moisture     0\n",
      "elevation_ft      0\n",
      "flood_risk_24h    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "streamflow_cfs    float64\n",
      "rainfall_24h      float64\n",
      "river_stage_ft    float64\n",
      "soil_moisture     float64\n",
      "elevation_ft      float64\n",
      "flood_risk_24h      int64\n",
      "dtype: object\n",
      "\n",
      "Synthetic dataset saved as 'flood_prediction_data.csv'\n",
      "\n",
      "\n",
      "** [Monday, October 20, 2025 - 03:08:00.9 PM PDT] Completed execution of code block using python in 2.26 seconds after 1 out of 20 turns and time 20.5s out of 3600s and minimum runtime 0s.**\n",
      "\n",
      "ENDOFTURN\n",
      "I notice the synthetic data has an extremely imbalanced target (only 0.1% flood risk). Let me create a more realistic dataset and then provide comprehensive feature engineering and modeling recommendations.\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_comprehensive.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "from sklearn.feature_selection import SelectKBest, f_classif\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "print(\"=== COMPREHENSIVE FLOOD PREDICTION MODEL GUIDE ===\\n\")\n",
      "\n",
      "# Create a more realistic flood dataset with better class balance\n",
      "np.random.seed(42)\n",
      "n_samples = 5000\n",
      "\n",
      "print(\"1. CREATING REALISTIC FLOOD DATASET\")\n",
      "print(\"=\" * 50)\n",
      "\n",
      "# Generate base features with more realistic flood scenarios\n",
      "data = {\n",
      "    'streamflow_cfs': np.random.lognormal(mean=4, sigma=1.2, size=n_samples),\n",
      "    'rainfall_24h': np.random.exponential(scale=0.8, size=n_samples),\n",
      "    'river_stage_ft': np.random.normal(loc=10, scale=4, size=n_samples),\n",
      "    'soil_moisture': np.random.beta(a=2, b=3, size=n_samples),\n",
      "    'elevation_ft': np.random.normal(loc=400, scale=150, size=n_samples)\n",
      "}\n",
      "\n",
      "# Ensure realistic ranges\n",
      "data['streamflow_cfs'] = np.clip(data['streamflow_cfs'], 50, 100000)\n",
      "data['rainfall_24h'] = np.clip(data['rainfall_24h'], 0, 8)\n",
      "data['river_stage_ft'] = np.clip(data['river_stage_ft'], 3, 30)\n",
      "data['soil_moisture'] = np.clip(data['soil_moisture'], 0, 1)\n",
      "data['elevation_ft'] = np.clip(data['elevation_ft'], 100, 1000)\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "print(\"2. FEATURE ENGINEERING - CREATING DERIVED FEATURES\")\n",
      "print(\"=\" * 55)\n",
      "\n",
      "# FEATURE ENGINEERING RECOMMENDATIONS:\n",
      "\n",
      "# A) Ratio and Interaction Features\n",
      "df['flow_to_stage_ratio'] = df['streamflow_cfs'] / (df['river_stage_ft'] + 1)\n",
      "df['rainfall_soil_interaction'] = df['rainfall_24h'] * df['soil_moisture']\n",
      "df['elevation_stage_diff'] = df['elevation_ft'] - df['river_stage_ft']\n",
      "\n",
      "# B) Threshold-based Features\n",
      "df['high_flow_flag'] = (df['streamflow_cfs'] > df['streamflow_cfs'].quantile(0.8)).astype(int)\n",
      "df['heavy_rain_flag'] = (df['rainfall_24h'] > df['rainfall_24h'].quantile(0.75)).astype(int)\n",
      "df['saturated_soil_flag'] = (df['soil_moisture'] > 0.7).astype(int)\n",
      "df['critical_stage_flag'] = (df['river_stage_ft'] > df['river_stage_ft'].quantile(0.85)).astype(int)\n",
      "\n",
      "# C) Normalized Features (z-scores)\n",
      "scaler = StandardScaler()\n",
      "normalized_features = ['streamflow_cfs', 'rainfall_24h', 'river_stage_ft']\n",
      "for feature in normalized_features:\n",
      "    df[f'{feature}_normalized'] = scaler.fit_transform(df[[feature]]).flatten()\n",
      "\n",
      "# D) Logarithmic Transformations (for skewed distributions)\n",
      "df['log_streamflow'] = np.log1p(df['streamflow_cfs'])\n",
      "df['log_rainfall'] = np.log1p(df['rainfall_24h'])\n",
      "\n",
      "# E) Binned Features\n",
      "df['elevation_category'] = pd.cut(df['elevation_ft'], \n",
      "                                 bins=[0, 200, 400, 600, 1000], \n",
      "                                 labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n",
      "df['elevation_category'] = df['elevation_category'].cat.codes\n",
      "\n",
      "# F) Composite Risk Scores\n",
      "df['hydrological_risk'] = (\n",
      "    0.4 * (df['streamflow_cfs'] / df['streamflow_cfs'].max()) +\n",
      "    0.3 * (df['rainfall_24h'] / df['rainfall_24h'].max()) +\n",
      "    0.3 * (df['river_stage_ft'] / df['river_stage_ft'].max())\n",
      ")\n",
      "\n",
      "df['vulnerability_score'] = (\n",
      "    0.6 * df['soil_moisture'] +\n",
      "    0.4 * (1 - df['elevation_ft'] / df['elevation_ft'].max())\n",
      ")\n",
      "\n",
      "# Create more realistic flood risk target\n",
      "flood_risk_score = (\n",
      "    0.25 * (df['streamflow_cfs'] / df['streamflow_cfs'].max()) +\n",
      "    0.20 * (df['rainfall_24h'] / df['rainfall_24h'].max()) +\n",
      "    0.20 * (df['river_stage_ft'] / df['river_stage_ft'].max()) +\n",
      "    0.15 * df['soil_moisture'] +\n",
      "    0.10 * (1 - df['elevation_ft'] / df['elevation_ft'].max()) +\n",
      "    0.10 * df['rainfall_soil_interaction']\n",
      ")\n",
      "\n",
      "# Add seasonal and random effects\n",
      "seasonal_effect = 0.1 * np.sin(2 * np.pi * np.arange(n_samples) / 365)\n",
      "random_noise = np.random.normal(0, 0.15, n_samples)\n",
      "flood_risk_score += seasonal_effect + random_noise\n",
      "\n",
      "# Create binary target with better balance\n",
      "threshold = np.percentile(flood_risk_score, 85)  # Top 15% are flood risk\n",
      "df['flood_risk_24h'] = (flood_risk_score > threshold).astype(int)\n",
      "\n",
      "print(f\"Enhanced dataset created with {len(df)} samples\")\n",
      "print(f\"Total features: {len(df.columns) - 1}\")\n",
      "print(f\"Flood risk distribution: {df['flood_risk_24h'].value_counts().to_dict()}\")\n",
      "print(f\"Flood risk rate: {df['flood_risk_24h'].mean():.3f}\")\n",
      "\n",
      "# Display feature engineering summary\n",
      "engineered_features = [col for col in df.columns if col not in \n",
      "                      ['streamflow_cfs', 'rainfall_24h', 'river_stage_ft', 'soil_moisture', 'elevation_ft', 'flood_risk_24h']]\n",
      "\n",
      "print(f\"\\nEngineered Features Created ({len(engineered_features)}):\")\n",
      "for i, feature in enumerate(engineered_features, 1):\n",
      "    print(f\"{i:2d}. {feature}\")\n",
      "\n",
      "print(\"\\n3. FEATURE ENGINEERING CATEGORIES IMPLEMENTED:\")\n",
      "print(\"=\" * 50)\n",
      "print(\"A) Ratio & Interaction Features:\")\n",
      "print(\"   - flow_to_stage_ratio: Streamflow efficiency\")\n",
      "print(\"   - rainfall_soil_interaction: Combined saturation effect\")\n",
      "print(\"   - elevation_stage_diff: Relative elevation safety margin\")\n",
      "\n",
      "print(\"\\nB) Threshold-based Binary Flags:\")\n",
      "print(\"   - high_flow_flag, heavy_rain_flag, saturated_soil_flag, critical_stage_flag\")\n",
      "\n",
      "print(\"\\nC) Normalized Features:\")\n",
      "print(\"   - Z-score normalization for main hydrological variables\")\n",
      "\n",
      "print(\"\\nD) Log Transformations:\")\n",
      "print(\"   - For handling skewed distributions (streamflow, rainfall)\")\n",
      "\n",
      "print(\"\\nE) Categorical Binning:\")\n",
      "print(\"   - elevation_category: Discretized elevation levels\")\n",
      "\n",
      "print(\"\\nF) Composite Risk Scores:\")\n",
      "print(\"   - hydrological_risk: Combined water-related risk\")\n",
      "print(\"   - vulnerability_score: Location-based vulnerability\")\n",
      "\n",
      "# Save enhanced dataset\n",
      "df.to_csv('flood_prediction_enhanced.csv', index=False)\n",
      "print(f\"\\nEnhanced dataset saved as 'flood_prediction_enhanced.csv'\")\n",
      "```\n",
      "\n",
      "<stream_turn_title>Creating Enhanced Flood Dataset with Feature Engineering</stream_turn_title>\n",
      "\n",
      "**LLM Call Info:**\n",
      "\n",
      " Turn Time: 29.03s out of 120s.\n",
      "\n",
      " Turns: 2 out of 20.\n",
      " Time: 49.5 out of 3600.\n",
      " Cost: Turn: $0.0470, Total: $0.1541, Remaining: $475.02.\n",
      "\n",
      "\n",
      "ENDOFTURN\n",
      "\n",
      "\n",
      "**Executing python code blocks**\n",
      "\n",
      "=== COMPREHENSIVE FLOOD PREDICTION MODEL GUIDE ===\n",
      "\n",
      "1. CREATING REALISTIC FLOOD DATASET\n",
      "==================================================\n",
      "2. FEATURE ENGINEERING - CREATING DERIVED FEATURES\n",
      "=======================================================\n",
      "Enhanced dataset created with 5000 samples\n",
      "Total features: 20\n",
      "Flood risk distribution: {0: 4250, 1: 750}\n",
      "Flood risk rate: 0.150\n",
      "\n",
      "Engineered Features Created (15):\n",
      " 1. flow_to_stage_ratio\n",
      " 2. rainfall_soil_interaction\n",
      " 3. elevation_stage_diff\n",
      " 4. high_flow_flag\n",
      " 5. heavy_rain_flag\n",
      " 6. saturated_soil_flag\n",
      " 7. critical_stage_flag\n",
      " 8. streamflow_cfs_normalized\n",
      " 9. rainfall_24h_normalized\n",
      "10. river_stage_ft_normalized\n",
      "11. log_streamflow\n",
      "12. log_rainfall\n",
      "13. elevation_category\n",
      "14. hydrological_risk\n",
      "15. vulnerability_score\n",
      "\n",
      "3. FEATURE ENGINEERING CATEGORIES IMPLEMENTED:\n",
      "==================================================\n",
      "A) Ratio & Interaction Features:\n",
      "   - flow_to_stage_ratio: Streamflow efficiency\n",
      "   - rainfall_soil_interaction: Combined saturation effect\n",
      "   - elevation_stage_diff: Relative elevation safety margin\n",
      "\n",
      "B) Threshold-based Binary Flags:\n",
      "   - high_flow_flag, heavy_rain_flag, saturated_soil_flag, critical_stage_flag\n",
      "\n",
      "C) Normalized Features:\n",
      "   - Z-score normalization for main hydrological variables\n",
      "\n",
      "D) Log Transformations:\n",
      "   - For handling skewed distributions (streamflow, rainfall)\n",
      "\n",
      "E) Categorical Binning:\n",
      "   - elevation_category: Discretized elevation levels\n",
      "\n",
      "F) Composite Risk Scores:\n",
      "   - hydrological_risk: Combined water-related risk\n",
      "   - vulnerability_score: Location-based vulnerability\n",
      "\n",
      "Enhanced dataset saved as 'flood_prediction_enhanced.csv'\n",
      "\n",
      "\n",
      "** [Monday, October 20, 2025 - 03:08:32.7 PM PDT] Completed execution of code block using python in 2.04 seconds after 2 out of 20 turns and time 52.3s out of 3600s and minimum runtime 0s.**\n",
      "\n",
      "ENDOFTURN\n",
      "Now let me build and evaluate multiple ML models with the engineered features, and provide comprehensive modeling recommendations.\n",
      "\n",
      "```python\n",
      "# filename: flood_model_development.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train\n",
      "\n",
      "‚úÖ Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "if H2OGPTE_AVAILABLE:\n",
    "    headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "    # Using FastAPI streaming endpoint for h2oGPTe\n",
    "    url = f\"{api_server_base_url}/api/ai/chat/enhanced/stream\"\n",
    "    \n",
    "    payload = {\n",
    "        \"message\": \"\"\"I have flood prediction data with these features:\n",
    "        - streamflow_cfs: Current river flow rate\n",
    "        - rainfall_24h: Rainfall in last 24 hours\n",
    "        - river_stage_ft: Water level\n",
    "        - soil_moisture: Ground saturation\n",
    "        - elevation_ft: Location elevation\n",
    "        \n",
    "        How should I approach building an ML model to predict flood risk in the next 24 hours?\n",
    "        What feature engineering would you recommend?\"\"\",\n",
    "        \"provider\": \"h2ogpte\",\n",
    "        \"use_agent\": True,\n",
    "        \"max_tokens\": 8192*10,\n",
    "    }\n",
    "    \n",
    "    print(\"üß† Consulting h2oGPTe agent for AutoML guidance...\\n\")\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        last_content = \"\"\n",
    "        # Stream the response\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                line_str = line.decode('utf-8')\n",
    "                if line_str.startswith('data: '):\n",
    "                    data_str = line_str[6:]  # Remove 'data: ' prefix\n",
    "                    try:\n",
    "                        data = json.loads(data_str)\n",
    "                        \n",
    "                        # First message contains provider info\n",
    "                        if 'provider' in data:\n",
    "                            print(f\"üì° Provider: {data.get('provider')}\")\n",
    "                            print(f\"ü§ñ Model: {data.get('model')}\\n\")\n",
    "                            print(\"üìù Response:\\n\")\n",
    "                        \n",
    "                        # h2oGPTe sends incremental chunks with full content\n",
    "                        elif 'chunk' in data and not data.get('done', False):\n",
    "                            new_content = data['chunk']\n",
    "                            # Only print the new portion\n",
    "                            if new_content.startswith(last_content):\n",
    "                                new_part = new_content[len(last_content):]\n",
    "                                print(new_part, end='', flush=True)\n",
    "                                last_content = new_content\n",
    "                        \n",
    "                        # Check for completion\n",
    "                        elif data.get('done', False):\n",
    "                            break\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "        \n",
    "        print(\"\\n\\n‚úÖ Streaming complete!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping h2oGPTe demo (credentials not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 4: Multi-Agent System with FastMCP\n",
    "\n",
    "## ü§ù FastMCP - Model Context Protocol Server\n",
    "\n",
    "Our flood prediction system uses FastMCP to expose 20+ specialized tools across 5 intelligent agents:\n",
    "\n",
    "### The 5 Agents\n",
    "\n",
    "1. **Data Collector Agent** üìä\n",
    "   - Collects USGS water data\n",
    "   - Retrieves NOAA flood forecasts\n",
    "   - Gathers weather information\n",
    "   - Monitors data quality\n",
    "\n",
    "2. **Risk Analyzer Agent** ‚ö†Ô∏è\n",
    "   - Calculates flood risk scores\n",
    "   - Analyzes trends and patterns\n",
    "   - Identifies high-risk areas\n",
    "\n",
    "3. **Emergency Responder Agent** üö®\n",
    "   - Assesses emergency readiness\n",
    "   - Activates alerts\n",
    "   - Coordinates evacuations\n",
    "\n",
    "4. **AI Predictor Agent** üîÆ\n",
    "   - Generates flood forecasts\n",
    "   - Predicts critical conditions\n",
    "   - Analyzes prediction accuracy\n",
    "\n",
    "5. **H2OGPTE ML Agent** üß†\n",
    "   - Trains ML models\n",
    "   - Optimizes features\n",
    "   - Analyzes model performance\n",
    "\n",
    "### Let's explore the available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Available Agents and Their Status\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üü¢ Data Collector\n",
      "   Description: Continuously pulls real-time flood data from USGS, NOAA, and weather APIs\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-20T22:13:41.743954+00:00\n",
      "   Check Interval: 300 seconds\n",
      "   Insights: 4\n",
      "\n",
      "üü¢ Risk Analyzer\n",
      "   Description: AI-powered analysis of flood risk conditions and trend detection\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-20T22:08:29.693476+00:00\n",
      "   Check Interval: 600 seconds\n",
      "   Insights: 4\n",
      "   Active Alerts: 2\n",
      "\n",
      "üü¢ Emergency Responder\n",
      "   Description: Coordinates emergency response activities and manages critical alerts\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-20T22:16:29.696294+00:00\n",
      "   Check Interval: 180 seconds\n",
      "   Insights: 5\n",
      "   Active Alerts: 5\n",
      "\n",
      "üü¢ AI Predictor\n",
      "   Description: Advanced AI forecasting and predictive analysis for flood conditions\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-20T22:13:29.694454+00:00\n",
      "   Check Interval: 900 seconds\n",
      "   Insights: 4\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get list of all agents and their capabilities\n",
    "response = requests.get(f\"{api_server_base_url}/api/agents\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"ü§ñ Available Agents and Their Status\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # The API returns a nested structure with agents dictionary\n",
    "    agents_dict = data.get('agents', {})\n",
    "    \n",
    "    for agent_key, agent_data in agents_dict.items():\n",
    "        status = \"üü¢\" if agent_data.get('is_running') else \"üî¥\"\n",
    "        print(f\"\\n{status} {agent_data.get('name', agent_key)}\")\n",
    "        print(f\"   Description: {agent_data.get('description', 'N/A')}\")\n",
    "        print(f\"   Status: {'Running' if agent_data.get('is_running') else 'Stopped'}\")\n",
    "        if agent_data.get('last_check'):\n",
    "            print(f\"   Last Check: {agent_data.get('last_check')}\")\n",
    "        if agent_data.get('check_interval'):\n",
    "            print(f\"   Check Interval: {agent_data.get('check_interval')} seconds\")\n",
    "        if agent_data.get('insights_count'):\n",
    "            print(f\"   Insights: {agent_data.get('insights_count')}\")\n",
    "        if agent_data.get('active_alerts_count'):\n",
    "            print(f\"   Active Alerts: {agent_data.get('active_alerts_count')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error fetching agents: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Agent Insights\n",
    "\n",
    "Agents continuously monitor flood conditions and generate insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Refreshing USGS data first...\n",
      "\n",
      "‚ö†Ô∏è  Data refresh returned status 500\n",
      "   Proceeding with existing data...\n",
      "\n",
      "üí° Agent Insights\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ü§ñ Data Collector\n",
      "------------------------------------------------------------\n",
      "\n",
      "üü° üîÑ Data Freshness: 24% current\n",
      "\n",
      "üîµ üåê API Connectivity: 5/5 active\n",
      "\n",
      "üîµ üìä Data Quality: 6.8/10\n",
      "   Change: +0.0\n",
      "\n",
      "üîµ ‚ö° Update Frequency: 12 updates/hour\n",
      "\n",
      "ü§ñ Risk Analyzer\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîµ üéØ Overall Risk Level: MODERATE (5.0/10)\n",
      "   Change: +0.0\n",
      "\n",
      "üîµ üö® Critical Watersheds: 1 areas\n",
      "\n",
      "üîµ üìà Risk Trend Analysis: Stable\n",
      "   Change: 0.0% per hour\n",
      "\n",
      "üîµ üß† AI Confidence: 0%\n",
      "   Change: Low\n",
      "\n",
      "ü§ñ Emergency Responder\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîµ üö® Active Incidents: 0 ongoing\n",
      "\n",
      "üîµ üöÅ Response Readiness: GOOD (85%)\n",
      "   Change: 8 teams ready\n",
      "\n",
      "üîµ üèÉ Evacuation Status: No active evacuations\n",
      "   Change: 0 zones active\n",
      "\n",
      "üîµ üì° Communication Systems: 100% operational\n",
      "   Change: 6 channels active\n",
      "\n",
      "üîµ üì¢ Alert Distribution: 0 alerts sent\n",
      "   Change: 0 today\n",
      "\n",
      "ü§ñ Predictor\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîµ üéØ Model Accuracy: 85.0%\n",
      "   Change: +0.0% vs yesterday\n",
      "\n",
      "üîµ üß† Prediction Confidence: 72%\n",
      "   Change: High\n",
      "\n",
      "================================================================================\n",
      "Generated at: 2025-10-20T22:18:04.279588+00:00\n"
     ]
    }
   ],
   "source": [
    "# Refresh USGS data before getting insights\n",
    "print(\"üîÑ Refreshing USGS data first...\\n\")\n",
    "\n",
    "# Note: Using local-token for development mode (server.py allows this when OIDC is disabled)\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "refresh_response = requests.post(\n",
    "    f\"{api_server_base_url}/api/dashboard/refresh-usgs-data\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if refresh_response.status_code == 200:\n",
    "    refresh_result = refresh_response.json()\n",
    "    print(f\"‚úÖ {refresh_result.get('message', 'Data refresh initiated')}\")\n",
    "    \n",
    "    # Wait a moment for background job to start\n",
    "    print(\"‚è≥ Waiting for data refresh to process...\\n\")\n",
    "    time.sleep(3)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Data refresh returned status {refresh_response.status_code}\")\n",
    "    print(f\"   Proceeding with existing data...\\n\")\n",
    "\n",
    "# Get insights from all agents\n",
    "response = requests.get(f\"{api_server_base_url}/api/agents/insights\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"üí° Agent Insights\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # The API returns insights grouped by agent\n",
    "    insights_by_agent = data.get('insights', {})\n",
    "    \n",
    "    count = 0\n",
    "    for agent_name, agent_insights in insights_by_agent.items():\n",
    "        print(f\"\\nü§ñ {agent_name.replace('_', ' ').title()}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for insight in agent_insights:\n",
    "            title = insight.get('title', 'N/A')\n",
    "            value = insight.get('value', 'N/A')\n",
    "            change = insight.get('change')\n",
    "            urgency = insight.get('urgency', 'normal')\n",
    "            timestamp = insight.get('timestamp', '')\n",
    "            \n",
    "            urgency_icon = {\n",
    "                'critical': 'üî¥',\n",
    "                'high': 'üü°',\n",
    "                'normal': 'üîµ',\n",
    "                'low': 'üü¢'\n",
    "            }.get(urgency, '‚ö™')\n",
    "            \n",
    "            print(f\"\\n{urgency_icon} {title}: {value}\")\n",
    "            if change:\n",
    "                print(f\"   Change: {change}\")\n",
    "            \n",
    "            count += 1\n",
    "            if count >= 15:  # Limit total insights shown\n",
    "                break\n",
    "        \n",
    "        if count >= 15:\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Generated at: {data.get('generated_at', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"‚ùå Error fetching insights: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Risk Analyzer Agent\n",
    "\n",
    "Calculates comprehensive flood risk scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Risk Analyzer Agent...\n",
      "\n",
      "üöÄ Starting risk_analyzer agent...\n",
      "\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "\n",
      "\n",
      "Question: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "Thought: I need to start by getting the current datetime to ensure the analysis is based on the latest data.\n",
      "Action: current_datetime\n",
      "Action Input: None\n",
      "\u001b[39m\n",
      "------------------------------\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: current_datetime\n",
      "\u001b[33mTool's input: None\n",
      "\u001b[36mTool's response: \n",
      "The current time of day is 2025-10-20 22:18:44 +0000\u001b[39m\n",
      "------------------------------\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "\u001b[39m\n",
      "------------------------------\n",
      "üí¨ [AGENT] Retrying ReAct Agent, including output parsing Observation\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "Action: comprehensive_flood_analysis_tool\n",
      "Action Input: {\"location\": \"Texas\"}\u001b[39m\n",
      "------------------------------\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: comprehensive_flood_analysis_tool\n",
      "\u001b[33mTool's input: {'location': 'Texas'}\n",
      "\u001b[36mTool's response: \n",
      "{\"status\":\"success\",\"location\":\"Texas\",\"analysis_timestamp\":\"2025-10-20T22:18:55.775095+00:00\",\"data_collection\":{\"agent\":\"Data Collector\",\"data_sources\":{\"usgs_sites\":10,\"noaa_alerts\":0,\"weather_locations\":7},\"insights\":[{\"title\":\"üîÑ Data Freshness\",\"value\":\"100% current\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"üåê API Connectivity\",\"value\":\"5/5 active\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"üìä Data Quality\",\"value\":\"9.3/10\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"‚ö° Update Frequency\",\"value\":\"12 updates/hour\",\"trend\":\"stable\",\"urgency\":\"normal\"}],\"alerts\":[]},\"risk_analysis\":{\"agent\":\"Risk Analyzer\",\"insights\":[{\"title\":\"üéØ Overall Risk Level\",\"value\":\"Unknown (0.0/10)\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"üö® Critical Watersheds\",\"value\":\"0 areas\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"üìà Risk Trend Analysis\",\"value\":\"Insufficient data\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"üß† AI Confidence\",\"value\":\"0%\",\"trend\":\"stable\",\"urgency\":\"normal\"}],\"alerts\":[]},\"...(rest of response truncated)\u001b[39m\n",
      "------------------------------\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: \n",
      "\n",
      "**Comprehensive Flood Risk Analysis for Texas (as of 2025-10-20 22:18:44 UTC):**\n",
      "\n",
      "1. **Detailed Risk Scores & Factors**  \n",
      "   - **Overall Risk Level**: LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "   - **Critical Components**:  \n",
      "     - **Rainfall**: No active NOAA alerts; default rainfall parameters used.  \n",
      "     - **River Stages**: USGS flow (0 cfs) and flood stage (20 ft) indicate minimal immediate risk.  \n",
      "     - **Elevation/Proximity**: Default elevation (100m) and distance-to-water (5km) suggest moderate geographic risk.  \n",
      "\n",
      "2. **Highest Risk Components**  \n",
      "   - **Data Gaps**: 0% AI confidence due to incomplete inputs (e.g., no current/future rainfall data, historical events).  \n",
      "   - **Monitoring Needs**: Watershed data (10 USGS sites) requires validation for accuracy.  \n",
      "\n",
      "3. **Trend Analysis**  \n",
      "   - **Risk Trend**: Stable (no active incidents or rising alerts).  \n",
      "   - **Prediction Confidence**: 70% for 48-hour forecasts, but no specific flood triggers identified.  \n",
      "\n",
      "4. **Recommendations**  \n",
      "   - **Immediate Actions**: Activate real-time rainfall and river gauge monitoring (e.g., NOAA alerts, USGS updates).  \n",
      "   - **Data Improvement**: Input location-specific parameters (e.g., current rainfall, elevation) for recalibration.  \n",
      "   - **Readiness**: Maintain emergency response systems (currently 85% ready) and public communication channels.  \n",
      "\n",
      "**Summary**: Texas currently faces low flood risk, but incomplete data and model uncertainty require urgent validation. Focus on enhancing input parameters and real-time monitoring to improve accuracy.\u001b[39m\n",
      "------------------------------\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Data Collection Complete!\n",
      "\n",
      "**Comprehensive Flood Risk Analysis for Texas (as of 2025-10-20 22:18:44 UTC):**\n",
      "\n",
      "1. **Detailed Risk Scores & Factors**  \n",
      "   - **Overall Risk Level**: LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "   - **Critical Components**:  \n",
      "     - **Rainfall**: No active NOAA alerts; default rainfall parameters used.  \n",
      "     - **River Stages**: USGS flow (0 cfs) and flood stage (20 ft) indicate minimal immediate risk.  \n",
      "     - **Elevation/Proximity**: Default elevation (100m) and distance-to-water (5km) suggest moderate geographic risk.  \n",
      "\n",
      "2. **Highest Risk Components**  \n",
      "   - **Data Gaps**: 0% AI confidence due to incomplete inputs (e.g., no current/future rainfall data, historical events).  \n",
      "   - **Monitoring Needs**: Watershed data (10 USGS sites) requires validation for accuracy.  \n",
      "\n",
      "3. **Trend Analysis**  \n",
      "   - **Risk Trend**: Stable (no active incidents or rising alerts).  \n",
      "   - **Prediction Confidence**: 70% for 48-hour forecasts, but no specific flood triggers identified.  \n",
      "\n",
      "4. **Recommendations**  \n",
      "   - **Immediate Actions**: Activate real-time rainfall and river gauge monitoring (e.g., NOAA alerts, USGS updates).  \n",
      "   - **Data Improvement**: Input location-specific parameters (e.g., current rainfall, elevation) for recalibration.  \n",
      "   - **Readiness**: Maintain emergency response systems (currently 85% ready) and public communication channels.  \n",
      "\n",
      "**Summary**: Texas currently faces low flood risk, but incomplete data and model uncertainty require urgent validation. Focus on enhancing input parameters and real-time monitoring to improve accuracy.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run Risk Analyzer Agent via NAT\n",
    "payload = {\n",
    "    \"agent\": \"risk_analyzer\",\n",
    "    \"message\": \"\"\"Analyze current flood risk for the Texas:\n",
    "    1. Calculate detailed risk scores for all factors\n",
    "    2. Identify the highest risk components\n",
    "    3. Provide trend analysis\n",
    "    4. Give recommendations for monitoring\n",
    "    \n",
    "    Be specific about the risk levels and factors.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Running Risk Analyzer Agent...\\n\")\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{api_server_base_url}/api/nat/chat/stream\",\n",
    "    json=payload,\n",
    "    headers=headers,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    final_output = None\n",
    "    \n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            line_str = line.decode('utf-8')\n",
    "            if line_str.startswith('data: '):\n",
    "                data_str = line_str[6:]  # Remove 'data: ' prefix\n",
    "                try:\n",
    "                    data = json.loads(data_str)\n",
    "                    \n",
    "                    # Handle different event types\n",
    "                    event_type = data.get('type')\n",
    "                    \n",
    "                    if event_type == 'start':\n",
    "                        print(f\"üöÄ Starting {data.get('agent_type')} agent...\")\n",
    "                        print()\n",
    "                    \n",
    "                    elif event_type == 'log':\n",
    "                        log_entry = data.get('log', {})\n",
    "                        level = log_entry.get('level', 'INFO')\n",
    "                        message = log_entry.get('message', '')\n",
    "                        \n",
    "                        # Show important logs\n",
    "                        if level in ['WARNING', 'ERROR']:\n",
    "                            print(f\"[{level}] {message}\")\n",
    "                        elif 'Agent' in message or 'Final Answer' in message or 'Tool' in message:\n",
    "                            print(f\"üí¨ {message}\")\n",
    "                    \n",
    "                    elif event_type == 'result':\n",
    "                        final_output = data.get('output')\n",
    "                        print(\"\\n\" + \"=\"*80)\n",
    "                        print(\"‚úÖ Data Collection Complete!\\n\")\n",
    "                    \n",
    "                    elif event_type == 'error':\n",
    "                        print(f\"\\n‚ùå Error: {data.get('error')}\")\n",
    "                    \n",
    "                    elif event_type == 'done':\n",
    "                        break\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "    \n",
    "    # Display final output\n",
    "    if final_output:\n",
    "        print(final_output)\n",
    "        print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: H2OGPTE ML Agent\n",
    "\n",
    "AutoML agent for model training and optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Running H2OGPTE ML Agent...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run H2OGPTE ML Agent via NAT\n",
    "payload = {\n",
    "    \"agent\": \"h2ogpte_agent\",\n",
    "    \"message\": \"\"\"Help me design an ML pipeline for flood prediction:\n",
    "    1. What features should I engineer from raw sensor data?\n",
    "    2. What model types work best for flood forecasting?\n",
    "    3. How should I handle imbalanced flood event data?\n",
    "    4. What validation strategy is appropriate for time-series?\n",
    "    \n",
    "    Provide actionable AutoML recommendations.\"\"\"\n",
    "}\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "print(\"üß† Running H2OGPTE ML Agent...\\n\")\n",
    "\n",
    "response = requests.post(f\"{api_server_base_url}/api/nat/chat\", json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"‚úÖ ML Recommendations Complete!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(result.get('response', result))\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 5: Real-World Data Integration\n",
    "\n",
    "## üåê Live Data from Government APIs\n",
    "\n",
    "Our system integrates with real-time data sources:\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "1. **USGS Water Services**\n",
    "   - Real-time streamflow (CFS)\n",
    "   - Gage height (feet)\n",
    "   - 12 monitoring stations in Texas\n",
    "   - Updated every 15 minutes\n",
    "\n",
    "2. **NOAA Weather Service**\n",
    "   - Flood warnings and watches\n",
    "   - Weather alerts\n",
    "   - Forecast data\n",
    "\n",
    "3. **Open-Meteo**\n",
    "   - Weather forecasts\n",
    "   - Flood API predictions\n",
    "   - Historical data\n",
    "\n",
    "### Let's view live watershed data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refresh USGS Data Manually\n",
    "\n",
    "Trigger a fresh data collection from USGS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Triggering USGS data refresh...\\n\")\n",
    "header = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "response = requests.post(f\"{api_server_base_url}/api/dashboard/refresh-usgs-data\", headers=header)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    time.sleep(5)\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "\n",
    "# Get current watershed data\n",
    "response = requests.get(f\"{api_server_base_url}/api/watersheds\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    watersheds = response.json()\n",
    "    \n",
    "    # Convert to DataFrame for nice display\n",
    "    df = pd.DataFrame(watersheds)\n",
    "    \n",
    "    # Select key columns\n",
    "    display_cols = ['name', 'current_streamflow_cfs', 'risk_score', \n",
    "                    'trend_rate_cfs_per_hour', 'last_updated']\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    \n",
    "    print(\"üåä Live Watershed Data\\n\")\n",
    "    print(\"=\"*100)\n",
    "    print(df[available_cols].to_string(index=False))\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nüìä Total Watersheds Monitored: {len(watersheds)}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if 'risk_score' in df.columns:\n",
    "        high_risk = len(df[df['risk_score'] > 7.0])\n",
    "        medium_risk = len(df[(df['risk_score'] >= 4.0) & (df['risk_score'] <= 7.0)])\n",
    "        low_risk = len(df[df['risk_score'] < 4.0])\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Risk Distribution:\")\n",
    "        print(f\"   üî¥ High Risk (>7.0): {high_risk}\")\n",
    "        print(f\"   üü° Medium Risk (4.0-7.0): {medium_risk}\")\n",
    "        print(f\"   üü¢ Low Risk (<4.0): {low_risk}\")\n",
    "else:\n",
    "    print(f\"‚ùå Error fetching watersheds: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì Summary & Next Steps\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "In this notebook, you've learned how to:\n",
    "\n",
    "‚úÖ **Set up a multi-agent AI system** for disaster response  \n",
    "‚úÖ **Integrate h2oGPTe** for AutoML and model training  \n",
    "‚úÖ **Use NVIDIA NIM** for high-performance inference  \n",
    "‚úÖ **Build NAT agent workflows** with React patterns  \n",
    "‚úÖ **Implement FastMCP servers** with custom tools  \n",
    "‚úÖ **Integrate real-time data** from government APIs  \n",
    "‚úÖ **Coordinate multiple AI agents** for complex tasks  \n",
    "‚úÖ **Evaluate responses** using LLM-as-Judge  \n",
    "\n",
    "## Architecture Highlights\n",
    "\n",
    "- **5 Specialized Agents**: Data Collector, Risk Analyzer, Emergency Responder, Predictor, H2OGPTE ML\n",
    "- **20+ MCP Tools**: Via FastMCP server on port 8001\n",
    "- **NVIDIA NIM Models**: Nemotron Super 49B, Llama 3.1 variants\n",
    "- **h2oGPTe A2A**: Agent-to-agent AutoML capabilities\n",
    "- **Real-time Data**: USGS, NOAA, Weather APIs\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **NVIDIA NIM**: [build.nvidia.com](https://build.nvidia.com)\n",
    "- **h2oGPTe**: [h2o.ai/platform/enterprise-h2ogpte](https://h2o.ai/platform/enterprise-h2ogpte/)\n",
    "- **NVIDIA NAT**: [docs.nvidia.com/nat](https://docs.nvidia.com/nat)\n",
    "- **FastMCP**: [github.com/jlowin/fastmcp](https://github.com/jlowin/fastmcp)\n",
    "- **USGS Water Data**: [waterdata.usgs.gov](https://waterdata.usgs.gov)\n",
    "- **NOAA Weather**: [weather.gov](https://weather.gov)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Customize Agents**: Modify agent configs for your specific use case\n",
    "2. **Add Data Sources**: Integrate additional APIs and sensors\n",
    "3. **Train ML Models**: Use h2oGPTe to train production models\n",
    "4. **Deploy to Production**: Use Docker/Kubernetes deployment\n",
    "5. **Monitor Performance**: Add logging and metrics\n",
    "\n",
    "## Contributing\n",
    "\n",
    "This is an open-source AI for Good project. Contributions welcome!\n",
    "\n",
    "---\n",
    "\n",
    "### üåä Thank you for exploring the Flood Prediction Blueprint!\n",
    "\n",
    "**Built with ‚ù§Ô∏è using h2oGPTe and NVIDIA NIM**\n",
    "\n",
    "For questions and support, please open an issue in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
