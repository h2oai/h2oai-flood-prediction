{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI-Powered Flood Prediction System with h2oGPTe and NVIDIA NIM\n",
    "\n",
    "[![Deploy on NVIDIA](https://img.shields.io/badge/Deploy%20on-NVIDIA%20AI%20Blueprints-76B900?logo=nvidia&logoColor=white)](https://build.nvidia.com)\n",
    "[![H2O.ai](https://img.shields.io/badge/Powered%20by-H2O.ai-FFD500)](https://h2o.ai)\n",
    "\n",
    "---\n",
    "\n",
    "## üåä Overview\n",
    "\n",
    "This blueprint demonstrates an **AI-powered flood prediction and disaster response system** that combines:\n",
    "\n",
    "- **h2oGPTe Agent-to-Agent (A2A)**: Advanced AutoML capabilities with Driverless AI for model training and feature engineering\n",
    "- **NVIDIA NIM**: State-of-the-art inference with `nvidia/llama-3.3-nemotron-super-49b-v1.5` and other NVIDIA models\n",
    "- **NVIDIA NAT Pipeline**: React Agent workflows for multi-agent orchestration\n",
    "- **FastMCP Server**: 20+ specialized tools across 5 intelligent agents\n",
    "- **Real-time Data Integration**: USGS Water Services, NOAA Forecasts, and Weather APIs\n",
    "\n",
    "### üéØ Use Case: AI for Good - Disaster Response\n",
    "\n",
    "This system provides:\n",
    "- **Real-time flood monitoring** with live data from watersheds and monitoring stations\n",
    "- **AI-powered risk assessment** using advanced machine learning models\n",
    "- **Emergency response coordination** with automated alerts and evacuation planning\n",
    "- **Predictive analytics** for flood forecasting 24-72 hours ahead\n",
    "- **AutoML model training** for continuous improvement of prediction accuracy\n",
    "\n",
    "### üèóÔ∏è Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                      Flood Prediction System                     ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ\n",
    "‚îÇ  ‚îÇ   h2oGPTe    ‚îÇ  ‚îÇ  NVIDIA NIM  ‚îÇ  ‚îÇ  FastMCP     ‚îÇ         ‚îÇ\n",
    "‚îÇ  ‚îÇ  (A2A Mode)  ‚îÇ  ‚îÇ  (Nemotron)  ‚îÇ  ‚îÇ   Server     ‚îÇ         ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ\n",
    "‚îÇ         ‚îÇ                 ‚îÇ                 ‚îÇ                   ‚îÇ\n",
    "‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n",
    "‚îÇ                  ‚îÇ                 ‚îÇ                            ‚îÇ\n",
    "‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ         ‚îÇ    NVIDIA NAT Agent Pipeline      ‚îÇ                  ‚îÇ\n",
    "‚îÇ         ‚îÇ      (React Agent Workflow)       ‚îÇ                  ‚îÇ\n",
    "‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                  ‚îÇ                                              ‚îÇ\n",
    "‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ\n",
    "‚îÇ    ‚îÇ    5 Specialized Agents   ‚îÇ                               ‚îÇ\n",
    "‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                               ‚îÇ\n",
    "‚îÇ    ‚îÇ  1. Data Collector        ‚îÇ ‚óÑ‚îÄ‚îÄ USGS Water Data           ‚îÇ\n",
    "‚îÇ    ‚îÇ  2. Risk Analyzer         ‚îÇ ‚óÑ‚îÄ‚îÄ NOAA Flood Alerts         ‚îÇ\n",
    "‚îÇ    ‚îÇ  3. Emergency Responder   ‚îÇ ‚óÑ‚îÄ‚îÄ Weather APIs              ‚îÇ\n",
    "‚îÇ    ‚îÇ  4. AI Predictor          ‚îÇ                               ‚îÇ\n",
    "‚îÇ    ‚îÇ  5. H2OGPTE ML Agent      ‚îÇ                               ‚îÇ\n",
    "‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  Output: Real-time Monitoring, Alerts, Predictions, ML Models  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üîë Key Technologies\n",
    "\n",
    "1. **h2oGPTe**: Enterprise AI platform with agent mode for AutoML and advanced analytics\n",
    "2. **NVIDIA NIM**: Optimized inference microservices for AI models\n",
    "3. **NVIDIA NAT**: Agent orchestration framework with React-based workflows\n",
    "4. **FastMCP**: Model Context Protocol server for tool integration\n",
    "5. **FastAPI**: High-performance API server for real-time operations\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "- Setting up multi-agent AI systems for disaster response\n",
    "- Integrating h2oGPTe for AutoML and model training\n",
    "- Using NVIDIA NIM for high-performance inference\n",
    "- Building NAT agent workflows with React patterns\n",
    "- Implementing FastMCP servers with custom tools\n",
    "- Real-time data integration from government APIs\n",
    "- Coordinating multiple AI agents for complex tasks\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Helm Deployment\n",
    "\n",
    "Before running this notebook, deploy the backend services using the Helm chart described in `./deployment/helm/README.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Environment Configuration\n",
    "\n",
    "Ensure the required API credentials and service endpoints are available in the environment before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA_API_KEY: nvapi-LRQz........................................................5JXH\n",
      "APP_H2OGPTE_URL: https://h2ogpte.cloud-dev.h2o.dev\n",
      "APP_H2OGPTE_API_KEY: sk-ktl41qb.....................................tiqB\n",
      "‚úÖ h2oGPTe credentials found\n",
      "üîó URL: https://h2ogpte.cloud-dev.h2o.dev\n",
      "‚úÖ API_SERVER_URL detected: http://flood-pred-web\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://flood-pred-web'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def preview_key(value: str) -> str:\n",
    "    if not value:\n",
    "        return \"Not set\"\n",
    "    if len(value) <= 14:\n",
    "        return value\n",
    "    dots = max(1, len(value) - 14)\n",
    "    return f\"{value[:10]}{'.' * dots}{value[-4:]}\"\n",
    "\n",
    "\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "print(f\"NVIDIA_API_KEY: {preview_key(NVIDIA_API_KEY)}\")\n",
    "\n",
    "H2OGPTE_URL = os.getenv(\"APP_H2OGPTE_URL\")\n",
    "print(f\"APP_H2OGPTE_URL: {H2OGPTE_URL or 'Not set'}\")\n",
    "\n",
    "H2OGPTE_API_KEY = os.getenv(\"APP_H2OGPTE_API_KEY\")\n",
    "print(f\"APP_H2OGPTE_API_KEY: {preview_key(H2OGPTE_API_KEY)}\")\n",
    "\n",
    "if H2OGPTE_URL and H2OGPTE_API_KEY:\n",
    "    print(\"‚úÖ h2oGPTe credentials found\")\n",
    "    print(f\"üîó URL: {H2OGPTE_URL}\")\n",
    "    H2OGPTE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  h2oGPTe credentials not set\")\n",
    "    print(\"This section will be skipped. To enable:\")\n",
    "    print(\"  export APP_H2OGPTE_URL='<your-url>'\")\n",
    "    print(\"  export APP_H2OGPTE_API_KEY='<your-key>'\")\n",
    "    H2OGPTE_AVAILABLE = False\n",
    "\n",
    "api_server_base_url = os.getenv(\"API_SERVER_URL\")\n",
    "if api_server_base_url:\n",
    "    print(f\"‚úÖ API_SERVER_URL detected: {api_server_base_url}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  API_SERVER_URL not set. API interactions will be skipped.\")\n",
    "api_server_base_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Helm-managed services are expected to be running.\n",
      "\n",
      "üìç Service Endpoints:\n",
      "   - FastAPI Server: http://flood-pred-web\n",
      "   - API Docs: http://flood-pred-web/docs\n",
      "   - Agents API: http://flood-pred-web/api/agents\n",
      "\n",
      "Use the next cell to verify service health.\n"
     ]
    }
   ],
   "source": [
    "# Services are managed via the Helm deployment. Display key endpoints for convenience.\n",
    "print(\"üîß Helm-managed services are expected to be running.\\n\")\n",
    "\n",
    "if not api_server_base_url:\n",
    "    print(\"‚ö†Ô∏è  API_SERVER_URL not set. Export API_SERVER_URL before continuing.\")\n",
    "else:\n",
    "    base_url = api_server_base_url.rstrip('/')\n",
    "    print(\"üìç Service Endpoints:\")\n",
    "    print(f\"   - FastAPI Server: {base_url}\")\n",
    "    print(f\"   - API Docs: {base_url}/docs\")\n",
    "    print(f\"   - Agents API: {base_url}/api/agents\")\n",
    "    print(\"\\nUse the next cell to verify service health.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Verify Services\n",
    "\n",
    "Let's check that all services are running correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking service health...\n",
      "\n",
      "‚úÖ FastAPI Dashboard is running\n",
      "‚úÖ Agents API is running\n",
      "‚úÖ Watersheds API is running\n",
      "\n",
      "==================================================\n",
      "‚úÖ All services are responding!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "print(\"üîç Checking service health...\\n\")\n",
    "\n",
    "if not api_server_base_url:\n",
    "    print(\"‚ö†Ô∏è  API_SERVER_URL not set. Skipping health checks.\")\n",
    "    fastapi_ok = False\n",
    "else:\n",
    "    base_url = api_server_base_url.rstrip('/')\n",
    "\n",
    "    def check_service(path, name, headers=None):\n",
    "        url = f\"{base_url}/{path.lstrip('/')}\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "        except requests.exceptions.RequestException as exc:\n",
    "            print(f\"‚ùå {name} is not responding: {exc}\")\n",
    "            return False\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(f\"‚úÖ {name} is running\")\n",
    "            return True\n",
    "        if response.status_code == 401:\n",
    "            print(f\"‚ö†Ô∏è  {name} requires authentication (401)\")\n",
    "            return True\n",
    "\n",
    "        print(f\"‚ö†Ô∏è  {name} responded with status {response.status_code}\")\n",
    "        return False\n",
    "\n",
    "    fastapi_ok = check_service('api/dashboard', 'FastAPI Dashboard')\n",
    "    agents_ok = check_service('api/agents', 'Agents API', headers={'Authorization': 'Bearer local-token'})\n",
    "    watersheds_ok = check_service('api/watersheds', 'Watersheds API')\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    if fastapi_ok and agents_ok and watersheds_ok:\n",
    "        print(\"‚úÖ All services are responding!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  One or more endpoints did not respond as expected.\")\n",
    "        print(\"Review Helm deployment status or API logs if needed.\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 2: NVIDIA NIM Integration\n",
    "\n",
    "## üöÄ NVIDIA NIM - Optimized Inference Microservices\n",
    "\n",
    "NVIDIA NIM provides high-performance inference for state-of-the-art language models. Our flood prediction system uses several NVIDIA models:\n",
    "\n",
    "### Available Models\n",
    "\n",
    "1. **nvidia/llama-3.3-nemotron-super-49b-v1.5** (Default)\n",
    "   - Latest Nemotron model optimized for instruction following\n",
    "   - Excellent for agent workflows and tool calling\n",
    "   - 49B parameters with superior efficiency\n",
    "\n",
    "2. **meta/llama-3.1-70b-instruct**\n",
    "   - Strong general-purpose reasoning\n",
    "   - Great for complex analysis tasks\n",
    "\n",
    "3. **nvidia/llama-3.1-nemotron-70b-instruct**\n",
    "   - NVIDIA-optimized Llama variant\n",
    "   - Enhanced for enterprise use cases\n",
    "\n",
    "4. **meta/llama-3.1-405b-instruct**\n",
    "   - Used as LLM-as-Judge for evaluation\n",
    "   - Highest reasoning capability\n",
    "\n",
    "### Let's test NVIDIA NIM integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Testing NVIDIA NIM with nvidia/llama-3.3-nemotron-super-49b-v1.5\n",
      "\n",
      "üìù Response:\n",
      "<think>\n",
      "Okay, so I need to figure out the key factors that indicate an increased risk of flooding in a river basin. Let me start by recalling what I know about floods and river basins. A river basin is the area of land that drains water into a particular river and its tributaries. Flooding happens when the river can't hold the amount of water it's receiving, leading to overflow.\n",
      "\n",
      "First, I think precipitation is a major factor. If there's a lot of rain, especially heavy and prolonged rainfall, that can cause the river levels to rise quickly. But maybe it's not just the amount of rain, but also the intensity and duration. Like, a storm that dumps a lot of rain in a short time might be worse than a steady drizzle over days.\n",
      "\n",
      "Then there's the terrain. If the land is steep, water runoff can be faster, leading to quicker rises in river levels. Flat areas might allow water to spread out more, but if the soil is saturated, even flat areas can flood. Soil type is probably important too. Clay soils don't absorb water well, so more runoff, whereas sandy soils absorb more, reducing runoff.\n",
      "\n",
      "Vegetation cover might play a role. Forests and grasslands can absorb a lot of water, reducing runoff. If there's deforestation or urbanization with impervious surfaces like concrete, that increases runoff because water can't soak into the ground. So urban areas might have higher flood risks.\n",
      "\n",
      "Snowmelt is another factor. In colder regions, if there's a lot of snow in the mountains and it melts quickly due to warm temperatures, that can cause a sudden increase in river flow. If the melt happens gradually, it might not be as bad, but rapid melting can be problematic.\n",
      "\n",
      "The capacity of the river and its tributaries matters. If the river is narrow or has obstructions like dams, levees, or bridges, that can restrict flow and cause water to back up. Dams can sometimes prevent flooding by holding back water, but if they fail or release too much water at once, that can cause floods downstream.\n",
      "\n",
      "Human activities and land use changes. Urbanization increases impervious surfaces, leading to more runoff. Poor drainage systems in cities can't handle heavy rains, leading to flooding. Agricultural practices like tilling can reduce soil's ability to absorb water. Also, building in floodplains increases exposure to flooding.\n",
      "\n",
      "Climate change might be a factor too. It can lead\n",
      "\n",
      "üìä Tokens used: 540\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Initialize NVIDIA NIM client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=os.getenv('NVIDIA_API_KEY')\n",
    ")\n",
    "\n",
    "# Test with Nemotron Super 49B\n",
    "model = \"nvidia/llama-3.3-nemotron-super-49b-v1.5\"\n",
    "\n",
    "local_nim_base_url: str = os.environ.get(\"NIM_LLM_BASE_URL\", \"\")\n",
    "local_nim_default_model: str = os.environ.get(\"NIM_LLM_DEFAULT_MODEL\", \"nvidia/llama-3-3-nemotron-super-49b-v1-5\")\n",
    "\n",
    "if local_nim_base_url:\n",
    "    print(f\"Using local NIM base URL: {local_nim_base_url}\")\n",
    "    client = OpenAI(\n",
    "        base_url=local_nim_base_url,\n",
    "        api_key=\"dummy\",\n",
    "    )\n",
    "\n",
    "print(f\"ü§ñ Testing NVIDIA NIM with {model}\\n\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert flood prediction assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are the key factors that indicate an increased risk of flooding in a river basin?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"üìù Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"\\nüìä Tokens used: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Response Example\n",
    "\n",
    "NVIDIA NIM supports streaming for real-time responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Streaming response about flood prediction...\n",
      "\n",
      "<think>\n",
      "Okay, so I need to explain how AI can improve flood forecasting accuracy. Let me start by recalling what I know about flood forecasting and AI. Flood forecasting involves predicting the occurrence and extent of flooding, usually based on factors like rainfall, river levels, soil moisture, and weather patterns. Traditional methods might use hydrological models that are based on physical equations and historical data. But AI, especially machine learning, can offer some advantages here.\n",
      "\n",
      "First, AI can handle large datasets. Flood prediction requires processing vast amounts of data from various sources like satellite imagery, weather stations, river gauges, and maybe even social media. Traditional models might struggle with integrating all these data sources efficiently, but AI can process and analyze them quickly. For example, machine learning algorithms can detect patterns in historical data that might not be obvious to traditional models.\n",
      "\n",
      "Then there's the aspect of real-time data processing. AI systems can continuously learn and adapt as new data comes in. This is important because weather conditions can change rapidly, and having a model that updates in real-time could provide more accurate forecasts. For instance, recurrent neural networks (RNNs) or Long Short-Term Memory (LSTM) networks are good for time-series data, which is relevant for tracking rising water levels over time.\n",
      "\n",
      "Another point is the ability of AI to model complex, non-linear relationships. Hydrological processes are inherently complex and non-linear. Traditional models might use simplified equations that don't capture all the nuances, leading to inaccuracies\n",
      "\n",
      "‚úÖ Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"üåä Streaming response about flood prediction...\\n\")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise flood prediction expert.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain how AI can improve flood forecasting accuracy.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\n‚úÖ Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Let's compare responses from different NVIDIA models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Comparing model responses for:\n",
      "'Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ü§ñ Model: llama-3.3-nemotron-super-49b-v1.5\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this question. The user is asking if they should issue a flood alert given a streamflow of 2500 CFS that's rising at 200 CFS per hour. Hmm, first, I need to recall what factors are involved in determining a flood alert. \n",
      "\n",
      "I know that flood alerts are typically based on specific thresholds set by agencies like the National Weather Service (NWS) in the US. These thresholds vary depending on the location and the river's characteristics. So, the first thing I should consider is what the normal or safe streamflow levels are for this particular stream or river. Without knowing the specific location, it's hard to say for sure, but maybe there are general guidelines.\n",
      "\n",
      "Streamflow of 2500 CFS‚ÄîCFS stands for cubic feet per second, which is a measure of the volume of water flowing per second. The rising rate is 200 CFS per hour, which is quite rapid. Even if 2500\n",
      "\n",
      "üìà Tokens: 250\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ü§ñ Model: llama-3.1-70b-instruct\n",
      "\n",
      "Streamflow is already high (2500 CFS) and rising rapidly (200 CFS/hour). I recommend issuing a flood alert immediately. The rapid increase in streamflow indicates a high risk of flooding, and prompt action is necessary to protect people and property.\n",
      "\n",
      "üìà Tokens: 103\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_to_test = [\n",
    "    \"nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
    "    \"meta/llama-3.1-70b-instruct\"\n",
    "]\n",
    "\n",
    "question = \"Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?\"\n",
    "\n",
    "print(f\"üìä Comparing model responses for:\\n'{question}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\nü§ñ Model: {model_name.split('/')[-1]}\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a flood emergency expert. Be concise.\"},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        print(response.choices[0].message.content)\n",
    "        print(f\"\\nüìà Tokens: {response.usage.total_tokens}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-as-Judge Evaluation\n",
    "\n",
    "The system includes an automatic evaluation feature using **cross-provider LLM-as-Judge**:\n",
    "- When NVIDIA models generate responses, h2oGPTe judges them\n",
    "- When h2oGPTe generates responses, NVIDIA models judge them\n",
    "- This provides unbiased evaluation of response quality\n",
    "\n",
    "Let's evaluate the NVIDIA model responses using our evaluation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating NVIDIA model response using LLM-as-Judge...\n",
      "\n",
      "‚úÖ Evaluation Complete!\n",
      "\n",
      "================================================================================\n",
      "üìä Evaluation Metrics:\n",
      "\n",
      "   üéØ Overall Score:    6.0/10\n",
      "   ü§ù Helpfulness:      6.0/10\n",
      "   ‚úÖ Accuracy:         4.0/10\n",
      "   üéØ Relevance:        8.0/10\n",
      "   üìù Coherence:        8.0/10\n",
      "   üõ°Ô∏è  Safety:           7.0/10\n",
      "   üí™ Confidence:       85.0%\n",
      "\n",
      "üí≠ Judge's Reasoning:\n",
      "   The response is well-structured and directly addresses the question with appropriate urgency. However, it lacks critical context - flood thresholds vary dramatically by location, watershed characteristics, and baseline conditions. 2500 CFS could be normal flow for a large river or extreme flooding for a small stream. The response assumes high risk without considering flood stage levels, historical data, or local thresholds. While the precautionary approach is generally safe, making definitive recommendations without proper context could lead to unnecessary evacuations or alert fatigue. The response would benefit from requesting additional watershed-specific information before making alert recommendations.\n",
      "\n",
      "‚è±Ô∏è  Evaluation Duration: 6832ms\n",
      "üÜî Evaluation ID: 7ffd44b0-e34d-47dc-b0c8-8f164a84ea70\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Let's evaluate one of the model responses from above\n",
    "question = \"Given streamflow of 2500 CFS and rising 200 CFS/hour, should we issue a flood alert?\"\n",
    "\n",
    "# Response from meta/llama-3.1-70b-instruct (from cell 12)\n",
    "response_text = \"\"\"Streamflow is already high (2500 CFS) and rising rapidly (200 CFS/hour). I recommend issuing a flood alert immediately. The rapid increase in streamflow indicates a high risk of flooding, and prompt action is necessary to protect people and property.\"\"\"\n",
    "\n",
    "print(\"üîç Evaluating NVIDIA model response using LLM-as-Judge...\\n\")\n",
    "\n",
    "# Call the evaluation API\n",
    "eval_payload = {\n",
    "    \"question\": question,\n",
    "    \"response\": response_text,\n",
    "    \"model\": \"meta/llama-3.1-70b-instruct\",\n",
    "    \"agent_used\": False,\n",
    "    \"response_provider\": \"nvidia\"  # This will trigger h2oGPTe as the judge\n",
    "}\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "response = requests.post(\n",
    "    f\"{api_server_base_url}/api/evaluation/evaluate\",\n",
    "    json=eval_payload,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    eval_result = response.json()\n",
    "    \n",
    "    print(\"‚úÖ Evaluation Complete!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìä Evaluation Metrics:\\n\")\n",
    "    \n",
    "    metrics = eval_result.get('metrics', {})\n",
    "    print(f\"   üéØ Overall Score:    {metrics.get('overall', 0):.1f}/10\")\n",
    "    print(f\"   ü§ù Helpfulness:      {metrics.get('helpfulness', 0):.1f}/10\")\n",
    "    print(f\"   ‚úÖ Accuracy:         {metrics.get('accuracy', 0):.1f}/10\")\n",
    "    print(f\"   üéØ Relevance:        {metrics.get('relevance', 0):.1f}/10\")\n",
    "    print(f\"   üìù Coherence:        {metrics.get('coherence', 0):.1f}/10\")\n",
    "    print(f\"   üõ°Ô∏è  Safety:           {metrics.get('safety', 0):.1f}/10\")\n",
    "    print(f\"   üí™ Confidence:       {metrics.get('confidence', 0):.1%}\")\n",
    "    \n",
    "    print(f\"\\nüí≠ Judge's Reasoning:\")\n",
    "    print(f\"   {eval_result.get('reasoning', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Evaluation Duration: {eval_result.get('duration_ms', 0)}ms\")\n",
    "    print(f\"üÜî Evaluation ID: {eval_result.get('evaluation_id', 'N/A')}\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 3: h2oGPTe Agent (A2A) Integration\n",
    "\n",
    "## üß† h2oGPTe - Enterprise AI with Agent Mode\n",
    "\n",
    "h2oGPTe provides advanced AutoML capabilities through its agent mode, enabling:\n",
    "\n",
    "- **Driverless AI Integration**: Automated machine learning with minimal code\n",
    "- **Agent-to-Agent (A2A)**: AI agents that can invoke other AI agents\n",
    "- **Feature Engineering**: Automatic feature creation for time-series data\n",
    "- **Model Interpretability**: Explainable AI for emergency response decisions\n",
    "\n",
    "### Setting up h2oGPTe Client\n",
    "\n",
    "**Note**: This section requires h2oGPTe credentials. If you don't have access, you can skip to the next section.\n",
    "\n",
    "Get your credentials at: [H2O.ai Enterprise](https://h2o.ai/platform/enterprise-h2ogpte/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ h2oGPTe credentials found\n",
      "üîó URL: https://h2ogpte.cloud-dev.h2o.dev\n"
     ]
    }
   ],
   "source": [
    "# Check if h2oGPTe credentials are available\n",
    "h2ogpte_url = os.getenv('APP_H2OGPTE_URL', '')\n",
    "h2ogpte_key = os.getenv('APP_H2OGPTE_API_KEY', '')\n",
    "\n",
    "if h2ogpte_url and h2ogpte_key:\n",
    "    print(\"‚úÖ h2oGPTe credentials found\")\n",
    "    print(f\"üîó URL: {h2ogpte_url}\")\n",
    "    H2OGPTE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  h2oGPTe credentials not set\")\n",
    "    print(\"This section will be skipped. To enable:\")\n",
    "    print(\"  export APP_H2OGPTE_URL='<your-url>'\")\n",
    "    print(\"  export APP_H2OGPTE_API_KEY='<your-key>'\")\n",
    "    H2OGPTE_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h2oGPTe for Flood Prediction ML\n",
    "\n",
    "Let's use h2oGPTe's agent mode to get guidance on training a flood prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Consulting h2oGPTe agent for AutoML guidance...\n",
      "\n",
      "üì° Provider: h2ogpte\n",
      "ü§ñ Model: claude-sonnet-4-20250514\n",
      "\n",
      "üìù Response:\n",
      "\n",
      "#### Agentic Analysis  \n",
      "#### Starting Agent  \n",
      "I'll help you build a comprehensive ML model for flood risk prediction. Let me start by analyzing your data structure and then provide recommendations for feature engineering and model building approaches.\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_analysis.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Set up plotting style\n",
      "plt.style.use('default')\n",
      "sns.set_palette(\"husl\")\n",
      "\n",
      "print(\"=== FLOOD PREDICTION MODEL DEVELOPMENT GUIDE ===\\n\")\n",
      "\n",
      "# First, let's create a synthetic dataset that matches your features to demonstrate the approach\n",
      "print(\"1. CREATING SYNTHETIC FLOOD PREDICTION DATASET\")\n",
      "print(\"=\" * 50)\n",
      "\n",
      "np.random.seed(42)\n",
      "n_samples = 5000\n",
      "\n",
      "# Generate realistic flood prediction data\n",
      "data = {\n",
      "    'streamflow_cfs': np.random.lognormal(mean=4, sigma=1.5, size=n_samples),\n",
      "    'rainfall_24h': np.random.exponential(scale=0.8, size=n_samples),\n",
      "    'river_stage_ft': np.random.normal(loc=15, scale=5, size=n_samples),\n",
      "    'soil_moisture': np.random.beta(a=2, b=2, size=n_samples),\n",
      "    'elevation_ft': np.random.normal(loc=500, scale=200, size=n_samples)\n",
      "}\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Ensure realistic ranges\n",
      "df['streamflow_cfs'] = np.clip(df['streamflow_cfs'], 10, 50000)\n",
      "df['rainfall_24h'] = np.clip(df['rainfall_24h'], 0, 8)\n",
      "df['river_stage_ft'] = np.clip(df['river_stage_ft'], 2, 35)\n",
      "df['soil_moisture'] = np.clip(df['soil_moisture'], 0, 1)\n",
      "df['elevation_ft'] = np.clip(df['elevation_ft'], 50, 1500)\n",
      "\n",
      "print(f\"Dataset created with {len(df)} samples\")\n",
      "print(\"\\nBasic statistics of raw features:\")\n",
      "print(df.describe())\n",
      "\n",
      "# Create flood risk target based on realistic thresholds\n",
      "def create_flood_risk(row):\n",
      "    risk_score = 0\n",
      "    \n",
      "    # High streamflow increases risk\n",
      "    if row['streamflow_cfs'] > 5000:\n",
      "        risk_score += 3\n",
      "    elif row['streamflow_cfs'] > 2000:\n",
      "        risk_score += 2\n",
      "    elif row['streamflow_cfs'] > 1000:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # High rainfall increases risk\n",
      "    if row['rainfall_24h'] > 3:\n",
      "        risk_score += 3\n",
      "    elif row['rainfall_24h'] > 1.5:\n",
      "        risk_score += 2\n",
      "    elif row['rainfall_24h'] > 0.5:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # High river stage increases risk\n",
      "    if row['river_stage_ft'] > 25:\n",
      "        risk_score += 3\n",
      "    elif row['river_stage_ft'] > 20:\n",
      "        risk_score += 2\n",
      "    elif row['river_stage_ft'] > 15:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # High soil moisture increases risk\n",
      "    if row['soil_moisture'] > 0.8:\n",
      "        risk_score += 2\n",
      "    elif row['soil_moisture'] > 0.6:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # Lower elevation increases risk\n",
      "    if row['elevation_ft'] < 200:\n",
      "        risk_score += 2\n",
      "    elif row['elevation_ft'] < 400:\n",
      "        risk_score += 1\n",
      "    \n",
      "    # Convert to binary classification (high risk if score >= 5)\n",
      "    return 1 if risk_score >= 5 else 0\n",
      "\n",
      "df['flood_risk_24h'] = df.apply(create_flood_risk, axis=1)\n",
      "\n",
      "print(f\"\\nFlood risk distribution:\")\n",
      "print(df['flood_risk_24h'].value_counts())\n",
      "print(f\"Flood risk rate: {df['flood_risk_24h'].mean():.3f}\")\n",
      "\n",
      "# Save the synthetic dataset\n",
      "df.to_csv('flood_prediction_data.csv', index=False)\n",
      "print(\"\\nSynthetic dataset saved as 'flood_prediction_data.csv'\")\n",
      "```\n",
      "\n",
      "<stream_turn_title>Creating Synthetic Flood Prediction Dataset</stream_turn_title>\n",
      "\n",
      "**LLM Call Info:**\n",
      "\n",
      " Turn Time: 17.10s out of 120s.\n",
      "\n",
      " Turns: 1 out of 20.\n",
      " Time: 17.1 out of 3600.\n",
      " Cost: Turn: $0.1089, Total: $0.1089, Remaining: $479.55.\n",
      "\n",
      "\n",
      "ENDOFTURN\n",
      "\n",
      "\n",
      "**Executing python code blocks**\n",
      "\n",
      "=== FLOOD PREDICTION MODEL DEVELOPMENT GUIDE ===\n",
      "\n",
      "1. CREATING SYNTHETIC FLOOD PREDICTION DATASET\n",
      "==================================================\n",
      "Dataset created with 5000 samples\n",
      "\n",
      "Basic statistics of raw features:\n",
      "       streamflow_cfs  rainfall_24h  ...  soil_moisture  elevation_ft\n",
      "count     5000.000000   5000.000000  ...    5000.000000   5000.000000\n",
      "mean       170.909516      0.775323  ...       0.505449    497.939389\n",
      "std        539.062885      0.759004  ...       0.221674    200.694399\n",
      "min         10.000000      0.000042  ...       0.001511     50.000000\n",
      "25%         20.351253      0.231739  ...       0.334843    355.913323\n",
      "50%         55.712171      0.541609  ...       0.505851    496.262014\n",
      "75%        148.267183      1.072618  ...       0.677444    634.768324\n",
      "max      19719.367619      6.420943  ...       0.989759   1245.566669\n",
      "\n",
      "[8 rows x 5 columns]\n",
      "\n",
      "Flood risk distribution:\n",
      "0    4625\n",
      "1     375\n",
      "Name: flood_risk_24h, dtype: int64\n",
      "Flood risk rate: 0.075\n",
      "\n",
      "Synthetic dataset saved as 'flood_prediction_data.csv'\n",
      "\n",
      "\n",
      "** [Thursday, October 16, 2025 - 02:42:21.4 AM PDT] Completed execution of code block using python in 2.19 seconds after 1 out of 20 turns and time 19.9s out of 3600s and minimum runtime 0s.**\n",
      "\n",
      "ENDOFTURN\n",
      "Now let me continue with the comprehensive feature engineering and model building approach:\n",
      "\n",
      "```python\n",
      "# filename: flood_prediction_feature_engineering.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "from sklearn.feature_selection import SelectKBest, f_classif\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Load the dataset\n",
      "df = pd.read_csv('flood_prediction_data.csv')\n",
      "\n",
      "print(\"2. COMPREHENSIVE FEATURE ENGINEERING FOR FLOOD PREDICTION\")\n",
      "print(\"=\" * 60)\n",
      "\n",
      "# Create a copy for feature engineering\n",
      "df_features = df.copy()\n",
      "\n",
      "print(\"Original features:\")\n",
      "print(df_features.columns.tolist())\n",
      "\n",
      "# ===== DOMAIN-SPECIFIC FEATURE ENGINEERING =====\n",
      "print(\"\\n2.1 DOMAIN-SPECIFIC ENGINEERED FEATURES\")\n",
      "print(\"-\" * 40)\n",
      "\n",
      "# 1. Flow-based features\n",
      "df_features['streamflow_log'] = np.log1p(df_features['streamflow_cfs'])\n",
      "df_features['streamflow_sqrt'] = np.sqrt(df_features['streamflow_cfs'])\n",
      "\n",
      "# 2. Rainfall intensity categories\n",
      "df_features['rainfall_intensity'] = pd.cut(df_features['rainfall_24h'], \n",
      "                                         bins=[0, 0.1, 0.5, 1.0, 2.0, 10], \n",
      "                                         labels=['none', 'light', 'moderate', 'heavy', 'extreme'])\n",
      "df_features['rainfall_intensity_encoded'] = df_features['rainfall_intensity'].cat.codes\n",
      "\n",
      "# 3. River stage relative to elevation (flood potential)\n",
      "df_features['stage_elevation_ratio'] = df_features['river_stage_ft'] / df_features['elevation_ft']\n",
      "df_features['elevation_stage_diff'] = df_features['elevation_ft'] - df_features['river_stage_ft']\n",
      "\n",
      "# 4. Soil saturation levels\n",
      "df_features['soil_saturation_level'] = pd.cut(df_features['soil_moisture'],\n",
      "                                             bins=[0, 0.3, 0.6, 0.8, 1.0],\n",
      "                                             labels=['dry', 'moderate', 'wet', 'saturated'])\n",
      "df_features['soil_saturation_encoded'] = df_features['soil_saturation_level'].cat.codes\n",
      "\n",
      "# 5. Combined risk indicators\n",
      "df_features['flow_rainfall_interaction'] = df_features['streamflow_cfs'] * df_features['rainfall_24h']\n",
      "df_features['stage_moisture_interaction'] = df_features['river_stage_ft'] * df_features['soil_moisture']\n",
      "\n",
      "# 6. Threshold-based binary features (based on flood risk thresholds)\n",
      "df_features['high_flow'] = (df_features['streamflow_cfs'] > df_features['streamflow_cfs'].quantile(0.8)).astype(int)\n",
      "df_features['heavy_rain'] = (df_features['rainfall_24h'] > df_features['rainfall_24h'].quantile(0.8)).astype(int)\n",
      "df_features['high_stage'] = (df_features['river_stage_ft'] > df_features['river_stage_ft'].quantile(0.8)).astype(int)\n",
      "df_features['saturated_soil'] = (df_features['soil_moisture'] > 0.7).astype(int)\n",
      "df_features['low_elevation'] = (df_features['elevation_ft'] < df_features['elevation_ft'].quantile(0.3)).astype(int)\n",
      "\n",
      "# 7. Composite risk scores\n",
      "df_features['hydrological_risk'] = (df_features['high_flow'] + df_features['heavy_rain'] + \n",
      "                                   df_features['high_stage']) / 3\n",
      "df_features['terrain_risk'] = df_features['low_elevation'] * df_features['stage_elevation_ratio']\n",
      "df_features['saturation_risk'] = df_features['saturated_soil'] * df_features['soil_moisture']\n",
      "\n",
      "# 8. Statistical transformations\n",
      "df_features['streamflow_zscore'] = (df_features['streamflow_cfs'] - df_features['streamflow_cfs'].mean()) / df_features['streamflow_cfs'].std()\n",
      "df_features['rainfall_zscore'] = (df_features['rainfall_24h'] - df_features['rainfall_24h'].mean()) / df_features['rainfall_24h'].std()\n",
      "\n",
      "print(f\"Total features after engineering: {len(df_features.columns)}\")\n",
      "print(\"New engineered features:\")\n",
      "new_features = [col for col in df_features.columns if col not in df.columns]\n",
      "for feature in new_features:\n",
      "    print(f\"  - {feature}\")\n",
      "\n",
      "# ===== FEATURE IMPORTANCE ANALYSIS =====\n",
      "print(\"\\n2.2 FEATURE IMPORTANCE ANALYSIS\")\n",
      "print(\"-\" * 35)\n",
      "\n",
      "# Prepare features for analysis (exclude categorical string columns)\n",
      "feature_cols = [col for col in df_features.columns if col not in ['flood_risk_24h', 'rainfall_intensity', 'soil_saturation_level']]\n",
      "X = df_features[feature_cols]\n",
      "y = df_features['flood_risk_24h']\n",
      "\n",
      "# Handle any remaining NaN values\n",
      "X = X.fillna(X.median())\n",
      "\n",
      "# Quick Random Forest for feature importance\n",
      "rf_temp = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "rf_temp.fit(X, y)\n",
      "\n",
      "# Get feature importance\n",
      "feature_importance = pd.DataFrame({\n",
      "    'feature': X.columns,\n",
      "    'importance': rf_temp.feature_importances_\n",
      "}).sort_values('importance', ascending=False)\n",
      "\n",
      "print(\"Top 15 most important features:\")\n",
      "print(feature_importance.head(15))\n",
      "\n",
      "# ===== VISUALIZATION =====\n",
      "print(\"\\n2.3 CREATING FEATURE ANALYSIS VISUALIZATIONS\")\n",
      "print(\"-\" * 45)\n",
      "\n",
      "# Create comprehensive visualization\n",
      "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
      "fig.suptitle('Flood Prediction: Feature Analysis and Engineering', fontsize=16, fontweight='bold')\n",
      "\n",
      "# 1. Original features distribution by flood risk\n",
      "for i, feature in enumerate(['streamflow_cfs', 'rainfall_24h', 'river_stage_ft']):\n",
      "    ax = axes[0, i]\n",
      "    df_features.boxplot(column=feature, by='flood_risk_24h', ax=ax)\n",
      "    ax.set_title(f'{feature} by Flood Risk')\n",
      "    ax.set_xlabel('Flood Risk (0=No, 1=Yes)')\n",
      "\n",
      "# 2. Engineered features\n",
      "axes[1, 0].scatter(df_features['stage_elevation_ratio'], df_features['flood_risk_24h'], alpha=0.5)\n",
      "axes[1, 0].set_title('Stage-Elevation Ratio vs Flood Risk')\n",
      "axes[1, 0].set_xlabel('Stage/Elevation Ratio')\n",
      "axes[1, 0].set_ylabel('Flood Risk')\n",
      "\n",
      "axes[1, 1].scatter(df_features['flow_rainfall_interaction'], df_features['flood_risk_24h'], alpha=0.5)\n",
      "axes[1, 1].set_title('Flow-Rainfall Interaction vs Flood Risk')\n",
      "axes[1, 1].set_xlabel('Flow √ó Rainfall')\n",
      "axes[1, 1].set_ylabel('Flood Risk')\n",
      "\n",
      "axes[1, 2].bar(range(len(feature_importance.head(10))), feature_importance.head(10)['importance'])\n",
      "axes[1, 2].set_title('Top 10 Feature Importance')\n",
      "axes[1, 2].set_xticks(range(len(feature_importance.head(10))))\n",
      "axes[1, 2].set_xticklabels(feature_importance.head(10)['feature'], rotation=45, ha='right')\n",
      "\n",
      "# 3. Correlation analysis\n",
      "correlation_matrix = X.corr()\n",
      "top_features = feature_importance.head(10)['feature'].tolist()\n",
      "corr_subset = correlation_matrix.loc[top_features, top_features]\n",
      "\n",
      "im = axes[2, 0].imshow(corr_subset, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
      "axes[2, 0].set_title('Correlation: Top 10 Features')\n",
      "axes[2, 0].set_xticks(range(len(top_features)))\n",
      "axes[2, 0].set_yticks(range(len(top_features)))\n",
      "axes[2, 0].set_xticklabels(top_features, rotation=45, ha='right')\n",
      "axes[2, 0].set_yticklabels(top_features)\n",
      "\n",
      "# 4. Risk score distributions\n",
      "axes[2, 1].hist([df_features[df_features['flood_risk_24h']==0]['hydrological_risk'],\n",
      "                df_features[df_features['flood_risk_24h']==1]['hydrological_risk']], \n",
      "               bins=20, alpha=0.7, label=['No Flood', 'Flood'])\n",
      "axes[2, 1].set_title('Hydrological Risk Score Distribution')\n",
      "axes[2, 1].set_xlabel('Hydrological Risk Score')\n",
      "axes[2, 1].legend()\n",
      "\n",
      "# 5. Threshold analysis\n",
      "threshold_features = ['high_flow', 'heavy_rain', 'high_stage', 'saturated_soil', 'low_elevation']\n",
      "threshold_means = [df_features[df_features['flood_risk_24h']==1][feat].mean() for feat in threshold_features]\n",
      "axes[2, 2].bar(range(len(threshold_features)), threshold_means)\n",
      "axes[2, 2].set_title('Threshold Feature Activation in Flood Cases')\n",
      "axes[2, 2].set_xticks(range(len(threshold_features)))\n",
      "axes[2, 2].set_xticklabels(threshold_features, rotation=45, ha='right')\n",
      "axes[2, 2].set_ylabel('Activation Rate in Flood Cases')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.savefig('flood_feature_analysis.png', dpi=300, bbox_inches='tight')\n",
      "plt.show()\n",
      "\n",
      "# Save the engineered dataset\n",
      "df_features.to_csv('flood_prediction_engineered.csv', index=False)\n",
      "print(f\"\\nEngineered dataset saved as 'flood_prediction_engineered.csv'\")\n",
      "print(f\"Dataset shape: {df_features.shape}\")\n",
      "```\n",
      "\n",
      "**LLM Call Info:**\n",
      "\n",
      " Turn Time: 32.18s out of 120s.\n",
      "\n",
      " Turns: 2 out of 20.\n",
      " Time: 52.1 out of 3600.\n",
      " Cost: Turn: $0.0556, Total: $0.1645, Remaining: $479.50.\n",
      "\n",
      "\n",
      "ENDOFTURN\n",
      "\n",
      "\n",
      "**Executing python code blocks**\n",
      "\n",
      "\n",
      "\n",
      "** [Thursday, October 16, 2025 - 02:42:53.8 AM PDT] Code block you just gave with file flood_prediction_feature_engineering.py was not executed or no code blocks given.**\n",
      "\n",
      "ENDOFTURN\n",
      "```python\n",
      "# filename: flood_prediction_feature_engineering.py\n",
      "# execution: true\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
      "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
      "from sklearn.feature_selection import SelectKBest, f_classif\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Load the dataset\n",
      "df = pd.read_csv('flood_prediction_data.csv')\n",
      "\n",
      "print(\"2. COMPREHENSIVE FEATURE ENGINEERING FOR FLOOD PREDICTION\")\n",
      "print(\"=\" * 60)\n",
      "\n",
      "# Create a copy for feature engineering\n",
      "df_features = df.copy()\n",
      "\n",
      "print(\"Original features:\")\n",
      "print(df_features.columns.tolist())\n",
      "\n",
      "# ===== DOMAIN-SPECIFIC FEATURE ENGINEERING =====\n",
      "print(\"\\n2.1 DOMAIN-SPECIFIC ENGINEERED FEATURES\")\n",
      "print(\"-\" * 40)\n",
      "\n",
      "# 1. Flow-based features\n",
      "df_features['streamflow_log'] = np.\n",
      "\n",
      "‚úÖ Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "if H2OGPTE_AVAILABLE:\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "    # Using FastAPI streaming endpoint for h2oGPTe\n",
    "    url = f\"{api_server_base_url}/api/ai/chat/enhanced/stream\"\n",
    "    \n",
    "    payload = {\n",
    "        \"message\": \"\"\"I have flood prediction data with these features:\n",
    "        - streamflow_cfs: Current river flow rate\n",
    "        - rainfall_24h: Rainfall in last 24 hours\n",
    "        - river_stage_ft: Water level\n",
    "        - soil_moisture: Ground saturation\n",
    "        - elevation_ft: Location elevation\n",
    "        \n",
    "        How should I approach building an ML model to predict flood risk in the next 24 hours?\n",
    "        What feature engineering would you recommend?\"\"\",\n",
    "        \"provider\": \"h2ogpte\",\n",
    "        \"use_agent\": True,\n",
    "        \"max_tokens\": 8192*10,\n",
    "    }\n",
    "    \n",
    "    print(\"üß† Consulting h2oGPTe agent for AutoML guidance...\\n\")\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        last_content = \"\"\n",
    "        # Stream the response\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                line_str = line.decode('utf-8')\n",
    "                if line_str.startswith('data: '):\n",
    "                    data_str = line_str[6:]  # Remove 'data: ' prefix\n",
    "                    try:\n",
    "                        data = json.loads(data_str)\n",
    "                        \n",
    "                        # First message contains provider info\n",
    "                        if 'provider' in data:\n",
    "                            print(f\"üì° Provider: {data.get('provider')}\")\n",
    "                            print(f\"ü§ñ Model: {data.get('model')}\\n\")\n",
    "                            print(\"üìù Response:\\n\")\n",
    "                        \n",
    "                        # h2oGPTe sends incremental chunks with full content\n",
    "                        elif 'chunk' in data and not data.get('done', False):\n",
    "                            new_content = data['chunk']\n",
    "                            # Only print the new portion\n",
    "                            if new_content.startswith(last_content):\n",
    "                                new_part = new_content[len(last_content):]\n",
    "                                print(new_part, end='', flush=True)\n",
    "                                last_content = new_content\n",
    "                        \n",
    "                        # Check for completion\n",
    "                        elif data.get('done', False):\n",
    "                            break\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "        \n",
    "        print(\"\\n\\n‚úÖ Streaming complete!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping h2oGPTe demo (credentials not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 4: Multi-Agent System with FastMCP\n",
    "\n",
    "## ü§ù FastMCP - Model Context Protocol Server\n",
    "\n",
    "Our flood prediction system uses FastMCP to expose 20+ specialized tools across 5 intelligent agents:\n",
    "\n",
    "### The 5 Agents\n",
    "\n",
    "1. **Data Collector Agent** üìä\n",
    "   - Collects USGS water data\n",
    "   - Retrieves NOAA flood forecasts\n",
    "   - Gathers weather information\n",
    "   - Monitors data quality\n",
    "\n",
    "2. **Risk Analyzer Agent** ‚ö†Ô∏è\n",
    "   - Calculates flood risk scores\n",
    "   - Analyzes trends and patterns\n",
    "   - Identifies high-risk areas\n",
    "\n",
    "3. **Emergency Responder Agent** üö®\n",
    "   - Assesses emergency readiness\n",
    "   - Activates alerts\n",
    "   - Coordinates evacuations\n",
    "\n",
    "4. **AI Predictor Agent** üîÆ\n",
    "   - Generates flood forecasts\n",
    "   - Predicts critical conditions\n",
    "   - Analyzes prediction accuracy\n",
    "\n",
    "5. **H2OGPTE ML Agent** üß†\n",
    "   - Trains ML models\n",
    "   - Optimizes features\n",
    "   - Analyzes model performance\n",
    "\n",
    "### Let's explore the available tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Available Agents and Their Status\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üü¢ Data Collector\n",
      "   Description: Continuously pulls real-time flood data from USGS, NOAA, and weather APIs\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-16T09:39:30.741364+00:00\n",
      "   Check Interval: 300 seconds\n",
      "   Insights: 4\n",
      "   Active Alerts: 6\n",
      "\n",
      "üü¢ Risk Analyzer\n",
      "   Description: AI-powered analysis of flood risk conditions and trend detection\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-16T09:37:26.977038+00:00\n",
      "   Check Interval: 600 seconds\n",
      "   Insights: 4\n",
      "   Active Alerts: 10\n",
      "\n",
      "üü¢ Emergency Responder\n",
      "   Description: Coordinates emergency response activities and manages critical alerts\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-16T09:41:27.049336+00:00\n",
      "   Check Interval: 180 seconds\n",
      "   Insights: 5\n",
      "   Active Alerts: 33\n",
      "\n",
      "üü¢ AI Predictor\n",
      "   Description: Advanced AI forecasting and predictive analysis for flood conditions\n",
      "   Status: Running\n",
      "   Last Check: 2025-10-16T09:32:27.009585+00:00\n",
      "   Check Interval: 900 seconds\n",
      "   Insights: 4\n",
      "   Active Alerts: 1\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get list of all agents and their capabilities\n",
    "response = requests.get(f\"{api_server_base_url}/api/agents\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"ü§ñ Available Agents and Their Status\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # The API returns a nested structure with agents dictionary\n",
    "    agents_dict = data.get('agents', {})\n",
    "    \n",
    "    for agent_key, agent_data in agents_dict.items():\n",
    "        status = \"üü¢\" if agent_data.get('is_running') else \"üî¥\"\n",
    "        print(f\"\\n{status} {agent_data.get('name', agent_key)}\")\n",
    "        print(f\"   Description: {agent_data.get('description', 'N/A')}\")\n",
    "        print(f\"   Status: {'Running' if agent_data.get('is_running') else 'Stopped'}\")\n",
    "        if agent_data.get('last_check'):\n",
    "            print(f\"   Last Check: {agent_data.get('last_check')}\")\n",
    "        if agent_data.get('check_interval'):\n",
    "            print(f\"   Check Interval: {agent_data.get('check_interval')} seconds\")\n",
    "        if agent_data.get('insights_count'):\n",
    "            print(f\"   Insights: {agent_data.get('insights_count')}\")\n",
    "        if agent_data.get('active_alerts_count'):\n",
    "            print(f\"   Active Alerts: {agent_data.get('active_alerts_count')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error fetching agents: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Agent Insights\n",
    "\n",
    "Agents continuously monitor flood conditions and generate insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Refreshing USGS data first...\n",
      "\n",
      "‚úÖ USGS data refresh started\n",
      "‚è≥ Waiting for data refresh to process...\n",
      "\n",
      "üí° Agent Insights\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ü§ñ Data Collector\n",
      "------------------------------------------------------------\n",
      "\n",
      "üü° üîÑ Data Freshness: 0% current\n",
      "\n",
      "üîµ üåê API Connectivity: 5/5 active\n",
      "\n",
      "üîµ üìä Data Quality: 6.0/10\n",
      "   Change: +0.0\n",
      "\n",
      "üîµ ‚ö° Update Frequency: 12 updates/hour\n",
      "\n",
      "ü§ñ Risk Analyzer\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîµ üéØ Overall Risk Level: LOW (1.8/10)\n",
      "   Change: +0.0\n",
      "\n",
      "üîµ üö® Critical Watersheds: 0 areas\n",
      "\n",
      "üîµ üìà Risk Trend Analysis: Stable\n",
      "   Change: 0.0% per hour\n",
      "\n",
      "üîµ üß† AI Confidence: 40%\n",
      "   Change: Low\n",
      "\n",
      "ü§ñ Emergency Responder\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîµ üö® Active Incidents: 0 ongoing\n",
      "\n",
      "üîµ üöÅ Response Readiness: GOOD (85%)\n",
      "   Change: 8 teams ready\n",
      "\n",
      "üîµ üèÉ Evacuation Status: No active evacuations\n",
      "   Change: 0 zones active\n",
      "\n",
      "üîµ üì° Communication Systems: 100% operational\n",
      "   Change: 6 channels active\n",
      "\n",
      "üîµ üì¢ Alert Distribution: 0 alerts sent\n",
      "   Change: 0 today\n",
      "\n",
      "ü§ñ Predictor\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîµ üéØ Model Accuracy: 85.5%\n",
      "   Change: -3.4% vs yesterday\n",
      "\n",
      "üîµ üß† Prediction Confidence: 72%\n",
      "   Change: High\n",
      "\n",
      "================================================================================\n",
      "Generated at: 2025-10-16T09:43:51.693961+00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Refresh USGS data before getting insights\n",
    "print(\"üîÑ Refreshing USGS data first...\\n\")\n",
    "\n",
    "# Note: Using local-token for development mode (server.py allows this when OIDC is disabled)\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "refresh_response = requests.post(\n",
    "    f\"{api_server_base_url}/api/dashboard/refresh-usgs-data\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if refresh_response.status_code == 200:\n",
    "    refresh_result = refresh_response.json()\n",
    "    print(f\"‚úÖ {refresh_result.get('message', 'Data refresh initiated')}\")\n",
    "    \n",
    "    # Wait a moment for background job to start\n",
    "    print(\"‚è≥ Waiting for data refresh to process...\\n\")\n",
    "    time.sleep(3)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Data refresh returned status {refresh_response.status_code}\")\n",
    "    print(f\"   Proceeding with existing data...\\n\")\n",
    "\n",
    "# Get insights from all agents\n",
    "response = requests.get(f\"{api_server_base_url}/api/agents/insights\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    print(\"üí° Agent Insights\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # The API returns insights grouped by agent\n",
    "    insights_by_agent = data.get('insights', {})\n",
    "    \n",
    "    count = 0\n",
    "    for agent_name, agent_insights in insights_by_agent.items():\n",
    "        print(f\"\\nü§ñ {agent_name.replace('_', ' ').title()}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for insight in agent_insights:\n",
    "            title = insight.get('title', 'N/A')\n",
    "            value = insight.get('value', 'N/A')\n",
    "            change = insight.get('change')\n",
    "            urgency = insight.get('urgency', 'normal')\n",
    "            timestamp = insight.get('timestamp', '')\n",
    "            \n",
    "            urgency_icon = {\n",
    "                'critical': 'üî¥',\n",
    "                'high': 'üü°',\n",
    "                'normal': 'üîµ',\n",
    "                'low': 'üü¢'\n",
    "            }.get(urgency, '‚ö™')\n",
    "            \n",
    "            print(f\"\\n{urgency_icon} {title}: {value}\")\n",
    "            if change:\n",
    "                print(f\"   Change: {change}\")\n",
    "            \n",
    "            count += 1\n",
    "            if count >= 15:  # Limit total insights shown\n",
    "                break\n",
    "        \n",
    "        if count >= 15:\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Generated at: {data.get('generated_at', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"‚ùå Error fetching insights: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Risk Analyzer Agent\n",
    "\n",
    "Calculates comprehensive flood risk scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Risk Analyzer Agent...\n",
      "\n",
      "üöÄ Starting risk_analyzer agent...\n",
      "\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "[WARNING] Using provided input_schema for multi-argument function\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "Action: comprehensive_flood_analysis_tool\n",
      "Action Input: {\"location\": \"Texas\"}\n",
      "\n",
      "\u001b[39m\n",
      "------------------------------\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: comprehensive_flood_analysis_tool\n",
      "\u001b[33mTool's input: {'location': 'Texas'}\n",
      "\u001b[36mTool's response: \n",
      "{\"status\":\"success\",\"location\":\"Texas\",\"analysis_timestamp\":\"2025-10-16T09:44:19.281009+00:00\",\"data_collection\":{\"agent\":\"Data Collector\",\"data_sources\":{\"usgs_sites\":10,\"noaa_alerts\":0,\"weather_locations\":7},\"insights\":[{\"title\":\"üîÑ Data Freshness\",\"value\":\"100% current\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"üåê API Connectivity\",\"value\":\"5/5 active\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"üìä Data Quality\",\"value\":\"9.3/10\",\"trend\":\"up\",\"urgency\":\"normal\"},{\"title\":\"‚ö° Update Frequency\",\"value\":\"12 updates/hour\",\"trend\":\"stable\",\"urgency\":\"normal\"}],\"alerts\":[]},\"risk_analysis\":{\"agent\":\"Risk Analyzer\",\"insights\":[{\"title\":\"üéØ Overall Risk Level\",\"value\":\"Unknown (0.0/10)\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"üö® Critical Watersheds\",\"value\":\"0 areas\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"üìà Risk Trend Analysis\",\"value\":\"Insufficient data\",\"trend\":\"stable\",\"urgency\":\"normal\"},{\"title\":\"üß† AI Confidence\",\"value\":\"0%\",\"trend\":\"stable\",\"urgency\":\"normal\"}],\"alerts\":[]},\"...(rest of response truncated)\u001b[39m\n",
      "------------------------------\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "**Final Answer**\n",
      "\n",
      "**1. Detailed Risk Scores & Factors:**  \n",
      "- **Overall Risk Level:** LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "- **Critical Factors Identified:**  \n",
      "  - **Data Limitations:** 0% AI confidence due to incomplete inputs (e.g., missing rainfall, flow rates, or watershed specifics).  \n",
      "  - **Elevation/Topography:** Texas‚Äôs varied elevation (default 100m) and distance-to-water (default 5km) suggest localized risks, but no specific scores calculated.  \n",
      "\n",
      "**2. Highest Risk Components:**  \n",
      "- **Monitoring Gaps:** No active alerts or incidents, but 0/10 critical watersheds analyzed.  \n",
      "- **Prediction Confidence:** 70% AI confidence with 48-hour reliable forecasts, indicating potential for rapid risk escalation.  \n",
      "\n",
      "**3. Trend Analysis:**  \n",
      "- **Data Freshness:** 100% current, but trend accuracy at 82% ‚Äì suggests stable conditions with minor uncertainty.  \n",
      "- **Historical Context:** No historical events inputted (default 0), limiting long-term trend insights.  \n",
      "\n",
      "**4. Recommendations for Monitoring:**  \n",
      "- **Immediate Actions:**  \n",
      "  - Deploy **calculate_risk_score_tool** for high-risk Texas regions (e.g., Houston, Dallas) with real-time rainfall, USGS flow, and river stage data.  \n",
      "  - Run **analyze_flood_risk_tool** using watershed-specific datasets to identify hidden vulnerabilities.  \n",
      "- **Enhanced Surveillance:**  \n",
      "  - Increase NOAA alert integration (currently 0 alerts) and validate USGS site coverage (10 sites active).  \n",
      "  - Monitor 24-hour forecasts closely due to low AI confidence in current outputs.  \n",
      "\n",
      "**Final Assessment:**  \n",
      "While initial analysis indicates LOW risk, critical data gaps and tool limitations prevent definitive conclusions. Immediate recalibration with targeted tools and localized data is strongly advised to ensure accurate flood preparedness.\u001b[39m\n",
      "------------------------------\n",
      "üí¨ [AGENT] Retrying ReAct Agent, including output parsing Observation\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "**Final Answer**\n",
      "\n",
      "**1. Detailed Risk Scores & Factors:**  \n",
      "- **Overall Risk Level:** LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "- **Critical Factors Identified:**  \n",
      "  - **Data Limitations:** 0% AI confidence due to incomplete inputs (e.g., missing rainfall, flow rates, or watershed specifics).  \n",
      "  - **Elevation/Topography:** Texas‚Äôs varied elevation (default 100m) and distance-to-water (default 5km) suggest localized risks, but no specific scores calculated.  \n",
      "\n",
      "**2. Highest Risk Components:**  \n",
      "- **Monitoring Gaps:** No active alerts or incidents, but 0/10 critical watersheds analyzed.  \n",
      "- **Prediction Confidence:** 70% AI confidence with 48-hour reliable forecasts, indicating potential for rapid risk escalation.  \n",
      "\n",
      "**3. Trend Analysis:**  \n",
      "- **Data Freshness:** 100% current, but trend accuracy at 82% ‚Äì suggests stable conditions with minor uncertainty.  \n",
      "- **Historical Context:** No historical events inputted (default 0), limiting long-term trend insights.  \n",
      "\n",
      "**4. Recommendations for Monitoring:**  \n",
      "- **Immediate Actions:**  \n",
      "  - Deploy **calculate_risk_score_tool** for high-risk Texas regions (e.g., Houston, Dallas) with real-time rainfall, USGS flow, and river stage data.  \n",
      "  - Run **analyze_flood_risk_tool** using watershed-specific datasets to identify hidden vulnerabilities.  \n",
      "- **Enhanced Surveillance:**  \n",
      "  - Increase NOAA alert integration (currently 0 alerts) and validate USGS site coverage (10 sites active).  \n",
      "  - Monitor 24-hour forecasts closely due to low AI confidence in current outputs.  \n",
      "\n",
      "**Final Assessment:**  \n",
      "While initial analysis indicates LOW risk, critical data gaps and tool limitations prevent definitive conclusions. Immediate recalibration with targeted tools and localized data is strongly advised to ensure accurate flood preparedness.\u001b[39m\n",
      "------------------------------\n",
      "üí¨ [AGENT] Retrying ReAct Agent, including output parsing Observation\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "**Final Answer**\n",
      "\n",
      "**1. Detailed Risk Scores & Factors:**  \n",
      "- **Overall Risk Level:** LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "- **Critical Factors Identified:**  \n",
      "  - **Data Limitations:** 0% AI confidence due to incomplete inputs (e.g., missing rainfall, flow rates, or watershed specifics).  \n",
      "  - **Elevation/Topography:** Texas‚Äôs varied elevation (default 100m) and distance-to-water (default 5km) suggest localized risks, but no specific scores calculated.  \n",
      "\n",
      "**2. Highest Risk Components:**  \n",
      "- **Monitoring Gaps:** No active alerts or incidents, but 0/10 critical watersheds analyzed.  \n",
      "- **Prediction Confidence:** 70% AI confidence with 48-hour reliable forecasts, indicating potential for rapid risk escalation.  \n",
      "\n",
      "**3. Trend Analysis:**  \n",
      "- **Data Freshness:** 100% current, but trend accuracy at 82% ‚Äì suggests stable conditions with minor uncertainty.  \n",
      "- **Historical Context:** No historical events inputted (default 0), limiting long-term trend insights.  \n",
      "\n",
      "**4. Recommendations for Monitoring:**  \n",
      "- **Immediate Actions:**  \n",
      "  - Deploy **calculate_risk_score_tool** for high-risk Texas regions (e.g., Houston, Dallas) with real-time rainfall, USGS flow, and river stage data.  \n",
      "  - Run **analyze_flood_risk_tool** using watershed-specific datasets to identify hidden vulnerabilities.  \n",
      "- **Enhanced Surveillance:**  \n",
      "  - Increase NOAA alert integration (currently 0 alerts) and validate USGS site coverage (10 sites active).  \n",
      "  - Monitor 24-hour forecasts closely due to low AI confidence in current outputs.  \n",
      "\n",
      "**Final Assessment:**  \n",
      "While initial analysis indicates LOW risk, critical data gaps and tool limitations prevent definitive conclusions. Immediate recalibration with targeted tools and localized data is strongly advised to ensure accurate flood preparedness.\u001b[39m\n",
      "------------------------------\n",
      "üí¨ [AGENT] Retrying ReAct Agent, including output parsing Observation\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "**Final Answer**\n",
      "\n",
      "**1. Detailed Risk Scores & Factors:**  \n",
      "- **Overall Risk Level:** LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "- **Critical Factors Identified:**  \n",
      "  - **Data Limitations:** 0% AI confidence due to incomplete inputs (e.g., missing rainfall, flow rates, or watershed specifics).  \n",
      "  - **Elevation/Topography:** Texas‚Äôs varied elevation (default 100m) and distance-to-water (default 5km) suggest localized risks, but no specific scores calculated.  \n",
      "\n",
      "**2. Highest Risk Components:**  \n",
      "- **Monitoring Gaps:** No active alerts or incidents, but 0/10 critical watersheds analyzed.  \n",
      "- **Prediction Confidence:** 70% AI confidence with 48-hour reliable forecasts, indicating potential for rapid risk escalation.  \n",
      "\n",
      "**3. Trend Analysis:**  \n",
      "- **Data Freshness:** 100% current, but trend accuracy at 82% ‚Äì suggests stable conditions with minor uncertainty.  \n",
      "- **Historical Context:** No historical events inputted (default 0), limiting long-term trend insights.  \n",
      "\n",
      "**4. Recommendations for Monitoring:**  \n",
      "- **Immediate Actions:**  \n",
      "  - Deploy **calculate_risk_score_tool** for high-risk Texas regions (e.g., Houston, Dallas) with real-time rainfall, USGS flow, and river stage data.  \n",
      "  - Run **analyze_flood_risk_tool** using watershed-specific datasets to identify hidden vulnerabilities.  \n",
      "- **Enhanced Surveillance:**  \n",
      "  - Increase NOAA alert integration (currently 0 alerts) and validate USGS site coverage (10 sites active).  \n",
      "  - Monitor 24-hour forecasts closely due to low AI confidence in current outputs.  \n",
      "\n",
      "**Final Assessment:**  \n",
      "While initial analysis indicates LOW risk, critical data gaps and tool limitations prevent definitive conclusions. Immediate recalibration with targeted tools and localized data is strongly advised to ensure accurate flood preparedness.\u001b[39m\n",
      "------------------------------\n",
      "üí¨ [AGENT] Retrying ReAct Agent, including output parsing Observation\n",
      "üí¨ \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Analyze current flood risk for the Texas:\n",
      "    1. Calculate detailed risk scores for all factors\n",
      "    2. Identify the highest risk components\n",
      "    3. Provide trend analysis\n",
      "    4. Give recommendations for monitoring\n",
      "\n",
      "    Be specific about the risk levels and factors.\n",
      "\u001b[36mAgent's thoughts: \n",
      "k>\n",
      "\n",
      "**Final Answer**\n",
      "\n",
      "**1. Detailed Risk Scores & Factors:**  \n",
      "- **Overall Risk Level:** LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "- **Critical Factors Identified:**  \n",
      "  - **Data Limitations:** 0% AI confidence due to incomplete inputs (e.g., missing rainfall, flow rates, or watershed specifics).  \n",
      "  - **Elevation/Topography:** Texas‚Äôs varied elevation (default 100m) and distance-to-water (default 5km) suggest localized risks, but no specific scores calculated.  \n",
      "\n",
      "**2. Highest Risk Components:**  \n",
      "- **Monitoring Gaps:** No active alerts or incidents, but 0/10 critical watersheds analyzed.  \n",
      "- **Prediction Confidence:** 70% AI confidence with 48-hour reliable forecasts, indicating potential for rapid risk escalation.  \n",
      "\n",
      "**3. Trend Analysis:**  \n",
      "- **Data Freshness:** 100% current, but trend accuracy at 82% ‚Äì suggests stable conditions with minor uncertainty.  \n",
      "- **Historical Context:** No historical events inputted (default 0), limiting long-term trend insights.  \n",
      "\n",
      "**4. Recommendations for Monitoring:**  \n",
      "- **Immediate Actions:**  \n",
      "  - Deploy **calculate_risk_score_tool** for high-risk Texas regions (e.g., Houston, Dallas) with real-time rainfall, USGS flow, and river stage data.  \n",
      "  - Run **analyze_flood_risk_tool** using watershed-specific datasets to identify hidden vulnerabilities.  \n",
      "- **Enhanced Surveillance:**  \n",
      "  - Increase NOAA alert integration (currently 0 alerts) and validate USGS site coverage (10 sites active).  \n",
      "  - Monitor 24-hour forecasts closely due to low AI confidence in current outputs.  \n",
      "\n",
      "**Final Assessment:**  \n",
      "While initial analysis indicates LOW risk, critical data gaps and tool limitations prevent definitive conclusions. Immediate recalibration with targeted tools and localized data is strongly advised to ensure accurate flood preparedness.\u001b[39m\n",
      "------------------------------\n",
      "[WARNING] [AGENT] Failed to parse agent output after 5 attempts, consider enabling or increasing parse_agent_response_max_retries\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Data Collection Complete!\n",
      "\n",
      "Invalid Format: Missing 'Action:' after 'Thought:'\n",
      "k>\n",
      "\n",
      "**Final Answer**\n",
      "\n",
      "**1. Detailed Risk Scores & Factors:**  \n",
      "- **Overall Risk Level:** LOW (0.0/10) ‚Äì Insufficient data for precise scoring.  \n",
      "- **Critical Factors Identified:**  \n",
      "  - **Data Limitations:** 0% AI confidence due to incomplete inputs (e.g., missing rainfall, flow rates, or watershed specifics).  \n",
      "  - **Elevation/Topography:** Texas‚Äôs varied elevation (default 100m) and distance-to-water (default 5km) suggest localized risks, but no specific scores calculated.  \n",
      "\n",
      "**2. Highest Risk Components:**  \n",
      "- **Monitoring Gaps:** No active alerts or incidents, but 0/10 critical watersheds analyzed.  \n",
      "- **Prediction Confidence:** 70% AI confidence with 48-hour reliable forecasts, indicating potential for rapid risk escalation.  \n",
      "\n",
      "**3. Trend Analysis:**  \n",
      "- **Data Freshness:** 100% current, but trend accuracy at 82% ‚Äì suggests stable conditions with minor uncertainty.  \n",
      "- **Historical Context:** No historical events inputted (default 0), limiting long-term trend insights.  \n",
      "\n",
      "**4. Recommendations for Monitoring:**  \n",
      "- **Immediate Actions:**  \n",
      "  - Deploy **calculate_risk_score_tool** for high-risk Texas regions (e.g., Houston, Dallas) with real-time rainfall, USGS flow, and river stage data.  \n",
      "  - Run **analyze_flood_risk_tool** using watershed-specific datasets to identify hidden vulnerabilities.  \n",
      "- **Enhanced Surveillance:**  \n",
      "  - Increase NOAA alert integration (currently 0 alerts) and validate USGS site coverage (10 sites active).  \n",
      "  - Monitor 24-hour forecasts closely due to low AI confidence in current outputs.  \n",
      "\n",
      "**Final Assessment:**  \n",
      "While initial analysis indicates LOW risk, critical data gaps and tool limitations prevent definitive conclusions. Immediate recalibration with targeted tools and localized data is strongly advised to ensure accurate flood preparedness.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run Risk Analyzer Agent via NAT\n",
    "import json\n",
    "payload = {\n",
    "    \"agent\": \"risk_analyzer\",\n",
    "    \"message\": \"\"\"Analyze current flood risk for the Texas:\n",
    "    1. Calculate detailed risk scores for all factors\n",
    "    2. Identify the highest risk components\n",
    "    3. Provide trend analysis\n",
    "    4. Give recommendations for monitoring\n",
    "    \n",
    "    Be specific about the risk levels and factors.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Running Risk Analyzer Agent...\\n\")\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{api_server_base_url}/api/nat/chat/stream\",\n",
    "    json=payload,\n",
    "    headers=headers,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    final_output = None\n",
    "    \n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            line_str = line.decode('utf-8')\n",
    "            if line_str.startswith('data: '):\n",
    "                data_str = line_str[6:]  # Remove 'data: ' prefix\n",
    "                try:\n",
    "                    data = json.loads(data_str)\n",
    "                    \n",
    "                    # Handle different event types\n",
    "                    event_type = data.get('type')\n",
    "                    \n",
    "                    if event_type == 'start':\n",
    "                        print(f\"üöÄ Starting {data.get('agent_type')} agent...\")\n",
    "                        print()\n",
    "                    \n",
    "                    elif event_type == 'log':\n",
    "                        log_entry = data.get('log', {})\n",
    "                        level = log_entry.get('level', 'INFO')\n",
    "                        message = log_entry.get('message', '')\n",
    "                        \n",
    "                        # Show important logs\n",
    "                        if level in ['WARNING', 'ERROR']:\n",
    "                            print(f\"[{level}] {message}\")\n",
    "                        elif 'Agent' in message or 'Final Answer' in message or 'Tool' in message:\n",
    "                            print(f\"üí¨ {message}\")\n",
    "                    \n",
    "                    elif event_type == 'result':\n",
    "                        final_output = data.get('output')\n",
    "                        print(\"\\n\" + \"=\"*80)\n",
    "                        print(\"‚úÖ Data Collection Complete!\\n\")\n",
    "                    \n",
    "                    elif event_type == 'error':\n",
    "                        print(f\"\\n‚ùå Error: {data.get('error')}\")\n",
    "                    \n",
    "                    elif event_type == 'done':\n",
    "                        break\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "    \n",
    "    # Display final output\n",
    "    if final_output:\n",
    "        print(final_output)\n",
    "        print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: H2OGPTE ML Agent\n",
    "\n",
    "AutoML agent for model training and optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run H2OGPTE ML Agent via NAT\n",
    "payload = {\n",
    "    \"agent\": \"h2ogpte_agent\",\n",
    "    \"message\": \"\"\"Help me design an ML pipeline for flood prediction:\n",
    "    1. What features should I engineer from raw sensor data?\n",
    "    2. What model types work best for flood forecasting?\n",
    "    3. How should I handle imbalanced flood event data?\n",
    "    4. What validation strategy is appropriate for time-series?\n",
    "    \n",
    "    Provide actionable AutoML recommendations.\"\"\"\n",
    "}\n",
    "headers = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "print(\"üß† Running H2OGPTE ML Agent...\\n\")\n",
    "\n",
    "response = requests.post(f\"{api_server_base_url}/api/nat/chat\", json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"‚úÖ ML Recommendations Complete!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(result.get('response', result))\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 6: Real-World Data Integration\n",
    "\n",
    "## üåê Live Data from Government APIs\n",
    "\n",
    "Our system integrates with real-time data sources:\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "1. **USGS Water Services**\n",
    "   - Real-time streamflow (CFS)\n",
    "   - Gage height (feet)\n",
    "   - 12 monitoring stations in Texas\n",
    "   - Updated every 15 minutes\n",
    "\n",
    "2. **NOAA Weather Service**\n",
    "   - Flood warnings and watches\n",
    "   - Weather alerts\n",
    "   - Forecast data\n",
    "\n",
    "3. **Open-Meteo**\n",
    "   - Weather forecasts\n",
    "   - Flood API predictions\n",
    "   - Historical data\n",
    "\n",
    "### Let's view live watershed data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refresh USGS Data Manually\n",
    "\n",
    "Trigger a fresh data collection from USGS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Triggering USGS data refresh...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Live Watershed Data\n",
      "\n",
      "====================================================================================================\n",
      "                                                name  current_streamflow_cfs  risk_score  trend_rate_cfs_per_hour        last_updated\n",
      "         Neches River at Evadale, TX (USGS 08041000)                 1000.00         4.0                      0.0 2025-10-04 20:00:07\n",
      "        Red River at Arthur City, TX (USGS 07335500)                 1020.00         4.0                      0.0 2025-10-04 20:00:06\n",
      "      Brazos River near Rosharon, TX (USGS 08116650)                  934.00         3.9                      0.0 2025-10-04 20:00:07\n",
      "         Trinity River at Dallas, TX (USGS 08057000)                  330.00         1.6                      0.0 2025-10-04 20:00:07\n",
      "        Colorado River at Austin, TX (USGS 08158000)                  249.00         1.2                      0.0 2025-10-04 20:00:07\n",
      "    Sabine River near Gladewater, TX (USGS 08020000)                  120.00         0.6                      0.0 2025-10-04 20:00:07\n",
      "      Guadalupe River at Comfort, TX (USGS 08167000)                   53.20         0.5                      0.0 2025-10-04 20:00:07\n",
      "San Antonio River at San Antonio, TX (USGS 08178000)                   11.10         0.5                      0.0 2025-10-04 20:00:07\n",
      "      Pecos River near Sheffield, TX (USGS 08447000)                    6.03         0.5                      0.0 2025-10-04 20:00:07\n",
      "    Canadian River near Amarillo, TX (USGS 07227500)                   41.80         0.5                      0.0 2025-10-04 20:00:06\n",
      "       Llano River near Junction, TX (USGS 08150000)                   61.60         0.5                      0.0 2025-10-04 20:00:07\n",
      "        Nueces River near Mathis, TX (USGS 08211000)                   63.60         0.5                      0.0 2025-10-04 20:00:07\n",
      "====================================================================================================\n",
      "\n",
      "üìä Total Watersheds Monitored: 12\n",
      "\n",
      "‚ö†Ô∏è  Risk Distribution:\n",
      "   üî¥ High Risk (>7.0): 0\n",
      "   üü° Medium Risk (4.0-7.0): 2\n",
      "   üü¢ Low Risk (<4.0): 10\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Triggering USGS data refresh...\\n\")\n",
    "header = {\"Authorization\": \"Bearer local-token\"}\n",
    "\n",
    "response = requests.post(f\"{api_server_base_url}/api/dashboard/refresh-usgs-data\", headers=header    )\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    time.sleep(5)\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Get current watershed data\n",
    "response = requests.get(f\"{api_server_base_url}/api/watersheds\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    watersheds = response.json()\n",
    "    \n",
    "    # Convert to DataFrame for nice display\n",
    "    df = pd.DataFrame(watersheds)\n",
    "    \n",
    "    # Select key columns\n",
    "    display_cols = ['name', 'current_streamflow_cfs', 'risk_score', \n",
    "                    'trend_rate_cfs_per_hour', 'last_updated']\n",
    "    \n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    \n",
    "    print(\"üåä Live Watershed Data\\n\")\n",
    "    print(\"=\"*100)\n",
    "    print(df[available_cols].to_string(index=False))\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nüìä Total Watersheds Monitored: {len(watersheds)}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if 'risk_score' in df.columns:\n",
    "        high_risk = len(df[df['risk_score'] > 7.0])\n",
    "        medium_risk = len(df[(df['risk_score'] >= 4.0) & (df['risk_score'] <= 7.0)])\n",
    "        low_risk = len(df[df['risk_score'] < 4.0])\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Risk Distribution:\")\n",
    "        print(f\"   üî¥ High Risk (>7.0): {high_risk}\")\n",
    "        print(f\"   üü° Medium Risk (4.0-7.0): {medium_risk}\")\n",
    "        print(f\"   üü¢ Low Risk (<4.0): {low_risk}\")\n",
    "else:\n",
    "    print(f\"‚ùå Error fetching watersheds: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì Summary & Next Steps\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "In this notebook, you've learned how to:\n",
    "\n",
    "‚úÖ **Set up a multi-agent AI system** for disaster response  \n",
    "‚úÖ **Integrate h2oGPTe** for AutoML and model training  \n",
    "‚úÖ **Use NVIDIA NIM** for high-performance inference  \n",
    "‚úÖ **Build NAT agent workflows** with React patterns  \n",
    "‚úÖ **Implement FastMCP servers** with custom tools  \n",
    "‚úÖ **Integrate real-time data** from government APIs  \n",
    "‚úÖ **Coordinate multiple AI agents** for complex tasks  \n",
    "‚úÖ **Evaluate responses** using LLM-as-Judge  \n",
    "\n",
    "## Architecture Highlights\n",
    "\n",
    "- **5 Specialized Agents**: Data Collector, Risk Analyzer, Emergency Responder, Predictor, H2OGPTE ML\n",
    "- **20+ MCP Tools**: Via FastMCP server on port 8001\n",
    "- **NVIDIA NIM Models**: Nemotron Super 49B, Llama 3.1 variants\n",
    "- **h2oGPTe A2A**: Agent-to-agent AutoML capabilities\n",
    "- **Real-time Data**: USGS, NOAA, Weather APIs\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **NVIDIA NIM**: [build.nvidia.com](https://build.nvidia.com)\n",
    "- **h2oGPTe**: [h2o.ai/platform/enterprise-h2ogpte](https://h2o.ai/platform/enterprise-h2ogpte/)\n",
    "- **NVIDIA NAT**: [docs.nvidia.com/nat](https://docs.nvidia.com/nat)\n",
    "- **FastMCP**: [github.com/jlowin/fastmcp](https://github.com/jlowin/fastmcp)\n",
    "- **USGS Water Data**: [waterdata.usgs.gov](https://waterdata.usgs.gov)\n",
    "- **NOAA Weather**: [weather.gov](https://weather.gov)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Customize Agents**: Modify agent configs for your specific use case\n",
    "2. **Add Data Sources**: Integrate additional APIs and sensors\n",
    "3. **Train ML Models**: Use h2oGPTe to train production models\n",
    "4. **Deploy to Production**: Use Docker/Kubernetes deployment\n",
    "5. **Monitor Performance**: Add logging and metrics\n",
    "\n",
    "## Contributing\n",
    "\n",
    "This is an open-source AI for Good project. Contributions welcome!\n",
    "\n",
    "---\n",
    "\n",
    "### üåä Thank you for exploring the Flood Prediction Blueprint!\n",
    "\n",
    "**Built with ‚ù§Ô∏è using h2oGPTe and NVIDIA NIM**\n",
    "\n",
    "For questions and support, please open an issue in the repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
